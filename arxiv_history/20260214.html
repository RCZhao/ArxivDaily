<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>arXiv Daily: 2026-02-14</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Roboto:400,700&display=swap" rel="stylesheet">
    <style>
        body { font-family: 'Roboto', Arial, sans-serif; background: #f8f9fa; transition: background 0.3s; }
        .arxiv-card { margin: 2em auto; max-width: 900px; box-shadow: 0 2px 8px rgba(0,0,0,0.08); border-radius: 16px; transition: box-shadow 0.3s, transform 0.3s; }
        .arxiv-card:hover { box-shadow: 0 4px 12px rgba(0,0,0,0.1); transform: translateY(-1px); }
        .arxiv-title { background: linear-gradient(90deg, #0d6efd 60%, #6610f2 100%); color: #fff; border-radius: 16px 16px 0 0; padding: 1.5em; font-size: 1.5em; font-weight: 700; letter-spacing: 0.5px;}
        .arxiv-meta { font-size: 1em; color: #555; margin-bottom: 1em; }
        .arxiv-abstract { background: #fff; padding: 1.5em; border-radius: 0 0 16px 16px; font-size: 1.1em; line-height: 1.7;}
        .arxiv-links a { margin-right: 1em; }
        .arxiv-scores { margin-top: 1em; font-size: 1em; }
        .navbar { background: #fff; box-shadow: 0 2px 8px rgba(0,0,0,0.04);}
        .footer { text-align: center; color: #888; padding: 2em 0 1em 0; font-size: 0.95em;}
        @media (prefers-color-scheme: dark) {
            body { background: #181a1b; color: #e4e6eb; }
            .arxiv-card { background: #23272b; box-shadow: 0 2px 8px rgba(0,0,0,0.28);}
            .arxiv-card:hover { box-shadow: 0 5px 15px rgba(0,0,0,0.25); transform: translateY(-1px); }
            .arxiv-title { background: linear-gradient(90deg, #375a7f 60%, #6f42c1 100%);}
            .arxiv-abstract { background: #23272b; color: #e4e6eb;}
            .navbar { background: #23272b; color: #e4e6eb;}
            .text-muted { color: #adb5bd !important; }
        }
        /* Improved abstract readability */
        .arxiv-abstract-text {
            font-size: 1.1em;
            line-height: 1.7;
        }
        p.big {
            line-height: 1.6;
            font-size: large;
        }
    </style>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'] ],
          processEscapes: true
        }
      });
    </script>
    <script>
    function toggleAuthors(element) {
        const fullList = element.querySelector('.author-full');
        const shortList = element.querySelector('.author-short');
        const toggleText = element.querySelector('.author-toggle');
        
        fullList.style.display = fullList.style.display === 'none' ? 'inline' : 'none';
        shortList.style.display = shortList.style.display === 'none' ? 'inline' : 'none';
        toggleText.textContent = fullList.style.display === 'none' ? ' (show all)' : ' (show less)';
    }
    </script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
</head>
<body>
    <nav class="navbar navbar-expand-lg mb-4">
        <div class="container">
            <a class="navbar-brand fw-bold text-primary" href="#">arXiv Daily</a>
            <span class="navbar-text">Modern arXiv Reader</span>
        </div>
    </nav>

    
    <div class="container py-4">
        <header class="mb-4"><h2 class="display-6 text-center">Analysis of Your Favorites</h2></header>
        
        <div class="row justify-content-center">
            <div class="col-lg-8 mb-4">
                <div class="card">
                    <div class="card-header fw-bold">Interest Word Cloud</div>
                    <div class="card-body text-center p-2">
                        <img src="analysis_results/word_cloud.png" class="img-fluid rounded" alt="Word Cloud of favorite paper topics">
                    </div>
                </div>
            </div>
        </div>
        
        
        <div class="row justify-content-center">
            <div class="col-lg-8 mb-4">
                <div class="card">
                    <div class="card-header fw-bold">Interest Clusters</div>
                    <div class="card-body text-center p-2">
                        <img src="analysis_results/daily_cluster_map.png" class="img-fluid rounded" alt="2D Cluster plot of favorite papers">
                    </div>
                </div>
            </div>
        </div>
        
    </div>
    

    <div class="container py-4">
        <header class="mb-4"><h1 class="display-5 text-center text-primary">arXiv: 2026-02-14</h1></header>

        
        <div class="row justify-content-center">
            <div class="col-lg-8 mb-4">
                <div class="card">
                    <div class="card-header fw-bold">Score Distribution of All Papers Found Today</div>
                    <div class="card-body text-center p-2">
                        <img src="analysis_results/score_distribution.png" class="img-fluid rounded" alt="Score distribution of all papers found today">
                    </div>
                </div>
            </div>
        </div>
        

        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">1. Probing baryonic feedback with fast radio bursts: joint analyses with cosmic shear and galaxy clustering
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Amy Wayland, David Alonso, Robert Reischke</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Integrating fast radio burst dispersion measures with weak lensing surveys significantly enhances cosmological constraints by breaking degeneracies between baryonic feedback processes and matter fluctuation parameters. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Cosmological inference from weak lensing (WL) surveys is increasingly limited by uncertainties in baryonic physics, which suppress the non-linear matter power spectrum on small scales. Multi-probe analyses that incorporate complementary tracers of the gas distribution around haloes offer a pathway to calibrate these effects and recover unbiased cosmological information. In this work, we forecast the constraining power of a joint analysis combining fiducial data from a Stage-IV WL survey with measurements of the dispersion measure from fast radio bursts (FRBs). We evaluate the ability of this approach to simultaneously constrain cosmological parameters and the astrophysical processes governing baryonic feedback, and we quantify the impact of key FRB systematics, including redshift uncertainties and source clustering. We find that, even after accounting for these effects, a 3$\times$2-point analysis of WL and FRBs significantly improves cosmological constraints, reducing the degradation factor on $S_8$ by $\sim 80\%$ compared to WL alone. We further show that FRBs alone are sensitive only to a degenerate combination of the key baryonic parameters, $\log_{10} M_{\rm c}$ and $η_{\rm b}$, and that the inclusion of WL measurements breaks this degeneracy. Finally, we extend our framework to incorporate galaxy clustering measurements using Luminous Red Galaxy and Emission Line Galaxy samples, performing a unified 6$\times$2-point analysis of WL, dispersion measures of FRBs, and galaxy clustering. While this combined approach tightens constraints on $Ω_{\rm m}$ and $\log_{10} M_{\rm c}$, it does not lead to a significant improvement in $S_8$ constraints beyond those obtained from WL and FRBs alone.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.12174" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.12174" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.12174" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.9</span>
                        <span class="badge bg-info text-dark">Author Score: 0.06</span>
                        <span class="badge bg-primary">Semantic Score: 0.96</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: weak lensing, galaxy clustering, cosmological constraints / weak gravitational lensing, cosmic shear, cosmological constraints</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">2. Causal-JEPA: Learning World Models through Object-Level Latent Interventions
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Heejeong Nam, Quentin Le Lidec, Lucas Maes, Yann LeCun, Randall Balestriero</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Implementing object-level masking within a joint embedding prediction framework induces causal inductive biases that substantially improve counterfactual reasoning and planning efficiency in object-centric world models. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">World models require robust relational understanding to support prediction, reasoning, and control. While object-centric representations provide a useful abstraction, they are not sufficient to capture interaction-dependent dynamics. We therefore propose C-JEPA, a simple and flexible object-centric world model that extends masked joint embedding prediction from image patches to object-centric representations. By applying object-level masking that requires an object&#39;s state to be inferred from other objects, C-JEPA induces latent interventions with counterfactual-like effects and prevents shortcut solutions, making interaction reasoning essential. Empirically, C-JEPA leads to consistent gains in visual question answering, with an absolute improvement of about 20\% in counterfactual reasoning compared to the same architecture without object-level masking. On agent control tasks, C-JEPA enables substantially more efficient planning by using only 1\% of the total latent input features required by patch-based world models, while achieving comparable performance. Finally, we provide a formal analysis demonstrating that object-level masking induces a causal inductive bias via latent interventions. Our code is available at https://github.com/galilai-group/cjepa.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.11389" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.11389" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.11389" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.6</span>
                        <span class="badge bg-info text-dark">Author Score: 0.06</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling / representation learning, generative models, neural architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">3. Simulation-Based Cosmological Mass Calibration of XXL Galaxy Clusters using HSC Weak Lensing
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">Sut-Ieng Tam, Keiichi Umetsu, Adam Amara, Dominique Eckert, Manon Regamey, Nicolas Cerardi, I-Non Chiu, Mauro Sereno, Florian Pacaud, Sunayana Bhargava, et al.</span>
                                <span class="author-full" style="display: none;">Sut-Ieng Tam, Keiichi Umetsu, Adam Amara, Dominique Eckert, Manon Regamey, Nicolas Cerardi, I-Non Chiu, Mauro Sereno, Florian Pacaud, Sunayana Bhargava, Christian Garrel, Fabio Gastaldello, Elias Koulouridis, Ben Maughan, Rogerio Monteiro-Oliveira, Marguerite Pierre</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A simulation-based inference framework applied to X-ray-selected galaxy clusters and weak-lensing data produces cosmological constraints consistent with Planck while establishing a self-consistent mass-calibration scale for the XXL survey. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We present a cosmological analysis of the X-ray-selected galaxy cluster sample from the XXL survey, employing a simulation-based inference (SBI) framework to jointly constrain cosmological parameters and X-ray scaling relations through forward modeling of cluster counts, X-ray observables, and weak-lensing measurements. Our analysis combines X-ray data from the XMM-XXL survey with shear measurements from the three-year shape catalog of the Hyper Suprime-Cam Subaru Strategic Program. The analysis focuses on the XXL C1 sample, comprising 171 clusters for abundance modeling, a subset of 86 clusters located within the XXL-N region for lensing-based mass calibration, and 162 clusters with X-ray temperature and luminosity measurements used to constrain scaling relations. Using the density-estimation likelihood-free inference (DELFI) algorithm, we construct a forward model with 12 parameters that incorporates the XXL selection function and cluster population modeling and accounts for key systematic effects including cluster miscentering, photometric redshift bias, and mass-dependent weak-lensing bias. Our SBI analysis yields a constraint on the cosmological parameter $S_8 \equiv σ_8 (Ω_{m}/0.3)^{0.5} = 0.867 \pm 0.063$, with an additional 3% systematic uncertainty from neural network stochasticity. The result is consistent with Planck and recent cluster-based measurements. The inferred temperature-mass relation is consistent with self-similar expectations within uncertainties, whereas the luminosity-temperature relation exhibits a slope steeper than the self-similar prediction. From the resulting posterior distribution of the forward model, we derive lensing-calibrated mass estimates for all individual XXL clusters with measured X-ray temperatures or luminosities. These results provide a self-consistent mass calibration for future multi-probe cosmological analyses of the XXL sample.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.11989" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.11989" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.11989" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.6</span>
                        <span class="badge bg-info text-dark">Author Score: 0.01</span>
                        <span class="badge bg-primary">Semantic Score: 0.96</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: weak lensing, galaxy clustering, cosmological constraints</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">4. SPT-3G D1: Compton-$y$ maps using data from the SPT-3G and Planck surveys
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">A. S. Maniyar, F. Bianchini, W. L. K. Wu, S. Raghunathan, A. J. Anderson, B. Ansarinejad, M. Archipley, L. Balkenhol, D. R. Barron, P. S. Barry, et al.</span>
                                <span class="author-full" style="display: none;">A. S. Maniyar, F. Bianchini, W. L. K. Wu, S. Raghunathan, A. J. Anderson, B. Ansarinejad, M. Archipley, L. Balkenhol, D. R. Barron, P. S. Barry, K. Benabed, A. N. Bender, B. A. Benson, L. E. Bleem, S. Bocquet, F. R. Bouchet, L. Bryant, E. Camphuis, M. G. Campitiello, J. E. Carlstrom, J. Carron, C. L. Chang, P. Chaubal, P. M. Chichura, A. Chokshi, T. -L. Chou, A. Coerver, T. M. Crawford, C. Daley, T. de Haan, K. R. Dibert, M. A. Dobbs, M. Doohan, A. Doussot, D. Dutcher, W. Everett, C. Feng, K. R. Ferguson, N. C. Ferree, K. Fichman, A. Foster, S. Galli, A. E. Gambrel, A. K. Gao, R. W. Gardner, F. Ge, N. Goeckner-Wald, R. Gualtieri, F. Guidi, S. Guns, N. W. Halverson, E. Hivon, A. Y. Q. Ho, G. P. Holder, W. L. Holzapfel, J. C. Hood, A. Hryciuk, N. Huang, T. Jhaveri, F. Kéruzoré, A. R. Khalife, L. Knox, M. Korman, K. Kornoelje, C. -L. Kuo, K. Levy, Y. Li, A. E. Lowitz, C. Lu, G. P. Lynch, T. J. Maccarone, E. S. Martsen, F. Menanteau, M. Millea, J. Montgomery, Y. Nakato, T. Natoli, G. I. Noble, Y. Omori, A. Ouellette, Z. Pan, P. Paschos, K. A. Phadke, A. W. Pollak, K. Prabhu, W. Quan, M. Rahimi, A. Rahlin, C. L. Reichardt, M. Rouble, J. E. Ruhl, E. Schiappucci, A. C. Silva Oliveira, A. Simpson, J. A. Sobrin, A. A. Stark, J. Stephen, C. Tandoi, B. Thorne, C. Trendafilova, C. Umilta, J. D. Vieira, A. G. Vieregg, A. Vitrier, Y. Wan, N. Whitehorn, M. R. Young, J. A. Zebrowski</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> High-resolution thermal Sunyaev-Zel&#39;dovich Compton-y maps derived from combined South Pole Telescope and Planck data provide a robust tool for analyzing large-scale structure and the thermodynamic state of cosmic baryons. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We present thermal Sunyaev-Zel&#39;dovich (tSZ) Compton-$y$ parameter maps constructed from two years (2019-2020) of observations with the South Pole Telescope (SPT) third-generation camera, SPT-3G, combined with data from the Planck satellite. Using a linear combination (LC) pipeline, we obtain a suite of reconstructions that explore different trade-offs between statistical sensitivity and suppression of astrophysical contaminants, including minimum-variance, CMB-deprojected, and CIB-deprojected $y$-maps. We validate these maps through different statistical techniques such as auto- and cross-power spectra with large-scale structure tracers as well as stacking on cluster locations. These tests are used to understand the balance between noise and astrophysical foreground residuals (such as the CIB) in combination with the recovery of the tSZ signal for different maps. For example, results from stacking at the location of clusters confirm the robustness of the recovered tSZ signal over the $\sim 1500\: {\rm deg}^2$ SPT-3G survey field used in this analysis. The high-resolution and low-noise maps produced here provide an important cosmological tool for future studies, including measurements of the Compton-$y$ map power spectrum, cross-correlations with other tracers of the large-scale structure, detailed modeling of cluster pressure profiles, and study of the thermodynamic state of the baryons in the Universe.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.11279" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.11279" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.11279" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.6</span>
                        <span class="badge bg-info text-dark">Author Score: 0.01</span>
                        <span class="badge bg-primary">Semantic Score: 0.95</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling / Cluster 2</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">5. pespace: A new tool of GPU-accelerated and auto-differentiable response generation and likelihood evaluation for space-borne gravitational wave detectors
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Rui Niu, Chang Feng, Wen Zhao</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The pespace software utilizes hardware-accelerated automatic differentiation to perform efficient Bayesian parameter estimation for massive black hole binaries, demonstrating how higher-order waveform modes and multi-detector networks resolve parameter degeneracies. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Space-borne gravitational wave detectors will expand the scope of gravitational wave astronomy to the milli-Hertz band in the near future. The development of data analysis software infrastructure at the current stage is crucial. In this paper, we introduce \texttt{pespace} which can be used for the full Bayesian parameter estimation of massive black hole binaries with detectors including LISA, Taiji, and Tianqin. The core computations are implemented using the high-performance parallel programming framework \texttt{taichi-lang} which enables automatic differentiation and hardware acceleration across different architectures. We also reimplement the waveform models \texttt{PhenomXAS} and \texttt{PhenomXHM} in the separate package \texttt{tiwave} to integrate waveform generation within the \texttt{taichi-lang} scope, making the entire computation accelerated and differentiable. To demonstrate the functionality of the tool, we use a typical signal from a massive black hole binary to perform the full Bayesian parameter estimation with the complete likelihood function for three scenarios: including a single detector using the waveform with only the dominant mode; a single detector using the waveform including higher modes; and a detector network with higher modes included. The results demonstrate that higher modes are essential in breaking degeneracies, and coincident observations by the detector network can significantly improve the measurement of source properties. Additionally, automatic differentiation provides an accurate way to obtain the Fisher matrix without manual fine-tuning of the finite difference step size. Using a subset of extrinsic parameters, we show that the approximated posteriors obtained by the Fisher matrix agree well with those derived from Bayesian parameter estimation.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.12011" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.12011" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.12011" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.5</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.95</span>
                        
                            <span class="badge bg-secondary">gr-qc</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">6. Evolution of submillimeter galaxies across cosmic-web environments
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">Ankit Kumar, M. Celeste Artale, Antonio D. Montero-Dorta, Lucia Guaita, Joop Schaye, Kyoung-Soo Lee, Alexandra Pope, Facundo Rodriguez, Eric Gawiser, Ho Seong Hwang, et al.</span>
                                <span class="author-full" style="display: none;">Ankit Kumar, M. Celeste Artale, Antonio D. Montero-Dorta, Lucia Guaita, Joop Schaye, Kyoung-Soo Lee, Alexandra Pope, Facundo Rodriguez, Eric Gawiser, Ho Seong Hwang, Paulina Troncoso Iribarren, Jaehyun Lee, Seong-Kook Lee, Changbom Park, Yujin Yang</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Cosmological simulations reveal that submillimeter galaxies preferentially inhabit dense filamentary and cluster-halo environments at high redshift, where they serve as the primary drivers of star formation before undergoing gas depletion. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Submillimeter galaxies (SMGs) provide valuable insights into galaxy formation and evolution and are likely influenced by their cosmic environment. However, their rarity makes environmental trends difficult to establish. We use the FLAMINGO simulation, which simultaneously reproduces the redshift distribution and number counts of SMGs. We use the DisPerSE to identify filamentary structures at $z=4$, 3, 2, 1.5, and 1. We define inner cluster-halo, outer cluster-halo, inner filament, outer filament, and void/wall environments at each redshift considering mass evolution of cluster-halos and density evolution of filaments. For a fixed stellar-mass cut of $M_* \geq 10^{9}$ M$_{\odot}$, the fraction of SMGs in the inner cluster-halo environment declines from $\sim30\%$ at $z=4$ to $\sim3\%$ by $z=1$, and similar trends are observed in other environments. The abundance of SMGs within a cluster-halo increases with halo mass, mirroring the increase in the total galaxy population. Consequently, the ratio of SMG halo occupation to that of all galaxies is largely insensitive to halo mass, but varies with redshift. In contrast, the ratio of the halo occupation of non-SMGs to that of all galaxies declines with halo mass and shows little redshift evolution. We show that the central and satellite SMGs form two distinct populations in inner cluster-halos. SMGs occupy the metal-rich side of the metallicity distribution, but rarely attain the highest metallicities because ongoing enrichment is limited by gas depletion. The brightest SMGs (S$_{850} &gt; 10$ mJy) are found exclusively in inner cluster-halos, highlighting a strong connection between SMG luminosity and environmental density. Our results show that SMGs dominate star formation in dense environments, contributing up to $80\%$ of the SFR in inner cluster-halos at $z=4$, but less than $50\%$ in low-density regions.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.11751" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.11751" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.11751" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.5</span>
                        <span class="badge bg-info text-dark">Author Score: 0.01</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: weak lensing, galaxy clustering, cosmological constraints / galaxy-halo connection, weak lensing, clustering</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">7. HLA: Hadamard Linear Attention
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Hanno Ackermann, Hong Cai, Mohsen Ghafoorian, Amirhossein Habibian</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Hadamard Linear Attention improves upon standard linear approximations by applying nonlinearities after computing pairwise similarities, achieving higher-degree rational function approximations of softmax without sacrificing computational efficiency in large-scale video generation models. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The attention mechanism is an important reason for the success of transformers. It relies on computing pairwise relations between tokens. To reduce the high computational cost of standard quadratic attention, linear attention has been proposed as an efficient approximation. It employs kernel functions that are applied independently to the inputs before the pairwise similarities are calculated. That allows for an efficient computational procedure which, however, amounts to a low-degree rational function approximating softmax. We propose Hadamard Linear Attention (HLA). Unlike previous works on linear attention, the nonlinearity in HLA is not applied separately to queries and keys, but, analogously to standard softmax attention, after the pairwise similarities have been computed. It will be shown that the proposed nonlinearity amounts to a higher-degree rational function to approximate softmax. An efficient computational scheme for the proposed method is derived that is similar to that of standard linear attention. In contrast to other approaches, no time-consuming tensor reshaping is necessary to apply the proposed algorithm. The effectiveness of the approach is demonstrated by applying it to a large diffusion transformer model for video generation, an application that involves very large amounts of tokens.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.12128" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.12128" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.12128" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling / representation learning, generative models, neural architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">8. Prototype Transformer: Towards Language Model Architectures Interpretable by Design
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Yordan Yordanov, Matteo Forasassi, Bayar Menzat, Ruizhi Wang, Chang Qi, Markus Kaltenberger, Amine M&#39;Charrak, Tommaso Salvatori, Thomas Lukasiewicz</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Replacing standard self-attention with a prototype-based communication mechanism enables the development of autoregressive language models that offer linear scalability and inherent interpretability through the emergence of nameable conceptual vectors. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">While state-of-the-art language models (LMs) surpass the vast majority of humans in certain domains, their reasoning remains largely opaque, undermining trust in their output. Furthermore, while autoregressive LMs can output explicit reasoning, their true reasoning process is opaque, which introduces risks like deception and hallucination. In this work, we introduce the Prototype Transformer (ProtoT) -- an autoregressive LM architecture based on prototypes (parameter vectors), posed as an alternative to the standard self-attention-based transformers. ProtoT works by means of two-way communication between the input sequence and the prototypes, and we show that this leads to the prototypes automatically capturing nameable concepts (e.g. &#34;woman&#34;) during training. They provide the potential to interpret the model&#39;s reasoning and allow for targeted edits of its behavior. Furthermore, by design, the prototypes create communication channels that aggregate contextual information at different time scales, aiding interpretability. In terms of computation scalability, ProtoT scales linearly with sequence length vs the quadratic scalability of SOTA self-attention transformers. Compared to baselines, ProtoT scales well with model and data size, and performs well on text generation and downstream tasks (GLUE). ProtoT exhibits robustness to input perturbations on par or better than some baselines, but differs from them by providing interpretable pathways showing how robustness and sensitivity arises. Reaching close to the performance of state-of-the-art architectures, ProtoT paves the way to creating well-performing autoregressive LMs interpretable by design.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.11852" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.11852" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.11852" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling / representation learning, generative models, neural architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">9. Status of the $S_8$ Tension: A 2026 Review of Probe Discrepancies
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Ioannis Pantos, Leandros Perivolaropoulos</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A comprehensive review of the S8 tension using a unified cosmic microwave background baseline identifies a significant divergence between different weak lensing surveys, suggesting that systematic effects in data pipelines contribute heavily to the observed cosmological discrepancies. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The parameter $S_8 \equiv σ_8 (Ω_m/0.3)^{0.5}$ quantifies the amplitude of matter density fluctuations. A persistent discrepancy exists between early-universe CMB observations and late-universe probes. This review assesses the ``$S_8$ tension&#39;&#39; against a new 2026 baseline: a unified ``Combined CMB&#39;&#39; framework incorporating Planck, ACT DR6, and SPT-3G. This combined analysis yields $S_8 = 0.836^{+0.012}_{-0.013}$, providing a higher central value and reduced uncertainties compared to Planck alone. Compiling measurements from 2019--2026, we reveal a striking bifurcation: DES Year 6 results exhibit a statistically significant tension of $2.4σ$--$2.7σ$ \citep{DESY6}, whereas KiDS Legacy results demonstrate statistical consistency at $&lt;1σ$ \citep{Wright2025}. We examine systematic origins of this dichotomy, including photometric redshift calibration, intrinsic alignment modeling, and shear measurement pipelines. We further contextualize these findings with cluster counts (where eROSITA favors high values while SPT favors low), galaxy-galaxy lensing, and redshift-space distortions. The heterogeneous landscape suggests survey-specific systematic effects contribute substantially to observed discrepancies, though new physics beyond $Λ$CDM cannot be excluded.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.12238" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.12238" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.12238" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">10. From Atoms to Trees: Building a Structured Feature Forest with Hierarchical Sparse Autoencoders
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Yifan Luo, Yang Zhan, Jiedong Jiang, Tianyang Liu, Mingrui Wu, Zhennan Zhou, Bin Dong</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Hierarchical Sparse Autoencoders utilize structural constraints and feature perturbations to jointly learn multi-scale conceptual relationships, effectively mapping the inherent hierarchical organization of representations within large language models. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Sparse autoencoders (SAEs) have proven effective for extracting monosemantic features from large language models (LLMs), yet these features are typically identified in isolation. However, broad evidence suggests that LLMs capture the intrinsic structure of natural language, where the phenomenon of &#34;feature splitting&#34; in particular indicates that such structure is hierarchical. To capture this, we propose the Hierarchical Sparse Autoencoder (HSAE), which jointly learns a series of SAEs and the parent-child relationships between their features. HSAE strengthens the alignment between parent and child features through two novel mechanisms: a structural constraint loss and a random feature perturbation mechanism. Extensive experiments across various LLMs and layers demonstrate that HSAE consistently recovers semantically meaningful hierarchies, supported by both qualitative case studies and rigorous quantitative metrics. At the same time, HSAE preserves the reconstruction fidelity and interpretability of standard SAEs across different dictionary sizes. Our work provides a powerful, scalable tool for discovering and analyzing the multi-scale conceptual structures embedded in LLM representations.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.11881" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.11881" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.11881" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling / representation learning, generative models, neural architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">11. Is cosmic birefringence due to dark energy or dark matter? Simulation-based inference
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Florie Carralot, Patricia Diego-Palazuelos, Adriaan J. Duivenvoorden, Eiichiro Komatsu, Nicoletta Krachmalnicoff, Carlo Baccigalupi</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Neural likelihood and posterior estimation applied to cosmic microwave background polarization data reveal non-Gaussian EB correlations and a mass-dependent transition in cosmic birefringence sensitivity, though instrumental effects and gravitational lensing limit the definitive identification of dark energy signatures. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Simulation-based inference (SBI) is a powerful inference technique for cases where the exact functional form of the likelihood is not known. A prime example is the likelihood of cross-correlation power spectra of the cosmic microwave background (CMB) fields at low multipoles, $\ell\lesssim 10$. In this paper, we investigate a parity-violating cross-correlation between $E$- and $B$- mode polarization fields using SBI. The $EB$ correlation at low $\ell$ is essential to distinguish between possible axion dark energy and dark matter interpretations of `cosmic birefringence&#39;, a rotation of the plane of linear polarization of the CMB, recently reported from WMAP, Planck, and Atacama Cosmology Telescope data. We use neural likelihood estimation to infer the likelihood of the $EB$ correlation at low $\ell$ and show that it is highly non-Gaussian. We then employ neural posterior estimation to constrain the scalar field mass ($m_φ$), the cosmic birefringence amplitude ($gφ_\mathrm{in}/2$), and the instrumental miscalibration angle ($α$), from simulated datasets. We find that the posterior on $m_φ$ shows two regimes, with a transition marked by $10^{-32}$ eV, highlighting a strong sensitivity to the scale dependence of cosmic birefringence. To quantify this behavior, we compute the probability $p(m_φ &lt; 10^{-32}$\,eV) for various fiducial values of $m_φ$. We find that $α$ and the contribution of lensed $B$ modes ultimately limit our ability to exclude the dark energy scenario fully.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.12019" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.12019" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.12019" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.01</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">12. Reionization Bubbles from Real-Space Cross Correlations of Line Intensity Maps
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Emilie Thélie, Sarah Libanore, Yonatan Sklansky, Julian B. Muñoz, Ely D. Kovetz</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Real-space cross-correlation between 21-cm signals and line-intensity maps provides a robust method for tracking the emergence and growth of ionized bubbles during the Epoch of Reionization by utilizing the transition from positive to negative correlation to identify peak bubble abundance. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We propose a new way to reconstruct the ionized-bubble size distribution during the Epoch of Reionization (EoR) through the real-space cross-correlation of 21-cm and star-forming line-intensity maps. Understanding the evolution and timing of the EoR is crucial for both astrophysics and cosmology, and a wealth of information on the first sources can be extracted from the study of ionized bubbles. Nevertheless, directly mapping bubbles is challenging due to the high redshifts involved, possible selection biases, and foregrounds in 21-cm maps. Here, we exploit the real-space cross-correlation $ξ_{21,ν}$ between 21-cm and line-intensity mapping (LIM) signals to reconstruct the evolution of bubble sizes during reionization. For the first time, we show that $ξ_{21,ν}(r)$ departs from a saturation level for each separation $r$ when bubbles of size $r$ begin to form, providing a handle for the onset of bubbles of each radius. Moreover, we demonstrate that $ξ_{21,ν}$ evolves from positive to negative as the EoR progresses, reaching a minimum (i.e. maximum anti-correlation) when bubbles of radius $r$ reach peak abundance. We show that these results are robust to changes in the astrophysical model as well as the timing/topology of reionization. This real-space observable complements usual Fourier-space estimators by capturing the localized nature of bubbles, offering new insights into the sources driving cosmic reionization.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.12277" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.12277" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.12277" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">13. Subaru High-$z$ Exploration of Low-Luminosity Quasars (SHELLQs). XXV. Large-scale environments of low-luminosity quasars at $z\sim6$ traced by Ly$α$ emitters
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">Junya Arita, Nobunari Kashikawa, Yoshiki Matsuoka, Masafusa Onoue, Michael A. Strauss, Kentaro Koretomo, Yoshihiro Takeda, Ryo Emori, Wanqiu He, Hiroki Hoshi, et al.</span>
                                <span class="author-full" style="display: none;">Junya Arita, Nobunari Kashikawa, Yoshiki Matsuoka, Masafusa Onoue, Michael A. Strauss, Kentaro Koretomo, Yoshihiro Takeda, Ryo Emori, Wanqiu He, Hiroki Hoshi, Masatoshi Imanishi, Rikako Ishimoto, Kei Ito, Kazushi Iwasawa, Satoshi Kikuta, Yongming Liang, Camryn L. Phillips, Shunta Shimizu, John D. Silverman, Yoshiki Toba, Takehiro Yoshioka</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Narrowband imaging of low-luminosity quasars at high redshift demonstrates that their local environments exhibit significant diversity in galaxy density regardless of radiative feedback, with some residing in overdensities that exceed those of typical galaxies with similar stellar masses. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">High-$z$ quasars are believed to reside in massive dark matter haloes (DMHs), suggesting that they reside in galaxy overdense regions. However, previous observations have shown a range of environments around them. The previous targets are limited to bright quasars ($M_{1450}\lesssim-25$), for which photoevaporation may hinder galaxy formation in their vicinity. Here, we present Subaru/Hyper-Suprime Cam observations of the environments of four low-luminosity quasars ($-24&lt;M_{1450}&lt;-22$) at $z\sim6.18$, which are expected to have a smaller photoevaporation effect. We detect Lyman $α$ emitters (LAEs) around them with narrowband NB872 imaging, and measure the local LAE overdensity. One quasar (J0844$-$0132) resides in an overdense region ($δ_\mathrm{LAE}=3.77\pm0.97$), whereas the other three fields are consistent with normal fields. The result is confirmed over the proximity zone of each quasar, suggesting that the diverse environment around quasars is independent of photoevaporation. We find no significant correlation between the LAE overdensities and the properties of host galaxies and supermassive black holes. Our quasars have host stellar mass measurements from JWST, allowing us to compare them with the LAE overdensity around galaxies without quasar activity with comparable stellar masses. We find that the LAE overdensity in the J0844$-$0132 field is stronger than that of galaxies with similar stellar mass at $z\sim6$, while the other quasar fields show a comparable LAE overdensity.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.11736" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.11736" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.11736" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.03</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: weak lensing, galaxy clustering, cosmological constraints / galaxy-halo connection, weak lensing, clustering</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">14. Amortised and provably-robust simulation-based inference
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Ayush Bharti, Charita Dellaporta, Yuga Hikida, François-Xavier Briol</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Combining generalized Bayesian principles with a neural approximation of weighted score-matching losses yields an amortized simulation-based inference framework that is provably robust to data outliers and computationally more efficient than traditional Markov chain Monte Carlo methods. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Complex simulator-based models are now routinely used to perform inference across the sciences and engineering, but existing inference methods are often unable to account for outliers and other extreme values in data which occur due to faulty measurement instruments or human error. In this paper, we introduce a novel approach to simulation-based inference grounded in generalised Bayesian inference and a neural approximation of a weighted score-matching loss. This leads to a method that is both amortised and provably robust to outliers, a combination not achieved by existing approaches. Furthermore, through a carefully chosen conditional density model, we demonstrate that inference can be further simplified and performed without the need for Markov chain Monte Carlo sampling, thereby offering significant computational advantages, with complexity that is only a small fraction of that of current state-of-the-art approaches.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.11325" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.11325" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.11325" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">stat.ML</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">15. Extending the Cosmological Collider: New Scaling Regimes and Constraints from BOSS
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Daniel Green, Jiashu Han, Benjamin Wallisch</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Direct couplings between the inflaton and auxiliary fields produce unique oscillatory signatures in the scale-dependent bias of the galaxy power spectrum, providing a sensitive probe for high-energy physics that enhances the discovery potential of large-scale structure surveys. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Primordial non-Gaussianity generated by additional fields during inflation offers a compelling observational target. Heavy fields imprint characteristic oscillatory signals in non-Gaussian correlation functions of the inflaton, a process sometimes referred to as cosmological-collider physics. These distinct signatures are compelling windows into ultra-high-energy physics, but are often suppressed, making standard equilateral non-Gaussianity the most promising discovery channel in many scenarios. In this paper, we show that direct couplings between the inflaton and additional fields can lead to a wide variety of novel, observationally relevant signals which open new parameter regimes that simultaneously exhibit the characteristics of light and heavy fields. We identify these primordial signatures in the late-time observables of the large-scale structure of the Universe, where they most significantly modify the scale-dependent bias of the galaxy power spectrum to include an oscillatory modulation around a non-trivial power law. We explore the full range of parameters that phenomenologically arise in these models and study the sensitivity of current and future galaxy surveys, finding that this new class of primordial non-Gaussianity is particularly accessible in near-term surveys due to its oscillatory feature. Finally, we perform an analysis of existing data from the final release of the Baryon Oscillation Spectroscopic Survey (BOSS DR12). While we find no evidence for a signal, we demonstrate significant improvements in sensitivity over respective non-oscillatory scenarios and place the first constraints on this extended parameter space of oscillatory non-Gaussianity.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.12232" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.12232" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.12232" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">16. GHOST: Unmasking Phantom States in Mamba2 via Grouped Hidden-state Output-aware Selection &amp; Truncation
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Michael Menezes, Anastasios Kyrillidis</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Approximating control-theoretic balanced truncation through forward-pass statistics allows for a significant reduction in the state-dimension overhead of Mamba2 models while maintaining high predictive accuracy. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">While Mamba2&#39;s expanded state dimension enhances temporal modeling, it incurs substantial inference overhead that saturates bandwidth during autoregressive generation. Standard pruning methods fail to address this bottleneck: unstructured sparsity leaves activations dense, magnitude-based selection ignores runtime dynamics, and gradient-based methods impose prohibitive costs. We introduce GHOST (Grouped Hidden-state Output-aware Selection and Truncation), a structured pruning framework that approximates control-theoretic balanced truncation using only forward-pass statistics. By jointly measuring controllability and observability, GHOST rivals the fidelity of gradient-based methods without requiring backpropagation. As a highlight, on models ranging from 130M to 2.7B parameters, our approach achieves a 50\% state-dimension reduction with approximately 1 perplexity point increase on WikiText-2. Code is available at https://anonymous.4open.science/r/mamba2_ghost-7BCB/.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.11408" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.11408" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.11408" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling / representation learning, generative models, neural architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">17. Beyond Parameter Arithmetic: Sparse Complementary Fusion for Distribution-Aware Model Merging
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Weihong Lin, Lin Sun, Qilong Shi, Aomufei Yuan, Yuxuan Tian, Zhengyang Wang, Guangxiang Zhao, Xiangzheng Zhang, Tong Yang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Selective incorporation of complementary parameters based on reverse Kullback-Leibler divergence allows the SCF-RKL framework to merge large language models while minimizing functional interference and preserving generative stability. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Model merging has emerged as a promising paradigm for composing the capabilities of large language models by directly operating in weight space, enabling the integration of specialized models without costly retraining. However, existing merging methods largely rely on parameter-space heuristics, which often introduce severe interference, leading to degraded generalization and unstable generation behaviors such as repetition and incoherent outputs. In this work, we propose Sparse Complementary Fusion with reverse KL (SCF-RKL), a novel model merging framework that explicitly controls functional interference through sparse, distribution-aware updates. Instead of assuming linear additivity in parameter space, SCF-RKL measures the functional divergence between models using reverse Kullback-Leibler divergence and selectively incorporates complementary parameters. This mode-seeking, sparsity-inducing design effectively preserves stable representations while integrating new capabilities. We evaluate SCF-RKL across a wide range of model scales and architectures, covering both reasoning-focused and instruction-tuned models. Extensive experiments on 24 benchmarks spanning advanced reasoning, general reasoning and knowledge, instruction following, and safety demonstrate, vision classification that SCF-RKL consistently outperforms existing model merging methods while maintaining strong generalization and generation stability.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.11717" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.11717" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.11717" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling / representation learning, generative models, neural architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">18. Seq2Seq2Seq: Lossless Data Compression via Discrete Latent Transformers and Reinforcement Learning
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Mahdi Khodabandeh, Ghazal Shabani, Arash Yousefi Jordehi, Seyed Abolghasem Mirroshandel</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Reinforcement learning integrated with a T5 transformer architecture enables a lossless data compression scheme that optimizes token sequences rather than continuous latent vectors, achieving superior compression ratios by exploiting inherent structural redundancies. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Efficient lossless compression is essential for minimizing storage costs and transmission overhead while preserving data integrity. Traditional compression techniques, such as dictionary-based and statistical methods, often struggle to optimally exploit the structure and redundancy in complex data formats. Recent advancements in deep learning have opened new avenues for compression; however, many existing approaches depend on dense vector representations that obscure the underlying token structure. To address these limitations, we propose a novel lossless compression method that leverages Reinforcement Learning applied to a T5 language model architecture. This approach enables the compression of data into sequences of tokens rather than traditional vector representations. Unlike auto-encoders, which typically encode information into continuous latent spaces, our method preserves the token-based structure, aligning more closely with the original data format. This preservation allows for higher compression ratios while maintaining semantic integrity. By training the model using an off-policy Reinforcement Learning algorithm, we optimize sequence length to minimize redundancy and enhance compression efficiency. Our method introduces an efficient and adaptive data compression system built upon advanced Reinforcement Learning techniques, functioning independently of external grammatical or world knowledge. This approach shows significant improvements in compression ratios compared to conventional methods. By leveraging the latent information within language models, our system effectively compresses data without requiring explicit content understanding, paving the way for more robust and practical compression solutions across various applications.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.12146" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.12146" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.12146" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling / representation learning, generative models, neural architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">19. The &#34;bubbly&#34; interstellar medium as origin for the inhomogeneous internal metallicity distributions in large disk galaxies
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Benjamin Metha, Michele Trenti, Colin Norman</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Small-scale chemical variations in local disk galaxies are attributed to metal-enriched superbubbles from spatially correlated supernovae, suggesting that star formation in large galaxies remains intrinsically bursty at the sub-kiloparsec level despite appearing steady on global scales. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Resolved metallicity studies of local disk galaxies have revealed that their interstellar media (ISMs) are far from chemically homogeneous, displaying significant ($\sim 0.05$ dex) variations in the metallicity on characteristic scales of a few hundred parsecs. Such data is at odds with most analytical models, where the ISM is predicted to be more well-mixed. Here, we suggest that the observed small-scale features seen in galaxies may be superbubbles of metal-enriched gas created by a collection of core collapse supernovae with tight spatial (and temporal) correlation. In this scenario, the size of the metallicity fluctuations (superbubble radius, $φ$) is set by the disk scale height of the galaxy in question (after which point shock breakout favours preferential expansion along directions perpendicular to the dense disc), and the amount of additional metals contained within a fluctuation is proportional to the star formation efficiency in superbubble regions ($ε$). To test this theory, we analysed metallicity maps from the PHANGS-MUSE sample of galaxies using a geostatistical forward-modelling approach. We find $φ\simeq 300$ pc and $ε= 0.1-0.2$, in good agreement with our theoretical model. Further, these small-scale parameters are found to be related to the global galaxy properties, suggesting that the local structure of the interstellar medium of galaxies is not universal. Such a model of star formation paints a new picture of galaxy evolution in the modern universe: in large local galaxies, star formation appears steady and regular when averaged over large scales. However, on small scales, these large galaxies remain intrinsically bursty like their smaller, high-redshift counterparts.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.11450" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.11450" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.11450" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: weak lensing, galaxy clustering, cosmological constraints / galaxy-halo connection, weak lensing, clustering</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">20. Addressing the ground state of the deuteron by physics-informed neural networks
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Lorenzo Brevi, Antonio Mandarino, Carlo Barbieri, Enrico Prati</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Physics-Informed Neural Networks successfully extract nuclear eigenstates for the deuteron by incorporating realistic nucleon-nucleon interactions and an efficient variational energy loss function, achieving high-precision results comparable to traditional numerical solvers. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Machine learning techniques have proven to be effective in addressing the structure of atomic nuclei. Physics$-$Informed Neural Networks (PINNs) are a promising machine learning technique suitable for solving integro-differential problems such as the many-body Schrödinger problem. So far, there has been no demonstration of extracting nuclear eigenstates using such method. Here, we tackle realistic nucleon-nucleon interaction in momentum space, including models with strong high-momentum correlations, and demonstrate highly accurate results for the deuteron. We further provide additional benchmarks in coordinate space. We introduce an expression for the variational energy that enters the loss function, which can be evaluated efficiently within the PINNs framework. Results are in excellent agreement with proven numerical methods, with a relative error between the value of the predicted binding energy by the PINN and the numerical benchmark of the order of $10^{-6}$. Our approach paves the way for the exploitation of PINNs to solve more complex atomic nuclei.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.11193" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.11193" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.11193" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">physics.comp-ph</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">21. NE2025: An Updated Electron Density Model for the Galactic Interstellar Medium
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>S. K. Ocker, J. M. Cordes</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The NE2025 Galactic electron density model incorporates updated pulsar parallaxes and scattering measurements to provide significantly more accurate distance and scattering predictions for compact radio sources. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Free electrons in the Galactic interstellar medium (ISM) disperse and scatter coherent radio waves, by amounts that depend on the distance to the radio source. Models of the Galactic electron density are thus widely used to predict distances and scattering of compact radio sources (including pulsars, fast radio bursts (FRBs), and long-period transients), in addition to mitigating ISM foregrounds in Galactic and extragalactic studies. We use a sample of 171 precise pulsar distances, based entirely on parallaxes and globular cluster associations, as well as scattering measurements of 568 pulsars, active galactic nuclei, and masers, to update the NE2001 Galactic electron density model. We refit the thick and thin disks and three of the spiral arms. The new parameters for these large-scale components significantly repartition free electrons between the thick disk and spiral arms, thereby correcting NE2001&#39;s systematic underestimation of pulsar distance and scattering. Sightlines with excessive dispersion and scattering are used to identify new clumps that are added to the model, in addition to refining clumps that were already included (e.g., Cygnus, Vela, and Gum). The Galactic Center component is revised, yielding scattering time predictions that are $10^3$ times smaller than the Galactic Center in NE2001. The updated model, NE2025, provides a factor of $20\times$ improvement in median distance prediction accuracy and $100\%$ median improvement in scattering predictions based on DM, relative to NE2001. There is a $15\times$ improvement in median distance prediction accuracy relative to YMW16. NE2025 is available on Github and the Python Package Interface.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.11838" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.11838" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.11838" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">22. Predicting LLM Output Length via Entropy-Guided Representations
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Huanyi Xie, Yubin Chen, Liangyu Wang, Lijie Hu, Di Wang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> ForeLen utilizes internal hidden states and entropy-guided pooling to predict sequence lengths in real-time, effectively reducing computational waste from padding in large language model serving. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The long-tailed distribution of sequence lengths in LLM serving and reinforcement learning (RL) sampling causes significant computational waste due to excessive padding in batched inference. Existing methods rely on auxiliary models for static length prediction, but they incur high overhead, generalize poorly, and fail in stochastic &#34;one-to-many&#34; sampling scenarios. We introduce a lightweight framework that reuses the main model&#39;s internal hidden states for efficient length prediction. Our framework features two core components: 1) Entropy-Guided Token Pooling (EGTP), which uses on-the-fly activations and token entropy for highly accurate static prediction with negligible cost, and 2) Progressive Length Prediction (PLP), which dynamically estimates the remaining length at each decoding step to handle stochastic generation. To validate our approach, we build and release ForeLen, a comprehensive benchmark with long-sequence, Chain-of-Thought, and RL data. On ForeLen, EGTP achieves state-of-the-art accuracy, reducing MAE by 29.16\% over the best baseline. Integrating our methods with a length-aware scheduler yields significant end-to-end throughput gains. Our work provides a new technical and evaluation baseline for efficient LLM inference.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.11812" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.11812" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.11812" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling / representation learning, generative models, neural architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">23. Time delays and stationarity in quasar light curves
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Namu Kroupa, David Yallup, Will Handley</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A fully Bayesian framework employing marginalized Gaussian processes distinguishes between deterministic drift and stochastic variability to provide robust time delay estimates and stationarity tests for quasar light curves. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We present a fully Bayesian framework for time delay inference and stationarity tests in quasar light curves using marginalised Gaussian processes. The model separates a deterministic, non-stationary drift (piecewise linear mean) from stationary stochastic variability (Matérn and Spectral Mixture kernels), and jointly models multiple images with per-image microlensing. Bayesian evidence and parameter posteriors are obtained via nested sampling and marginalised over model choices. Applied to the quasars WFI J2033 - 4723, B 1608 + 656, and HE 0435 - 1223, we find strong evidence for non-stationarity in B 1608 + 656 and HE 0435 - 1223, while WFI J2033 - 4723 is consistent with stationarity. The stochastic component favours an Markovian exponential kernel for B 1608 + 656 and a non-Markovian Matérn-$\frac32$ kernel for WFI J2033 - 4723 and HE 0435 - 1223. Multi-length-scale Spectral Mixture kernels are disfavoured. Time delays are shown to be robust to model assumptions and consistent with prior work within the error. We further identify and mitigate a likelihood pathology which biases toward large delays, providing a practical nested sampling convergence protocol.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.11264" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.11264" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.11264" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.01</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">24. First statistical constraints on galactic scale outflows properties traced by their extended Mg II emission with MUSE
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Ismael Pessa, Lutz Wisotzki, Tanya Urrutia, Nicolas F. Bouché, Floriane Leclercq, Ramona Augustin, Yucheng Guo, Daria Kozlova, Haruka Kusakabe, John Pharo</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Population-level analysis of circumgalactic MgII emission reveals that star-formation-driven outflows accelerate radially, with velocities and spatial extents that correlate with host galaxy stellar mass and star formation rates. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Galaxies evolve within vast gaseous halos that fuel star formation and carry signatures of feedback-driven outflows. Deep integral field data have enabled the study of MgII halos, which trace galaxy-scale outflows in emission, but their faintness has limited studies to single-object analyses. Here, we present the first statistical study of MgII-emitting halos using deep MUSE observations of 47 star-forming galaxies at $0.7&lt;z&lt;2.0$. Building on our previous work, where we developed and applied an outflow modeling framework for a single MgII halo, we now extend this approach to a larger sample, enabling robust population-level insights on the properties of circumgalactic outflows traced by their extended MgII emission. We detect extended emission out to tens of kiloparsecs and model the outflows as an ensemble of radially accelerating shells. Galaxies with MgII outflows tend to have higher SFRs, sSFRs, and younger stellar populations, consistent with star-formation-driven winds. The observations are consistent with winds that accelerate linearly with radius, from launching velocities of ~60 km/s up to maximum velocities that correlate with stellar mass and reach ~490 km/s. Their inner regions are highly opaque, and we find a tentative trend between stellar mass and central optical depth. The opening angle of the outflow shows some dependency on the host-galaxy stellar mass, with less massive galaxies showing primarily wide opening angles, and more massive galaxies showing a broader range of values, with both wide and narrow opening angles. The distribution of the spatial extent of MgII halos exhibits a clear peak at half-light radius (HLR) of ~5 kpc, with an extended tail of larger HLR values, up to ~20 kpc. Compact halo sizes (HLR $&lt; 8$ kpc) correlate with stellar mass, but extended halos do not, which could suggest a difference in the powering mechanism between compact and extended halos.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.11280" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.11280" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.11280" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: weak lensing, galaxy clustering, cosmological constraints / galaxy-halo connection, weak lensing, clustering</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">25. Stop Unnecessary Reflection: Training LRMs for Efficient Reasoning with Adaptive Reflection and Length Coordinated Penalty
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Zewei Yu, Lirong Gao, Yuke Zhu, Bo Zheng, Sheng Guo, Haobo Wang, Junbo Zhao</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The Adaptive Reflection and Length Coordinated Penalty framework improves the efficiency of large reasoning models by dynamically penalizing redundant self-reflection and excessive chain-of-thought length based on problem complexity. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Large Reasoning Models (LRMs) have demonstrated remarkable performance on complex reasoning tasks by employing test-time scaling. However, they often generate over-long chains-of-thought that, driven by substantial reflections such as repetitive self-questioning and circular reasoning, lead to high token consumption, substantial computational overhead, and increased latency without improving accuracy, particularly in smaller models. Our observation reveals that increasing problem complexity induces more excessive and unnecessary reflection, which in turn reduces accuracy and increases token overhead. To address this challenge, we propose Adaptive Reflection and Length Coordinated Penalty (ARLCP), a novel reinforcement learning framework designed to dynamically balance reasoning efficiency and solution accuracy. ARLCP introduces two key innovations: (1) a reflection penalty that adaptively curtails unnecessary reflective steps while preserving essential reasoning, and (2) a length penalty calibrated to the estimated complexity of the problem. By coordinating these penalties, ARLCP encourages the model to generate more concise and effective reasoning paths. We evaluate our method on five mathematical reasoning benchmarks using DeepSeek-R1-Distill-Qwen-1.5B and DeepSeek-R1-Distill-Qwen-7B models. Experimental results show that ARLCP achieves a superior efficiency-accuracy trade-off compared to existing approaches. For the 1.5B model, it reduces the average response length by 53.1% while simultaneously improving accuracy by 5.8%. For the 7B model, it achieves a 35.0% reduction in length with a 2.7% accuracy gain. The code is released at https://github.com/ZeweiYu1/ARLCP .</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.12113" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.12113" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.12113" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling / representation learning, generative models, neural architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">26. SAM3-LiteText: An Anatomical Study of the SAM3 Text Encoder for Efficient Vision-Language Segmentation
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Chengxi Zeng, Yuxuan Jiang, Ge Gao, Shuai Wang, Duolikun Danier, Bin Zhu, Stevan Rudinac, David Bull, Fan Zhang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> SAM3-LiteText optimizes vision-language segmentation by replacing over-provisioned text encoders with compact, distilled models, drastically reducing memory footprint while maintaining visual grounding accuracy. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Vision-language segmentation models such as SAM3 enable flexible, prompt-driven visual grounding, but inherit large, general-purpose text encoders originally designed for open-ended language understanding. In practice, segmentation prompts are short, structured, and semantically constrained, leading to substantial over-provisioning in text encoder capacity and persistent computational and memory overhead. In this paper, we perform a large-scale anatomical analysis of text prompting in vision-language segmentation, covering 404,796 real prompts across multiple benchmarks. Our analysis reveals severe redundancy: most context windows are underutilized, vocabulary usage is highly sparse, and text embeddings lie on low-dimensional manifold despite high-dimensional representations. Motivated by these findings, we propose SAM3-LiteText, a lightweight text encoding framework that replaces the original SAM3 text encoder with a compact MobileCLIP student that is optimized by knowledge distillation. Extensive experiments on image and video segmentation benchmarks show that SAM3-LiteText reduces text encoder parameters by up to 88%, substantially reducing static memory footprint, while maintaining segmentation performance comparable to the original model. Code: https://github.com/SimonZeng7108/efficientsam3/tree/sam3_litetext.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.12173" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.12173" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.12173" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling / representation learning, generative models, neural architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">27. Revis: Sparse Latent Steering to Mitigate Object Hallucination in Large Vision-Language Models
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Jialin Wu, Wei Shi, Han Shen, Peigui Qi, Kunsheng Tang, Zhicong Huang, Binghao Wang, Zhou Yang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> REVIS reduces object hallucination in vision-language models through a training-free latent space intervention that re-activates suppressed visual information using sparse orthogonal projections. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Despite the advanced capabilities of Large Vision-Language Models (LVLMs), they frequently suffer from object hallucination. One reason is that visual features and pretrained textual representations often become intertwined in the deeper network layers. To address this, we propose REVIS, a training-free framework designed to explicitly re-activate this suppressed visual information. Rooted in latent space geometry, REVIS extracts the pure visual information vector via orthogonal projection and employs a calibrated strategy to perform sparse intervention only at the precise depth where suppression occurs. This surgical approach effectively restores visual information with minimal computational cost. Empirical evaluations on standard benchmarks demonstrate that REVIS reduces object hallucination rates by approximately 19% compared to state-of-the-art baselines, while preserving general reasoning capabilities.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.11824" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.11824" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.11824" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling / representation learning, generative models, neural architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">28. Using astrochemical models to simulate reactivity experiments on cold surfaces
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Valeriia Sokolova, Basile Husquinet, Stephan Diana, Paola Caselli, Emanuele Congiu, Wiebke Riedel, Olli Sipila, Anton Vasyunin, Valentine Wakelam, Francois Dulieu</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Benchmarking astrochemical codes against laboratory CO hydrogenation experiments validates the use of rate-equation models for reproducing solid-state molecular synthesis while identifying key differences in physical process descriptions. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The development of molecular complexity during stellar and planetary formation owes much to the interaction of gas and dust. When the first astrochemical models including solid-state chemistry were developed more than forty years ago, data from dedicated laboratory experiments were limited. Since then, many groups have developed specific experimental setups to address this issue, but astrochemical models have rarely been directly confronted with these new results. We want to demonstrate whether it is possible to use rate-equation-type astrochemical models developed in the context of the Interstellar Medium to compare them with laboratory astrophysics experiments. In this work, we use the case of low-temperature hydrogenation of CO, which is known to lead to methanol, among other molecules. We carried out 9 experiments, varying the experimental parameters such as temperature and dose. We give quantitative results and take care of detailing the vocabulary used in the experiments. We use astrochemical codes, NAUTILUS, pyRate and MONACO, to reproduce our experimental conditions, which requires good control of the change of vocabulary and scales, especially for fluxes and time scales. This work demonstrates that it is possible to use different astrochemical codes to compare modelling results directly with the output of experiments. There are discrepancies between models and experiments, as well as between models, but a fair agreement is achieved. We discuss the possible origin of the differences, which could originate from the chemical network or the difference in the description of physical processes.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.11347" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.11347" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.11347" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">29. Tiny Recursive Reasoning with Mamba-2 Attention Hybrid
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Wenlong Wang, Fergal Reid</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Replacing Transformer blocks with Mamba-2 hybrid operators in recursive reasoning scaffolds enhances solution reliability on abstract reasoning tasks, demonstrating the effectiveness of state-space models for latent iterative refinement. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Recent work on recursive reasoning models like TRM demonstrates that tiny networks (7M parameters) can achieve strong performance on abstract reasoning tasks through latent recursion -- iterative refinement in hidden representation space without emitting intermediate tokens. This raises a natural question about operator choice: Mamba-2&#39;s state space recurrence is itself a form of iterative refinement, making it a natural candidate for recursive reasoning -- but does introducing Mamba-2 into the recursive scaffold preserve reasoning capability? We investigate this by replacing the Transformer blocks in TRM with Mamba-2 hybrid operators while maintaining parameter parity (6.83M vs 6.86M parameters). On ARC-AGI-1, we find that the hybrid improves pass@2 (the official metric) by +2.0\% (45.88\% vs 43.88\%) and consistently outperforms at higher K values (+4.75\% at pass@100), whilst maintaining pass@1 parity. This suggests improved candidate coverage -- the model generates correct solutions more reliably -- with similar top-1 selection. Our results validate that Mamba-2 hybrid operators preserve reasoning capability within the recursive scaffold, establishing SSM-based operators as viable candidates in the recursive operator design space and taking a first step towards understanding the best mixing strategies for recursive reasoning.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.12078" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.12078" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.12078" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling / representation learning, generative models, neural architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">30. Detecting RLVR Training Data via Structural Convergence of Reasoning
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Hongbo Zhang, Yue Yang, Jianhao Yan, Guangsheng Bao, Yue Zhang, Yue Zhang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Min-kNN Distance detects benchmark contamination in reinforcement-learned reasoning models by measuring the collapse in generation diversity that occurs when a model processes previously seen training prompts. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Reinforcement learning with verifiable rewards (RLVR) is central to training modern reasoning models, but the undisclosed training data raises concerns about benchmark contamination. Unlike pretraining methods, which optimize models using token-level probabilities, RLVR fine-tunes models based on reward feedback from self-generated reasoning trajectories, making conventional likelihood-based detection methods less effective. We show that RLVR induces a distinctive behavioral signature: prompts encountered during RLVR training result in more rigid and similar generations, while unseen prompts retain greater diversity. We introduce Min-$k$NN Distance, a simple black-box detector that quantifies this collapse by sampling multiple completions for a given prompt and computing the average of the $k$ smallest nearest-neighbor edit distances. Min-$k$NN Distance requires no access to the reference model or token probabilities. Experiments across multiple RLVR-trained reasoning models show that Min-$k$NN Distance reliably distinguishes RL-seen examples from unseen ones and outperforms existing membership inference and RL contamination detection baselines.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.11792" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.11792" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.11792" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling / representation learning, generative models, neural architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">31. Dark matter distributions around extreme mass ratio inspirals: effects of radial pressure and relativistic treatment
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Yang Zhao, Yungui Gong</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Incorporating radial pressure and relativistic effects into dark matter density profiles significantly alters the orbital evolution and gravitational wave signatures of extreme mass ratio inspirals, highlighting the necessity of sophisticated modeling for accurate detection. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We investigate different treatments of dark matter (DM) distributions surrounding extreme mass ratio inspirals (EMRIs) to assess their impact on orbital evolution and gravitational wave emission. Density profiles derived from the mass current and from the energy-momentum tensor using a distribution function yield consistent results, but both differ substantially from profiles obtained using an anisotropic fluid model based on Einstein cluster ansatz. We find that the inclusion of radial pressure significantly modifies both the orbital dynamics and the resulting gravitational wave waveforms. By analyzing waveform dephasing and mismatches, we show that a fully relativistic treatment of DM distributions can substantially alter the detectability thresholds of DM halos. Our results demonstrate that radial pressure and relativistic modeling of DM are essential for accurately describing the dynamics and observational signatures of EMRIs embedded in DM halos.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.12022" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.12022" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.12022" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">gr-qc</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">32. SemaPop: Semantic-Persona Conditioned Population Synthesis
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Zhenlin Qin, Yancheng Ling, Leizhen Wang, Francisco Câmara Pereira, Zhenliang Ma</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Integrating large language models with generative adversarial networks enables the synthesis of synthetic populations that simultaneously satisfy statistical marginal constraints and capture complex behavioral semantics from survey data. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Population synthesis is a critical component of individual-level socio-economic simulation, yet remains challenging due to the need to jointly represent statistical structure and latent behavioral semantics. Existing population synthesis approaches predominantly rely on structured attributes and statistical constraints, leaving a gap in semantic-conditioned population generation that can capture abstract behavioral patterns implicitly in survey data. This study proposes SemaPop, a semantic-statistical population synthesis model that integrates large language models (LLMs) with generative population modeling. SemaPop derives high-level persona representations from individual survey records and incorporates them as semantic conditioning signals for population generation, while marginal regularization is introduced to enforce alignment with target population marginals. In this study, the framework is instantiated using a Wasserstein GAN with gradient penalty (WGAN-GP) backbone, referred to as SemaPop-GAN. Extensive experiments demonstrate that SemaPop-GAN achieves improved generative performance, yielding closer alignment with target marginal and joint distributions while maintaining sample-level feasibility and diversity under semantic conditioning. Ablation studies further confirm the contribution of semantic persona conditioning and architectural design choices to balancing marginal consistency and structural realism. These results demonstrate that SemaPop-GAN enables controllable and interpretable population synthesis through effective semantic-statistical information fusion. SemaPop-GAN also provides a promising modular foundation for developing generative population projection systems that integrate individual-level behavioral semantics with population-level statistical constraints.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.11569" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.11569" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.11569" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling / representation learning, generative models, neural architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">33. Efficient parallel finite-element methods for planetary gravitation: DtN and multipole expansions
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Ziheng Yu, Alex D. C. Myhill, David Al-Attar</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Dirichlet-to-Neumann maps and multipole expansions provide superior accuracy and computational efficiency compared to domain truncation for solving the Poisson equation in large-scale parallel finite-element simulations of planetary gravitational fields. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The Poisson equation governing a planet&#39;s gravitational field is posed on the unbounded domain, $\mathbb{R}^3$, whereas finite-element computations require bounded meshes. We implement and compare three strategies for handling the infinite exterior in the finite-element method: (i) naive domain truncation; (ii) Dirichlet-to-Neumann (DtN) map on a truncated boundary; (iii) multipole expansion on a truncated boundary. While all these methods are known within the geophysical literature, we discuss their parallel implementations within modern open-source finite-element codes, focusing specifically on the widely-used MFEM package. We consider both calculating the gravitational potential for a static density structure and computing the linearised perturbation to the potential caused by a displacement field - a necessary step for coupling self-gravitation into planetary dynamics. In contrast to some earlier studies, we find that the domain truncation method can provide accurate solutions at an acceptable cost, with suitable coarsening of the mesh within the exterior domain. Nevertheless, the DtN and multipole methods provide superior accuracy at a lower cost within large-scale parallel geophysical simulations despite their need for non-local communication associated with spherical harmonic expansions. The DtN method, in particular, admits an efficient parallel implementation based on an MPI-communicator limited to processors that contain part of the mesh&#39;s outer boundary. A series of further illustrative calculations are provided to show the potential of the DtN and multipole methods within realistic geophysical modelling.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.12075" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.12075" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.12075" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">astro-ph.EP</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">34. MAPLE: Modality-Aware Post-training and Learning Ecosystem
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Nikhil Verma, Minjung Kim, JooYoung Yoo, Kyung-Min Jin, Manasa Bharadwaj, Kevin Ferreira, Ko Keun Kim, Youngjoon Kim</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Modality-aware policy optimization and curriculum scheduling within the MAPLE ecosystem enhance the convergence speed and robustness of multimodal language models by accounting for the specific signal requirements of diverse tasks. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Multimodal language models now integrate text, audio, and video for unified reasoning. Yet existing RL post-training pipelines treat all input signals as equally relevant, ignoring which modalities each task actually requires. This modality-blind training inflates policy-gradient variance, slows convergence, and degrades robustness to real-world distribution shifts where signals may be missing, added, or reweighted. We introduce MAPLE, a complete modality-aware post-training and learning ecosystem comprising: (1) MAPLE-bench, the first benchmark explicitly annotating minimal signal combinations required per task; (2) MAPO, a modality-aware policy optimization framework that stratifies batches by modality requirement to reduce gradient variance from heterogeneous group advantages; (3) Adaptive weighting and curriculum scheduling that balances and prioritizes harder signal combinations. Systematic analysis across loss aggregation, clipping, sampling, and curriculum design establishes MAPO&#39;s optimal training strategy. Adaptive weighting and curriculum focused learning further boost performance across signal combinations. MAPLE narrows uni/multi-modal accuracy gaps by 30.24%, converges 3.18x faster, and maintains stability across all modality combinations under realistic reduced signal access. MAPLE constitutes a complete recipe for deployment-ready multimodal RL post-training.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.11596" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.11596" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.11596" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling / representation learning, generative models, neural architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">35. Time-Structured Tail Probabilities for Ultra-High-Energy Gamma-Hadron Discrimination in Water-Cherenkov Arrays
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Ruben Conceição, Pedro J. Costa, Mário Pimenta</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Utilizing the time-resolved structure of signal tails in water-Cherenkov detector traces significantly improves gamma-hadron discrimination for ultra-high-energy photon searches, achieving performance near that of idealized muon-counting methods. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Gamma-hadron discrimination based on shower observables is essential for identifying gamma-ray astrophysical sources at the highest energies. In this work, we introduce $P^{α, T}_{\rm tail}$, a new discrimination variable for ultra-high-energy photon searches within the framework of a water-Cherenkov detector (WCD) array. The observable extends signal-integrated methods by incorporating the time structure of WCD traces, using cumulative signal distributions. Using simulated proton- and gamma-induced air showers at energies around $10^{17}\,\mathrm{eV}$, we evaluate the performance of $P^{α, T}_{\rm tail}$ and compare it with established WCD-based observables such as $S_b$, risetime-based variables, and the SWGO-inspired, $P^α_{\rm tail}$. The new variable attains a background contamination of roughly $2 \times 10^{-2}$ at $50\%$ gamma efficiency, improving upon existing WCD-only methods by nearly a factor of five and approaching the performance of an idealized muon-isolating reference. These results demonstrate the effectiveness of exploiting time-resolved signal tails to enhance ultra-high-energy photon searches in sparse surface arrays.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.12167" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.12167" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.12167" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">hep-ph</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">36. Black Holes Trapped by Ghosts
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Cheng-Yong Zhang, Yunqi Liu, Bin Wang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Identification of a nonlinear phase space bottleneck controlled by a saddle-node ghost reveals a universal quiescence-burst signature that delays the onset of linear ringdown in relaxing black hole remnants and other compact objects. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Violent cosmic events, from black hole mergers to stellar collapses, often leave behind highly excited black hole remnants that inevitably relax to equilibrium. The prevailing view, developed over decades, holds that this relaxation is rapidly filtered into a linear regime, establishing linear perturbation theory as the bedrock of black hole spectroscopy and a key pillar of gravitational-wave physics. Here we unveil a distinct nonlinear regime that transcends the traditional paradigm: before the familiar linear ringdown, an intrinsically nonlinear, long-lived bottleneck can dominate the evolution. This stage is controlled by a saddle-node ghost in phase space, which traps the remnant and delays the onset of linearity by a timescale obeying a universal power-law. The ghost imprints a distinctive quiescence-burst signature on the emitted radiation: a prolonged silence followed by a violent burst and a delayed ringdown. Rooted in the bifurcation topology, it extends naturally to neutron and boson stars, echoing a topological universality shared with diverse nonlinear systems in nature. Our results expose a missing nonlinear chapter in gravitational dynamics and identify ghost-induced quiescence-burst patterns as clear targets for future observations.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.12101" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.12101" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.12101" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">gr-qc</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">37. TSR: Trajectory-Search Rollouts for Multi-Turn RL of LLM Agents
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Aladin Djuhera, Swanand Ravindra Kadhe, Farhan Ahmed, Holger Boche</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Implementing lightweight tree-style search during the rollout phase of reinforcement learning improves the quality of multi-turn agent trajectories and stabilizes training across diverse stochastic environments. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Advances in large language models (LLMs) are driving a shift toward using reinforcement learning (RL) to train agents from iterative, multi-turn interactions across tasks. However, multi-turn RL remains challenging as rewards are often sparse or delayed, and environments can be stochastic. In this regime, naive trajectory sampling can hinder exploitation and induce mode collapse. We propose TSR (Trajectory-Search Rollouts), a training-time approach that repurposes test-time scaling ideas for improved per-turn rollout generation. TSR performs lightweight tree-style search to construct high-quality trajectories by selecting high-scoring actions at each turn using task-specific feedback. This improves rollout quality and stabilizes learning while leaving the underlying optimization objective unchanged, making TSR optimizer-agnostic. We instantiate TSR with best-of-N, beam, and shallow lookahead search, and pair it with PPO and GRPO, achieving up to 15% performance gains and more stable learning on Sokoban, FrozenLake, and WebShop tasks at a one-time increase in training compute. By moving search from inference time to the rollout stage of training, TSR provides a simple and general mechanism for stronger multi-turn agent learning, complementary to existing frameworks and rejection-sampling-style selection methods.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.11767" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.11767" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.11767" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling / representation learning, generative models, neural architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">38. Estimation of instrument and noise parameters for inverse problem based on prior diffusion model
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Jean-François Giovannelli</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Leveraging diffusion processes as priors within a Bayesian framework enables the efficient joint estimation of observation parameters and images in inverse problems while providing robust uncertainty quantification through Markov Chain Monte Carlo sampling. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">This article addresses the issue of estimating observation parameters (response and error parameters) in inverse problems. The focus is on cases where regularization is introduced in a Bayesian framework and the prior is modeled by a diffusion process. In this context, the issue of posterior sampling is well known to be thorny, and a recent paper proposes a notably simple and effective solution. Consequently, it offers an remarkable additional flexibility when it comes to estimating observation parameters. The proposed strategy enables us to define an optimal estimator for both the observation parameters and the image of interest. Furthermore, the strategy provides a means of quantifying uncertainty. In addition, MCMC algorithms allow for the efficient computation of estimates and properties of posteriors, while offering some guarantees. The paper presents several numerical experiments that clearly confirm the computational efficiency and the quality of both estimates and uncertainties quantification.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.11711" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.11711" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.11711" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">stat.ML</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">39. On the numerical evaluation of the `exact&#39; Post-Newtonian parameters in Brans-Dicke and Entangled Relativity theories
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Thomas Chehab, Olivier Minazzoli</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Numerical analysis of exact post-Newtonian parameters in scalar-tensor theories reveals that internal stellar structure significantly influences gravitational deviations, offering potential pathways to constrain Entangled Relativity through solar system and compact object observations. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">In context of Brans-Dicke scalar-tensor theories of gravity, it has recently been obtained that the post-Newtonian parameters should be generalized in the context of strongly gravitating bodies, and that its generalization -- the so-called $\textit{exact parameters}$ -- actually depends on the pressure and energy density of a considered celestial body. Here we develop two new methods to numerically obtain the $\textit{exact parameters}$ by means of usual Tolman-Oppenheimer-Volkoff computation, and find that the difference with the value of standard post-Newtonian parameters can be more than 80% in some situations. We also provide the connection with the Damour-Esposito Farèse non-pertubative parameter $α_{DEF}$. We then apply the methodology to the case of Entangled Relativity, and derive these exact parameters for the Sun and the Earth, as well as for neutron stars. We argue that current and foreseeable experiments are likely able to constrain the theory under the assumption that $\mathcal{L}_m=-ρ$, where $ρ$ is the total energy density. If $\mathcal{L}_m=T$ instead, as often advocated in the literature, then there is no deviation with respect to General Relativity and the prospects of testing Entangled Relativity become much more remote in time, as only compact objects with extreme electric or magnetic fields could lead to some deviation from General Relativity.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.11811" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.11811" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.11811" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">gr-qc</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">40. A study of charged-particle multiplicity distribution in high energy p-O collisions
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Yuri N. Lima, Lucas J. F. Silva, Andre V. Giannini, Marcelo G. Munhoz</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Comparisons between alpha-cluster and Woods-Saxon nuclear models in proton-oxygen collisions demonstrate that initial geometric configurations and choice of computational formalism significantly influence the predicted multiplicity distributions of charged particles. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">This study investigates the multiplicity distribution of charged particles generated in $p$-O collisions, employing Pythia (Angantyr) and $k_T$-factorization approach. Oxygen nucleus configurations are sampled using a $α$-cluster model to evaluate both formalisms and assess how initial nucleus configuration influences the properties of the produced final states. Results obtained through clustering are systematically compared to those derived from the Woods-Saxon nuclear distribution. The analysis encompasses various pseudorapidity intervals ($|η|&lt;$ 0.5, 1.0, 2.0, 3.0) and center-of-mass energies ($\sqrt{s}=$ 2.36, 5.02, 7.0, 13.0 TeV). Based on the resulting distributions, we examine the KNO scaling effect and fit the distributions with the double NBD model for parameterization, aiming to accurately characterize the observed results and elucidate contributions from both soft and semi-hard processes. Our results indicate that different geometric descriptions of the oxygen nucleus project significantly different multiplicities of charged particles, especially for large multiplicities and higher pseudorapidity. We also observed that multiplicity of charged particles calculated with Pythia reveals significantly different behavior from that calculated with $k_T$-factorization.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.11452" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.11452" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.11452" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">hep-ph</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">41. InjectRBP: Steering Large Language Model Reasoning Behavior via Pattern Injection
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Xiuping Wu, Zhao Yu, Yuxin Cheng, Ngai Wong, Liangjun Ke, Tapas Mishra, Konstantinos V. Katsikopoulos</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Enhancing large language model reasoning involves injecting behavioral patterns derived from past successes or learned value functions into the inference process, yielding significant performance gains without parameter fine-tuning. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Reasoning can significantly enhance the performance of Large Language Models. While recent studies have exploited behavior-related prompts adjustment to enhance reasoning, these designs remain largely intuitive and lack a systematic analysis of the underlying behavioral patterns. Motivated by this, we investigate how models&#39; reasoning behaviors shape reasoning from the perspective of behavioral patterns. We observe that models exhibit adaptive distributions of reasoning behaviors when responding to specific types of questions, and that structurally injecting these patterns can substantially influence the quality of the models&#39; reasoning processes and outcomes. Building on these findings, we propose two optimization methods that require no parameter updates: InjectCorrect and InjectRLOpt. InjectCorrect guides the model by imitating behavioral patterns derived from its own past correct answers. InjectRLOpt learns a value function from historical behavior-pattern data and, via our proposed Reliability-Aware Softmax Policy, generates behavioral injectant during inference to steer the reasoning process. Our experiments demonstrate that both methods can improve model performance across various reasoning tasks without requiring any modifications to model parameters, achieving gains of up to 5.34% and 8.67%, respectively.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.12013" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.12013" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.12013" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling / representation learning, generative models, neural architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">42. Characterising Ly$α$ damping wings at the onset of reionisation: Evidence for highly efficient star formation driven by dense, neutral gas in UV-bright galaxies at $z&gt;9$
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">Clara L. Pollock, Kasper E. Heintz, Joris Witstok, Rashmi Gottumukkala, Gabriel Brammer, Sownak Bose, Alex J. Cameron, Pratika Dayal, Pieter van Dokkum, Johan Fynbo, et al.</span>
                                <span class="author-full" style="display: none;">Clara L. Pollock, Kasper E. Heintz, Joris Witstok, Rashmi Gottumukkala, Gabriel Brammer, Sownak Bose, Alex J. Cameron, Pratika Dayal, Pieter van Dokkum, Johan Fynbo, Viola Gelli, Matthew J. Hayes, Akio K. Inoue, Claudia del P. Lagos, Peter Laursen, Romain A. Meyer, Rohan Naidu, Pascal Oesch, Lucie E. Rowland, Nial R. Tanvir, Sandro Tacchella, Chamilla Terp, Francesco Valentino, Fabian Walter, John Weaver, Callum Witten</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Spectroscopic analysis of high-redshift galaxies reveals that exceptionally efficient star formation driven by dense neutral hydrogen gas, combined with minimal dust obscuration, accounts for the observed overabundance of UV-bright sources at cosmic dawn. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">One of the major conundrums in contemporary extragalactic astrophysics is the apparent overabundance of a remarkable population of UV-bright galaxies at redshifts $z\gtrsim 9$. We analyse galaxies spectroscopically observed by JWST/NIRSpec Prism and confirmed to lie at $z&gt;9$, with sufficient signal-to-noise to carefully model their rest-frame UV to optical continua and line emission. In particular, we model the damped Lyman-$α$ (Ly$α$) absorption (DLA) features of each galaxy to place observational constraints on the gas assembly of neutral atomic hydrogen (HI) onto the galaxy halos at the onset of cosmic reionisation. Based on the derived HI column densities and star-formation rate (SFR) surface densities, we show that all galaxies are highly efficient at forming stars on rapid $\sim 10-100\,$Myr depletion timescales, greatly in excess compared to the canonical local universe Kennicutt-Schmidt relation and predictions from state-of-the-art galaxy formation simulations. The dense HI gas appears to also drive the offset from the fundamental-metallicity relation of these galaxies though its dust-to-gas ratio is seemingly consistent with values derived for local galaxies except for the lowest metallicity sight-lines. Our results provide the first robust observational constraints on the impact of pristine HI gas on early galaxy assembly, and imply that a combination of highly efficient star formation and low dust obscuration can likely explain the UV-brightness of galaxies at cosmic dawn.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.11783" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.11783" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.11783" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: weak lensing, galaxy clustering, cosmological constraints / galaxy-halo connection, weak lensing, clustering</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">43. Provable Offline Reinforcement Learning for Structured Cyclic MDPs
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Kyungbok Lee, Angelica Cristello Sarteau, Michael R. Kosorok</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A modular cyclic Markov decision process framework addresses stage-specific dynamics and distribution mismatch in multi-step decision problems by decomposing the process into independently optimizable sub-problems using a vector of stage-tailored Q-functions. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We introduce a novel cyclic Markov decision process (MDP) framework for multi-step decision problems with heterogeneous stage-specific dynamics, transitions, and discount factors across the cycle. In this setting, offline learning is challenging: optimizing a policy at any stage shifts the state distributions of subsequent stages, propagating mismatch across the cycle. To address this, we propose a modular structural framework that decomposes the cyclic process into stage-wise sub-problems. While generally applicable, we instantiate this principle as CycleFQI, an extension of fitted Q-iteration enabling theoretical analysis and interpretation. It uses a vector of stage-specific Q-functions, tailored to each stage, to capture within-stage sequences and transitions between stages. This modular design enables partial control, allowing some stages to be optimized while others follow predefined policies. We establish finite-sample suboptimality error bounds and derive global convergence rates under Besov regularity, demonstrating that CycleFQI mitigates the curse of dimensionality compared to monolithic baselines. Additionally, we propose a sieve-based method for asymptotic inference of optimal policy values under a margin condition. Experiments on simulated and real-world Type 1 Diabetes data sets demonstrate CycleFQI&#39;s effectiveness.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.11679" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.11679" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.11679" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">stat.ML</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling / representation learning, generative models, neural architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">44. The Pensieve Paradigm: Stateful Language Models Mastering Their Own Context
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Xiaoyuan Liu, Tian Liang, Dongyang Ma, Deyu Zhou, Haitao Mi, Pinjia He, Yan Wang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Integrating an internal reasoning loop and autonomous memory management tools into foundation models enables dynamic context engineering, allowing agents to surpass fixed context window limitations and improve performance on complex, long-form tasks. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">In the world of Harry Potter, when Dumbledore&#39;s mind is overburdened, he extracts memories into a Pensieve to be revisited later. In the world of AI, while we possess the Pensieve-mature databases and retrieval systems, our models inexplicably lack the &#34;wand&#34; to operate it. They remain like a Dumbledore without agency, passively accepting a manually engineered context as their entire memory. This work finally places the wand in the model&#39;s hand. We introduce StateLM, a new class of foundation models endowed with an internal reasoning loop to manage their own state. We equip our model with a suite of memory tools, such as context pruning, document indexing, and note-taking, and train it to actively manage these tools. By learning to dynamically engineering its own context, our model breaks free from the architectural prison of a fixed window. Experiments across various model sizes demonstrate StateLM&#39;s effectiveness across diverse scenarios. On long-document QA tasks, StateLMs consistently outperform standard LLMs across all model scales; on the chat memory task, they achieve absolute accuracy improvements of 10% to 20% over standard LLMs. On the deep research task BrowseComp-Plus, the performance gap becomes even more pronounced: StateLM achieves up to 52% accuracy, whereas standard LLM counterparts struggle around 5%. Ultimately, our approach shifts LLMs from passive predictors to state-aware agents where reasoning becomes a stateful and manageable process.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.12108" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.12108" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.12108" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling / representation learning, generative models, neural architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">45. Aggregate Models, Not Explanations: Improving Feature Importance Estimation
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Joseph Paillard, Angel Reyero Lobo, Denis A. Engemann, Bertrand Thirion</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Theoretical and empirical evidence suggests that performing ensembling at the model level rather than the explanation level minimizes excess risk and produces more stable, accurate feature-importance estimates for complex machine learning architectures. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Feature-importance methods show promise in transforming machine learning models from predictive engines into tools for scientific discovery. However, due to data sampling and algorithmic stochasticity, expressive models can be unstable, leading to inaccurate variable importance estimates and undermining their utility in critical biomedical applications. Although ensembling offers a solution, deciding whether to explain a single ensemble model or aggregate individual model explanations is difficult due to the nonlinearity of importance measures and remains largely understudied. Our theoretical analysis, developed under assumptions accommodating complex state-of-the-art ML models, reveals that this choice is primarily driven by the model&#39;s excess risk. In contrast to prior literature, we show that ensembling at the model level provides more accurate variable-importance estimates, particularly for expressive models, by reducing this leading error term. We validate these findings on classical benchmarks and a large-scale proteomic study from the UK Biobank.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.11760" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.11760" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.11760" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">stat.ML</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">46. Quark Medical Alignment: A Holistic Multi-Dimensional Alignment and Collaborative Optimization Paradigm
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">Tianxiang Xu, Jiayi Liu, Yixuan Tong, Jialu Xu, Yunqing Wei, Kaiwen Feng, PanPan Hou, Kangping Yin, Jiyuan Hu, Hao Zhou, et al.</span>
                                <span class="author-full" style="display: none;">Tianxiang Xu, Jiayi Liu, Yixuan Tong, Jialu Xu, Yunqing Wei, Kaiwen Feng, PanPan Hou, Kangping Yin, Jiyuan Hu, Hao Zhou, Zhenxin Ma, Jian Xu, Guanjun Jiang</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Aligning large language models for high-stakes medical applications requires a multi-dimensional matrix of expert-driven objectives and a specialized optimization framework that balances heterogeneous reward signals through adaptive weighting and scale normalization. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">While reinforcement learning for large language model alignment has progressed rapidly in recent years, transferring these paradigms to high-stakes medical question answering reveals a fundamental paradigm mismatch. Reinforcement Learning from Human Feedback relies on preference annotations that are prohibitively expensive and often fail to reflect the absolute correctness of medical facts. Reinforcement Learning from Verifiable Rewards lacks effective automatic verifiers and struggles to handle complex clinical contexts. Meanwhile, medical alignment requires the simultaneous optimization of correctness, safety, and compliance, yet multi-objective heterogeneous reward signals are prone to scale mismatch and optimization conflicts.To address these challenges, we propose a robust medical alignment paradigm. We first construct a holistic multi-dimensional medical alignment matrix that decomposes alignment objectives into four categories: fundamental capabilities, expert knowledge, online feedback, and format specifications. Within each category, we establish a closed loop of where observable metrics inform attributable diagnosis, which in turn drives optimizable rewards, thereby providing fine-grained, high-resolution supervision signals for subsequent iterative optimization. To resolve gradient domination and optimization instability problem caused by heterogeneous signals, we further propose a unified optimization mechanism. This mechanism employs Reference-Frozen Normalization to align reward scales and implements a Tri-Factor Adaptive Dynamic Weighting strategy to achieve collaborative optimization that is weakness-oriented, risk-prioritized, and redundancy-reducing. Experimental results demonstrate the effectiveness of our proposed paradigm in real-world medical scenario evaluations, establishing a new paradigm for complex alignment in vertical domains.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.11661" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.11661" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.11661" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling / representation learning, generative models, neural architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">47. RELATE: A Reinforcement Learning-Enhanced LLM Framework for Advertising Text Generation
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">Jinfang Wang, Jiajie Liu, Jianwei Wu, Ziqin Luo, Zhen Chen, Chunlei Li, Biao Han, Tao Deng, Yi Li, Shuanglong Li, et al.</span>
                                <span class="author-full" style="display: none;">Jinfang Wang, Jiajie Liu, Jianwei Wu, Ziqin Luo, Zhen Chen, Chunlei Li, Biao Han, Tao Deng, Yi Li, Shuanglong Li, Lin Liu</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Replacing the traditional two-stage advertising text pipeline with an end-to-end reinforcement learning framework allows for the simultaneous optimization of content generation, performance metrics, and compliance constraints. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">In online advertising, advertising text plays a critical role in attracting user engagement and driving advertiser value. Existing industrial systems typically follow a two-stage paradigm, where candidate texts are first generated and subsequently aligned with online performance metrics such as click-through rate(CTR). This separation often leads to misaligned optimization objectives and low funnel efficiency, limiting global optimality. To address these limitations, we propose RELATE, a reinforcement learning-based end-to-end framework that unifies generation and objective alignment within a single model. Instead of decoupling text generation from downstream metric alignment, RELATE integrates performance and compliance objectives directly into the generation process via policy learning. To better capture ultimate advertiser value beyond click-level signals, We incorporate conversion-oriented metrics into the objective and jointly model them with compliance constraints as multi-dimensional rewards, enabling the model to generate high-quality ad texts that improve conversion performance under policy constraints. Extensive experiments on large-scale industrial datasets demonstrate that RELATE consistently outperforms baselines. Furthermore, online deployment on a production advertising platform yields statistically significant improvements in click-through conversion rate(CTCVR) under strict policy constraints, validating the robustness and real-world effectiveness of the proposed framework.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.11780" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.11780" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.11780" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling / representation learning, generative models, neural architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">48. Heavy-to-light Structure Functions at $\mathcal{O}(α_s^3)$ in QCD
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Long Chen, Xiang Chen, Xin Guan, Yan-Qing Ma</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> High-order perturbative QCD corrections to heavy-to-light structure functions, calculated via a hybrid interpolation and differential equation approach, provide refined predictions for semi-leptonic heavy quark decays and improve the determination of CKM matrix elements. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We present the first complete $\mathcal{O}(α_s^2)$ and $\mathcal{O}(α_s^3)$ perturbative QCD corrections to all five heavy-to-light structure functions underlying the triple-differential semi-leptonic decay rates of heavy quarks. This is achieved via a hybrid computational strategy that combines an efficient linear interpolation (with a suitable function basis) based on stratified Gauss-Kronrod points in the leptonic-mass $q^2$ with the differential equations in the other variable, further armed with reduced numerical $\varepsilon$-dependence. Among the selected applications, we highlight the state-of-the-art prediction $Γ(B \rightarrow X_u \ell \barν_{\ell}) = \frac{|V_{ub}|^2}{|3.82\times 10^{-3}|^2}\,\big( 6.53 \,\pm 0.12 \, \pm 0.13\, \pm 0.03\, \big) \times 10^{-16}\,\text{GeV}\,$ derived in the kinetic-mass scheme. We report several notable observations regarding the convergence of the first three orders of QCD corrections to the $q^2$-spectrum and to inclusive moments of the lepton-energy spectrum in semi-leptonic weak decays of $b$- and $c$-quark in different quark-mass schemes; they are important both for improving the inclusive determinations of the relevant CKM elements, non-perturbative dynamical parameters, and for gaining new insights into the potential impact of high-order QCD corrections. Lastly we discuss a novel interesting point encountered in the consistent perturbative reformulation of the differential $q^2$-spectrum from the pole-mass to other mass schemes: certain boundary-effect terms are identified that are non-vanishing for $b \rightarrow u \ell \barν_{\ell}$ firstly at $\mathcal{O}(α_s^3)$; their incorporation is essential to preserve the integrity of the integrated moments of the perturbatively re-expanded $q^2$-spectrum but necessitates histogramming from $\mathcal{O}(α_s^3)$ onward even within pure perturbation theory.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.11879" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.11879" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.11879" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">hep-ph</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">49. Think like a Scientist: Physics-guided LLM Agent for Equation Discovery
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Jianke Yang, Ohm Venkatachalam, Mohammad Kianezhad, Sharvaree Vadgama, Rose Yu</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> An agentic framework for symbolic discovery improves equation accuracy and noise robustness by emulating the scientific method, first identifying physical symmetries and structural priors before executing constrained symbolic regression. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Explaining observed phenomena through symbolic, interpretable formulas is a fundamental goal of science. Recently, large language models (LLMs) have emerged as promising tools for symbolic equation discovery, owing to their broad domain knowledge and strong reasoning capabilities. However, most existing LLM-based systems try to guess equations directly from data, without modeling the multi-step reasoning process that scientists often follow: first inferring physical properties such as symmetries, then using these as priors to restrict the space of candidate equations. We introduce KeplerAgent, an agentic framework that explicitly follows this scientific reasoning process. The agent coordinates physics-based tools to extract intermediate structure and uses these results to configure symbolic regression engines such as PySINDy and PySR, including their function libraries and structural constraints. Across a suite of physical equation benchmarks, KeplerAgent achieves substantially higher symbolic accuracy and greater robustness to noisy data than both LLM and traditional baselines.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.12259" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.12259" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.12259" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">50. Linear Growth of Matter Perturbations Probed by Redshift-Space Distortions in Interacting $Λ(t)$CDM Cosmologies
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>A. A. Escobal, H. A. P. Macedo, J. F. Jesus, R. C. Nunes, J. A. S. Lima</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Joint analysis of diverse cosmological datasets constrains the clustering parameter and coupling strength within interacting dark energy models where the energy exchange is governed by the Hubble expansion rate and dark energy density. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">In the context of a spatially flat $Λ(t)$CDM cosmology, we investigate interacting dark energy (IDE) scenarios characterized by phenomenological interaction terms proportional to the Hubble expansion rate and the dark energy density. Our analysis is performed at both the background and linear perturbation levels, with particular emphasis on the evolution of dark matter density fluctuations. Cosmological constraints are derived from a joint analysis of CMB distance priors, Baryon Acoustic Oscillations (BAO), Type Ia supernovae (SNe Ia) from Pantheon+, Redshift-Space Distortions (RSD), and $H(z)$ data from Cosmic Chronometers (CC). Using the linear growth of matter perturbations, we estimate the clustering parameter $S_8$ within IDE extensions of the flat $Λ(t)$CDM framework. At the perturbative level, we consider interaction terms of the form $Q_{\text{I}}=\varepsilon a H\barρ_{Λ(t)}$ (Model I) and $Q_{\text{II}}=\varepsilon H\barρ_{Λ(t)}$ (Model II). From the combined dataset, we obtain the constraints $S_8 = 0.870 \pm 0.026$ for Model I and $S_8 = 0.872 \pm 0.026$ for Model II. Finally, we discuss the implications for the coupling parameter $\varepsilon$, taking into account the semi-analytical approximations and observational data employed in this study.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.11310" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.11310" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.11310" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: cosmology, statistical inference, probabilistic modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
    </div>

    <footer class="footer">
        &copy; 2026 arXiv Daily · Powered by <a href="https://arxiv.org/" target="_blank">arXiv</a>
    </footer>
</body>
</html>