<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>arXiv Daily: 2025-11-22</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Roboto:400,700&display=swap" rel="stylesheet">
    <style>
        body { font-family: 'Roboto', Arial, sans-serif; background: #f8f9fa; transition: background 0.3s; }
        .arxiv-card { margin: 2em auto; max-width: 900px; box-shadow: 0 2px 8px rgba(0,0,0,0.08); border-radius: 16px; transition: box-shadow 0.3s, transform 0.3s; }
        .arxiv-card:hover { box-shadow: 0 4px 12px rgba(0,0,0,0.1); transform: translateY(-1px); }
        .arxiv-title { background: linear-gradient(90deg, #0d6efd 60%, #6610f2 100%); color: #fff; border-radius: 16px 16px 0 0; padding: 1.5em; font-size: 1.5em; font-weight: 700; letter-spacing: 0.5px;}
        .arxiv-meta { font-size: 1em; color: #555; margin-bottom: 1em; }
        .arxiv-abstract { background: #fff; padding: 1.5em; border-radius: 0 0 16px 16px; font-size: 1.1em; line-height: 1.7;}
        .arxiv-links a { margin-right: 1em; }
        .arxiv-scores { margin-top: 1em; font-size: 1em; }
        .navbar { background: #fff; box-shadow: 0 2px 8px rgba(0,0,0,0.04);}
        .footer { text-align: center; color: #888; padding: 2em 0 1em 0; font-size: 0.95em;}
        @media (prefers-color-scheme: dark) {
            body { background: #181a1b; color: #e4e6eb; }
            .arxiv-card { background: #23272b; box-shadow: 0 2px 8px rgba(0,0,0,0.28);}
            .arxiv-card:hover { box-shadow: 0 5px 15px rgba(0,0,0,0.25); transform: translateY(-1px); }
            .arxiv-title { background: linear-gradient(90deg, #375a7f 60%, #6f42c1 100%);}
            .arxiv-abstract { background: #23272b; color: #e4e6eb;}
            .navbar { background: #23272b; color: #e4e6eb;}
            .text-muted { color: #adb5bd !important; }
        }
        /* Improved abstract readability */
        .arxiv-abstract-text {
            font-size: 1.1em;
            line-height: 1.7;
        }
        p.big {
            line-height: 1.6;
            font-size: large;
        }
    </style>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'] ],
          processEscapes: true
        }
      });
    </script>
    <script>
    function toggleAuthors(element) {
        const fullList = element.querySelector('.author-full');
        const shortList = element.querySelector('.author-short');
        const toggleText = element.querySelector('.author-toggle');
        
        fullList.style.display = fullList.style.display === 'none' ? 'inline' : 'none';
        shortList.style.display = shortList.style.display === 'none' ? 'inline' : 'none';
        toggleText.textContent = fullList.style.display === 'none' ? ' (show all)' : ' (show less)';
    }
    </script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
</head>
<body>
    <nav class="navbar navbar-expand-lg mb-4">
        <div class="container">
            <a class="navbar-brand fw-bold text-primary" href="#">arXiv Daily</a>
            <span class="navbar-text">Modern arXiv Reader</span>
        </div>
    </nav>

    
    <div class="container py-4">
        <header class="mb-4"><h2 class="display-6 text-center">Analysis of Your Favorites</h2></header>
        
        <div class="row justify-content-center">
            <div class="col-lg-8 mb-4">
                <div class="card">
                    <div class="card-header fw-bold">Interest Word Cloud</div>
                    <div class="card-body text-center p-2">
                        <img src="analysis_results/word_cloud.png" class="img-fluid rounded" alt="Word Cloud of favorite paper topics">
                    </div>
                </div>
            </div>
        </div>
        
        
        <div class="row justify-content-center">
            <div class="col-lg-8 mb-4">
                <div class="card">
                    <div class="card-header fw-bold">Interest Clusters</div>
                    <div class="card-body text-center p-2">
                        <img src="analysis_results/daily_cluster_map.png" class="img-fluid rounded" alt="2D Cluster plot of favorite papers">
                    </div>
                </div>
            </div>
        </div>
        
    </div>
    

    <div class="container py-4">
        <header class="mb-4"><h1 class="display-5 text-center text-primary">arXiv: 2025-11-22</h1></header>

        
        <div class="row justify-content-center">
            <div class="col-lg-8 mb-4">
                <div class="card">
                    <div class="card-header fw-bold">Score Distribution of All Papers Found Today</div>
                    <div class="card-body text-center p-2">
                        <img src="analysis_results/score_distribution.png" class="img-fluid rounded" alt="Score distribution of all papers found today">
                    </div>
                </div>
            </div>
        </div>
        

        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">1. The PAU Survey: The $i$-band galaxy luminosity function from the present-day to $z = 2$
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">S. Koonkor, C. M. Baugh, G. Manzoni, D. Navarro-Gironés, P. Renard, H. Hoekstra, H. Hildebrandt, E. Gaztañaga, J. García-Bellido, P. Tallada-Crespí, et al.</span>
                                <span class="author-full" style="display: none;">S. Koonkor, C. M. Baugh, G. Manzoni, D. Navarro-Gironés, P. Renard, H. Hoekstra, H. Hildebrandt, E. Gaztañaga, J. García-Bellido, P. Tallada-Crespí, F. J. Castander, J. De Vincente, R. Casas, R. Miquel, N. Sevilla-Noarbe, M. Eriksen</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Using 1.1 million PAUS galaxies and machine learning techniques for photometric redshift correction, the rest-frame $i$-band galaxy luminosity function was measured up to $z=2$, highlighting increasing model discrepancies at high redshift and distinct evolutionary trends between red and blue galaxy populations. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We present a measurement of the $i$-band galaxy luminosity function from the present-day to $z = 2$, using over 1.1 million galaxies from the Physics of the Accelerating Universe Survey (PAUS). PAUS combines broad-band imaging from the Canada-France-Hawaii Telescope Lensing Survey with narrow-band photometry from PAUCam, enabling high-precision photometric redshifts with an accuracy of $σ_{68} (Δz) = 0.019$ down to $i_{\textrm{AB}} = 23$. A synthetic lightcone mock catalogue built using the \texttt{GALFORM} semi-analytic model is used to simulate PAUS selection effects and photometric uncertainties, and to derive a machine-learning based estimate of the $k$-correction. We recover rest-frame $i$-band luminosities using a random forest regressor trained on simulated $ugriz$ photometry and redshifts. Luminosity functions are estimated using the $1/V_{\textrm{max}}$ method, accounting for photometric redshift and magnitude errors, and validated against mock data. We find good agreement between observations and models at $z &lt; 1$, with increasing discrepancies at higher redshifts due to photometric redshift outliers. The bright-end of the luminosity function becomes flatter at high redshift, primarily driven by redshift errors. We show that the faint-end of the luminosity function becomes more incomplete with increasing redshift, but is still useful for constraining models. We analyze the red and blue galaxy populations separately, observing distinct evolutionary trends. The model overpredicts the number of both faint red and blue galaxies. Our study highlights the importance of accurate redshift estimation and selection modeling for robust luminosity function recovery, and demonstrates that PAUS can characterise the galaxy population with photometric redshifts across a wide redshift baseline.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.16042" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.16042" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.16042" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 10.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.19</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Large-Scale Structure, Weak Lensing, Cosmological Constraints / Galaxy Clustering, Weak Lensing, Halo Modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">2. Denoising weak lensing mass maps with diffusion model and generative adversarial network
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Shohei D. Aoyama, Ken Osato, Masato Shirasaki</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A diffusion model (DM) implemented for weak gravitational lensing denoising demonstrated superior performance compared to generative adversarial networks (GANs), exhibiting greater training stability, robust signal recovery through sample averaging, and higher accuracy in reproducing cosmic density field statistics. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The matter distribution of the Universe can be mapped through the weak gravitational lensing (WL) effect: small distortions of the shapes of distant galaxies, which reflects the inhomogeneity of the cosmic density field. The most dominant contaminant in the WL effect is the shape noise; the signal is diluted due to the finite number of source galaxies. In order to explore the full potential of WL measurements, sharpening the signal by removing the shape noise from the observational data, i.e., WL denoising, is a pressing issue. Machine learning approaches, in particular, deep generative models, have proven effective at the WL denoising task. We implement a denoising model based on the diffusion model (DM) and conduct systematic in-depth comparisons with generative adversarial networks (GANs), which have been applied in previous works for WL denoising. Utilizing the large suite of mock simulations of WL observations, we demonstrate that DM surpasses GAN in the WL denosing task in multiple aspects: (1) the training process is more stable, (2) taking the average of multiple samples from DM can robustly reproduce the true signal, and (3) DM can recover various statistics with higher accuracy.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.16415" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.16415" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.16415" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.5</span>
                        <span class="badge bg-info text-dark">Author Score: 0.04</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">3. Fossil group origins XIV: The radial orbits of A267
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>S. Zarattini, A. Biviano, I. Bartalucci, J. A. L. Aguerri, C. P. Haines, M. Girardi</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Analysis of the fossil cluster A267&#39;s galaxy orbits using the MAMPOSSt algorithm confirmed that its member galaxies follow more radial orbits than those in typical clusters, suggesting this orbital distribution may be key to forming the characteristic large magnitude gap ($\Delta m_{12}$). (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Fossil groups (FGs) are groups or clusters of galaxies with a single, massive, central galaxy and with a clear lack of L* galaxies. The physical reason for their large magnitude gap (dm12) may arise from early FG formation, which allowed all L galaxies to merge with the central one, and/or it could be related to the fact that galaxies accreting on the FGs move on radial orbits, shortening their merging timescales. The latter properties could be linked with the peculiar position of FGs within the cosmic web. We determine the velocity anisotropy profile beta(r) of the fossil cluster A267, which is related to the orbital distribution of cluster galaxies. This is the first individual FG for which the orbital distribution of galaxies is determined. We aim to confirm previous findings based on stack samples that indicate that FGs, on average, host galaxies on more radial orbits than normal clusters. We started with a sample of 2315 redshifts in the field of A267 and we determined the membership for 329 of them. Of these, 174 are located within r200. We used them as tracers of the gravitational potential of the cluster to solve the Jeans equation using the MAMPOSSt algorithm. We thus obtained the cluster mass M(r) and beta(r) profiles. We also estimated M(r) from the X-ray data. A comparison of the MAMPOSSt and X-ray-determined M(r)s allows us to estimate the cluster hydrostatic mass bias, that is consistent with previous findings. The anisotropy parameter beta(r) indicates tangential orbits for the galaxies near the cluster centre and increasingly radial orbits in the external regions. We therefore confirm that FGs are characterised by more radial orbits for their member galaxies than the average cluster population. We speculate that this different orbital distribution might be an important element in creating a large dm12.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.15786" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.15786" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.15786" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.01</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Large-Scale Structure, Weak Lensing, Cosmological Constraints / Galaxy Clustering, Weak Lensing, Halo Modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">4. Primordial non-Gaussianity in noncanonical warm inflation with nonminimal derivative coupling
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Xiao-Min Zhang, Run-Qing Zhao, Yun-Cai Feng, Peng-Cheng Chu, Zhi-Peng Peng, Xi-Bin Li</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Non-Gaussian perturbations in the warm k-inflation model, specifically the intrinsic ($f_{NL}^{int}$) and $\delta N$ ($f_{NL}^{\delta N}$) components derived from three-point and four-point correlations, were calculated and compared against observational data to constrain the model&#39;s parameter space. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">This paper presents and investigates non-Gaussian perturbations for the warm k-inflation model that is driven by pure kinetic energy. The two complementary components of the overall non-Gaussianity are the three-point and four-point correlations. The intrinsic non-Gaussian component, denoted as the nonlinear parameter f_{NL}^{int}, is rooted in the three-point correlation for the inflaton field. Meanwhile, the δN part non-Gaussianity, denoted as f_{NL}^{δN}, is the contribution attributed to the four-point correlation function of the inflaton field. In this paper, the above two components in warm k-inflation are individually computed and analyzed. Then, comparisons and discussions between them are conducted, and the non-Gaussian theoretical results are compared with experimental observations to determine the range of model parameters within the allowable range of observation.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.16312" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.16312" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.16312" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">gr-qc</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">5. Deep Learning Framework for Enhanced Neutrino Reconstruction of Single-line Events in the ANTARES Telescope
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">A. Albert, S. Alves, M. André, M. Ardid, S. Ardid, J. -J. Aubert, J. Aublin, B. Baret, S. Basa, Y. Becherini, et al.</span>
                                <span class="author-full" style="display: none;">A. Albert, S. Alves, M. André, M. Ardid, S. Ardid, J. -J. Aubert, J. Aublin, B. Baret, S. Basa, Y. Becherini, B. Belhorma, F. Benfenati, V. Bertin, S. Biagi, J. Boumaaza, M. Bouta, M. C. Bouwhuis, H. Brânzaş, R. Bruijn, J. Brunner, J. Busto, B. Caiffi, D. Calvo, S. Campion, A. Capone, F. Carenini, J. Carr, V. Carretero, T. Cartraud, S. Celli, L. Cerisy, M. Chabab, R. Cherkaoui El Moursli, T. Chiarusi, M. Circella, J. A. B. Coelho, A. Coleiro, R. Coniglione, P. Coyle, A. Creusot, A. F. Díaz, B. De Martino, C. Distefano, I. Di Palma, C. Donzaud, D. Dornic, D. Drouhin, T. Eberl, A. Eddymaoui, T. van Eeden, D. van Eijk, S. El Hedri, N. El Khayati, A. Enzenhöfer, P. Fermani, G. Ferrara, F. Filippini, L. Fusco, S. Gagliardini, J. García-Méndez, C. Gatius Oliver, P. Gay, N. Geißelbrecht, H. Glotin, R. Gozzini, R. Gracia Ruiz, K. Graf, C. Guidi, L. Haegel, H. van Haren, A. J. Heijboer, Y. Hello, L. Hennig, J. J. Hernández-Rey, J. Hößl, F. Huang, G. Illuminati, B. Jisse-Jung, M. de Jong, P. de Jong, M. Kadler, O. Kalekin, U. Katz, A. Kouchner, I. Kreykenbohm, V. Kulikovskiy, R. Lahmann, M. Lamoureux, A. Lazo, D. Lefèvre, E. Leonora, G. Levi, S. Le Stum, S. Loucatos, J. Manczak, M. Marcelin, A. Margiotta, A. Marinelli, J. A. Martínez-Mora, P. Migliozzi, A. Moussa, R. Muller, S. Navas, E. Nezri, B. Ó Fearraigh, E. Oukacha, A. M. Păun, G. E. Păvălaş, S. Peña-Martínez, M. Perrin-Terrin, P. Piattelli, C. Poiré, V. Popa, T. Pradier, N. Randazzo, D. Real, G. Riccobene, A. Romanov, A. Sánchez Losa, A. Saina, F. Salesa Greus, D. F. E. Samtleben, M. Sanguineti, P. Sapienza, F. Schüssler, J. Seneca, M. Spurio, Th. Stolarczyk, M. Taiuti, Y. Tayalati, B. Vallage, G. Vannoye, V. Van Elewyck, S. Viola, D. Vivolo, J. Wilms, S. Zavatarelli, A. Zegarelli, J. D. Zornoza, J. Zúñiga</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The $N$-fit deep learning algorithm, utilizing convolutional layers and transfer learning, significantly enhances the reconstruction of low-energy single-line neutrino events in ANTARES by providing reliable azimuthal angle predictions and substantially reducing errors in spatial and energy parameter estimation. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We present the $N$-fit algorithm designed to improve the reconstruction of neutrino events detected by a single line of the ANTARES underwater telescope, usually associated with low energy neutrino events ($\sim$ 100 GeV). $N$-Fit is a neural network model that relies on deep learning and combines several advanced techniques in machine learning --deep convolutional layers, mixture density output layers, and transfer learning. This framework divides the reconstruction process into two dedicated branches for each neutrino event topology --tracks and showers-- composed of sub-models for spatial estimation --direction and position-- and energy inference, which later on are combined for event classification. Regarding the direction of single-line events, the $N$-Fit algorithm significantly refines the estimation of the zenithal angle, and delivers reliable azimuthal angle predictions that were previously unattainable with traditional $χ^2$-fit methods. Improving on energy estimation of single-line events is a tall order; $N$-Fit benefits from transfer learning to efficiently integrate key characteristics, such as the estimation of the closest distance from the event to the detector. $N$-Fit also takes advantage from transfer learning in event topology classification by freezing convolutional layers of the pretrained branches. Tests on Monte Carlo simulations and data demonstrate a significant reduction in mean and median absolute errors across all reconstructed parameters. The improvements achieved by $N$-Fit highlight its potential for advancing multimessenger astrophysics and enhancing our ability to probe fundamental physics beyond the Standard Model using single-line events from ANTARES data.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.16614" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.16614" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.16614" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.01</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">physics.comp-ph</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">6. Time dependent loss reweighting for flow matching and diffusion models is theoretically justified
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Lukas Billera, Hedwig Nora Nordlinder, Ben Murrell</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Theoretical justification is provided for allowing the Bregman divergence loss and linear generator parameterization in Generator Matching and Edit Flows to depend on both time $t$ and state $X_t$, validating common time-dependent loss weighting practices used in training flow and diffusion models. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">This brief note clarifies that, in Generator Matching (which subsumes a large family of flow matching and diffusion models over continuous, manifold, and discrete spaces), both the Bregman divergence loss and the linear parameterization of the generator can depend on both the current state $X_t$ and the time $t$, and we show that the expectation over time in the loss can be taken with respect to a broad class of time distributions. We also show this for Edit Flows, which falls outside of Generator Matching. That the loss can depend on $t$ clarifies that time-dependent loss weighting schemes, often used in practice to stabilize training, are theoretically justified when the specific flow or diffusion scheme is a special case of Generator Matching (or Edit Flows). It also often simplifies the construction of $X_1$-predictor schemes, which are sometimes preferred for model-related reasons. We show examples that rely upon the dependence of linear parameterizations, and of the Bregman divergence loss, on $t$ and $X_t$.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.16599" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.16599" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.16599" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">stat.ML</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms / Representation Learning, Neural Architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">7. The abundance and properties of the lowest luminosity dwarf galaxies around the Milky Way: Insights from Semi-Analytic Models
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">Niusha Ahvazi, Andrew B. Pace, Christopher T. Garling, Xiaowei Ou, Nitya Kallivayalil, Paul Torrey, Andrew Benson, Aklant Bhowmick, Núria Torres-Albà, Alex M. Garcia, et al.</span>
                                <span class="author-full" style="display: none;">Niusha Ahvazi, Andrew B. Pace, Christopher T. Garling, Xiaowei Ou, Nitya Kallivayalil, Paul Torrey, Andrew Benson, Aklant Bhowmick, Núria Torres-Albà, Alex M. Garcia, Alejandro Saravia, Jonathan Kho, Jack T. Warfield, Kaia R. Atzberger</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Semi-analytic modeling of faint satellite galaxies demonstrates that the inclusion of molecular hydrogen cooling predicts a significantly larger population of hyper-faint systems compared to atomic cooling models, suggesting that kinematic measurements are essential for distinguishing these dark matter-dominated dwarfs from star clusters. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We investigate the formation and observable properties of faint satellite galaxies (M$_\rm V &gt; -3$) in Milky Way-like halos using the semi-analytic galaxy formation model Galacticus. The ability of the smallest dark matter halos to form stars depends sensitively on the balance between gas cooling and reionization heating. To quantify how this balance shapes the abundance and properties of the faintest galaxies, we compare two model variants: a fiducial model that includes molecular hydrogen (H$_2$) cooling and UV background radiation, and a No-H$_2$ model with atomic cooling only. Both models reproduce the structural properties of brighter Milky Way satellites, but they diverge at the lowest luminosities in the hyper-faint regime. The fiducial model predicts a substantially larger population of such systems that are on average hosted in halos with lower peak masses and quenched earlier. Many of these predicted systems lie below current observational thresholds but are within reach of next-generation deep imaging surveys. The predicted size-luminosity distributions of both models overlap with the region occupied by recently discovered &#34;ambiguous&#34; systems, whose classification as galaxies or star clusters remains uncertain. Specifically, we find that hyper-faint satellites have line-of-sight velocity dispersions of $σ_{\rm los} \sim 1-3$ km/s in the fiducial model, nearly an order of magnitude higher than expected for purely self-gravitating stellar systems of the same stellar mass. This distinction underscores the diagnostic power of precise kinematic measurements for determining whether ambiguous objects are dark matter dominated dwarf galaxies or star clusters, and highlights the importance of upcoming spectroscopic campaigns in resolving the nature of the faintest satellites.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.15808" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.15808" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.15808" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.01</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Large-Scale Structure, Weak Lensing, Cosmological Constraints / Galaxy Clustering, Weak Lensing, Halo Modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">8. Environmental Invariance of the Galaxy Size-Mass Relation
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Li-Wen Liao, Andrew Cooper</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Analysis of a large DESI-LS galaxy sample reveals that environmental influence on the overall size-mass relation is an effect of varying subpopulation mixtures, not direct size transformation, confirming that individual galaxy assembly histories are the primary drivers of galaxy size. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The galaxy size-luminosity and size-stellar mass relations are important constraints on the galactic baryon cycle of gas accretion, star formation, and feedback. There are conflicting claims in the literature regarding how environment influences size: both direct transformative effects and `assembly bias&#39; may contribute to observed variations with environment. We construct a large homogeneous sample of size measurements to M*~10^7 Msun. Our sample fills a gap in field galaxy size measurements around 10^7-10^8 Msun; the literature at these masses is biased towards satellites of L* galaxies and members of galaxy clusters. We use sizes from the DESI-LS, together with a published catalog that contains stellar masses and cluster positions derived from DESI-LS photometry. Our sample extends to z&lt;0.3 and comprises 540,228 galaxies with spectroscopic redshifts and 9,513,732 galaxies with photometric redshifts. We explore the environmental dependence of size for a mass-limited subset of our sample at z&lt;0.05, based on distance to the nearest cluster center. We obtain size-luminosity and size-mass relations in good agreement with previous studies. By separating galaxies according to color and morphology, we show that the environmental variation of the overall size-mass relation on Mpc scales can be understood as the consequence of a changing mixture of subpopulations, rather than direct size transformation. For example, at fixed mass, quiescent (red) late-type galaxies within 2Mpc of a cluster have the same size as quiescent late-type galaxies 30Mpc from the nearest cluster. Our results support individual galaxy assembly histories as the primary determinant of galaxy size. The existence of significantly different, environment-insensitive size mass relations for subpopulations separated by color and Sersic index provides a clear target for calibration of the baryon cycle in cosmological simulations.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.16332" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.16332" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.16332" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Large-Scale Structure, Weak Lensing, Cosmological Constraints / Galaxy Clustering, Weak Lensing, Halo Modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">9. SURFing to the Fundamental Limit of Jet Tagging
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Ian Pang, Darius A. Faroughy, David Shih, Ranit Das, Gregor Kasieczka</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The SUrrogate ReFerence (SURF) method, which uses a validated generative surrogate model (EPiC-FM) to enable exact Neyman-Pearson tests, establishes that modern jet tagging algorithms are operating close to their fundamental statistical performance limits. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Beyond the practical goal of improving search and measurement sensitivity through better jet tagging algorithms, there is a deeper question: what are their upper performance limits? Generative surrogate models with learned likelihood functions offer a new approach to this problem, provided the surrogate correctly captures the underlying data distribution. In this work, we introduce the SUrrogate ReFerence (SURF) method, a new approach to validating generative models. This framework enables exact Neyman-Pearson tests by training the target model on samples from another tractable surrogate, which is itself trained on real data. We argue that the EPiC-FM generative model is a valid surrogate reference for JetClass jets and apply SURF to show that modern jet taggers may already be operating close to the true statistical limit. By contrast, we find that autoregressive GPT models unphysically exaggerate top vs. QCD separation power encoded in the surrogate reference, implying that they are giving a misleading picture of the fundamental limit.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.15779" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.15779" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.15779" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">hep-ph</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">10. Forecasting the Constraint on the Hu-Sawicki $f(R)$ Modified Gravity in the CSST $3\times2$pt Photometric Survey
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Jun-Hui Yan, Yan Gong, Qi Xiong, Xuelei Chen, Qi Guo, Ming Li, Yun Liu, Wenxiang Pei</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Forecasting constraints on the Hu-Sawicki $f(R)$ model using simulated CSST $3\times2$pt data indicates that the 100 deg$^2$ photometric survey will constrain $\log_{10}|f_{R0}|$ to $&lt;-5.29$, with the full survey area expected to improve precision tenfold. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We forecast the constraint on the Hu-Sawicki $f(R)$ model from the photometric survey operated by the Chinese Space Station Survey Telescope (CSST). The simulated $3\times2$pt data of galaxy clustering, weak lensing, and galaxy-galaxy lensing measurements within 100 deg$^{2}$ are used in the analysis. The mock observational maps are constructed from a light cone, redshift sampling and noise. The angular power spectra are measured with pseudo-$C_\ell$ estimators and compared to theory in the same basis using validated weighting functions and an analytic covariance matrix that includes Gaussian, connected non-Gaussian, and super-sample terms. We model the theoretical spectra using two methods. The first one uses MGCAMB to compute the linear modified-gravity clustering power spectra, and the second one adopts the FREmu emulator with a baseline of nonlinear $Λ$CDM prescription. Parameter inference is performed with Cobaya, and the cosmological and modified-gravity parameters are sampled within the emulator training domain, which is jointly fitted with the systematic parameters. We find that the predictions from the two methods are in good agreement at the overlapping large scales, and the emulator method can correctly provide additional high-$\ell$ information. The $1σ$ upper bounds of $\log_{10}|f_{R0}|$ are found to be $&lt;-5.42$ for cosmic shear only case and $&lt;-5.29$ for the 100 deg$^2$ CSST $3\times2$pt probe. The full CSST photometric survey with 17,500 deg$^2$ survey area is expected to further improve the constraint precision by about one order of magnitude. Our results demonstrate that the CSST $3\times2$pt survey can deliver strict tests on $f(R)$ gravity.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.16097" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.16097" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.16097" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">11. Domain walls in the scaling regime: Equal Time Correlator and Gravitational Waves
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Simone Blasi, Alberto Mariotti, Aäron Rase, Miguel Vanvlasselaer</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> High-resolution 3D lattice simulations of early universe domain wall networks confirm rapid scaling, establish a universal subhorizon shape for the Equal Time Correlator, and quantify the network&#39;s coherence by analyzing its gravitational wave spectrum across different cosmologies. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Domain walls are topological defects that may have formed in the early Universe through the spontaneous breakdown of discrete symmetries, and can be a strong source of gravitational waves (GWs). We perform 3D lattice field theory simulations with CosmoLattice, considering grid sizes $N = 1250$, $2048$ and $4096$, to study the dynamics of the domain wall network and its GW signatures. We first analyze how the network approaches the scaling regime with a constant $\mathcal{O}(1)$ number of domain walls per Hubble volume, including setups with a large initial number of domains as expected in realistic scenarios, and find that scaling is always reached in a few Hubble times after the network formation. To better understand the properties of the scaling regime, we then numerically extract the Equal Time Correlator (ETC) of the energy-momentum tensor of the network, thus determining its characteristic shape for the case of domain walls, and verifying explicitly its functional dependence as predicted by scaling arguments. The ETC can be further extended to the Unequal Time Correlator (UTC) controlling the GW emission by making assumptions on the coherence of the source. By comparison with the actual GW spectrum evaluated by CosmoLattice, we are then able to infer the degree of coherence of the domain wall network. Finally, by performing numerical simulations in different background cosmologies, e.g. radiation domination and kination, we find evidence for a universal ETC at subhorizon scales and hence a universal shape of the GW spectrum in the UV, while the expansion history of the Universe may instead be determined by the IR features of the GW spectrum.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.16649" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.16649" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.16649" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">hep-ph</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">12. Teukolsky by Design: A Hybrid Spectral-PINN solver for Kerr Quasinormal Modes
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Alexandre M. Pombo, Lorenzo Pizzuti</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A novel hybrid SpectralPINN solver, employing Chebyshev polynomials, achieves high-accuracy solutions for Kerr quasinormal modes using both separated and joint Teukolsky formulations, demonstrating its utility in constraining non-separable black hole perturbations. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We introduce SpectralPINN, a hybrid pseudo-spectral/physics-informed neural network (PINN) solver for Kerr quasinormal modes that targets the Teukolsky equation in both the separated (radial/angular) and joint two-dimensional formulations. The solver replaces standard neural activation functions with Chebyshev polynomials of the first kind and supports both soft -- via loss penalties -- and hard -- enforced by analytic masks -- implementations of Leaver&#39;s normalization. Benchmarking against Leaver&#39;s continued-fraction method shows cumulative (real+imaginary part) relative frequency errors of $\sim 0.001\%$ for the separated formulation with hard normalization, $\sim 0.1\%$ for both the soft separated and soft joint formulations, and $\sim 0.01\%$ for the hard joint case. Exploiting our ability to solve the joint equation, we add a small quadrupolar perturbation to the Teukolsky operator, effectively rendering the problem non-separable. The resulting perturbed quasinormal modes are compared against the expected precision of the Einstein Telescope, allowing us to constrain the magnitude of the perturbation. These proof-of-concept results demonstrate that hybrid spectral-PINN solvers can provide a flexible pathway to quasinormal spectra in settings where separability, asymptotics, or field content become more intricate and high accuracy is required.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.15796" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.15796" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.15796" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">gr-qc</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">13. TOFA: Training-Free One-Shot Federated Adaptation for Vision-Language Models
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Li Zhang, Zhongxuan Han, XiaoHua Feng, Jiaming Zhang, Yuyuan Li, Linbo Jiang, Jianan Lin, Chaochao Chen</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> TOFA, a novel training-free, one-shot federated adaptation framework for Vision-Language Models, enhances robustness against data heterogeneity by combining personalized visual prototype distributions with globally aligned textual prompts via adaptive weight calibration. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Efficient and lightweight adaptation of pre-trained Vision-Language Models (VLMs) to downstream tasks through collaborative interactions between local clients and a central server is a rapidly emerging research topic in federated learning. Existing adaptation algorithms are typically trained iteratively, which incur significant communication costs and increase the susceptibility to potential attacks. Motivated by the one-shot federated training techniques that reduce client-server exchanges to a single round, developing a lightweight one-shot federated VLM adaptation method to alleviate these issues is particularly attractive. However, current one-shot approaches face certain challenges in adapting VLMs within federated settings: (1) insufficient exploitation of the rich multimodal information inherent in VLMs; (2) lack of specialized adaptation strategies to systematically handle the severe data heterogeneity; and (3) requiring additional training resource of clients or server. To bridge these gaps, we propose a novel Training-free One-shot Federated Adaptation framework for VLMs, named TOFA. To fully leverage the generalizable multimodal features in pre-trained VLMs, TOFA employs both visual and textual pipelines to extract task-relevant representations. In the visual pipeline, a hierarchical Bayesian model learns personalized, class-specific prototype distributions. For the textual pipeline, TOFA evaluates and globally aligns the generated local text prompts for robustness. An adaptive weight calibration mechanism is also introduced to combine predictions from both modalities, balancing personalization and robustness to handle data heterogeneity. Our method is training-free, not relying on additional training resources on either the client or server side. Extensive experiments across 9 datasets in various federated settings demonstrate the effectiveness of the proposed TOFA method.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.16423" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.16423" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.16423" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms / Representation Learning, Neural Architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">14. Bridging VLMs and Embodied Intelligence with Deliberate Practice Policy Optimization
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">Yi Zhang, Che Liu, Xiancong Ren, Hanchu Ni, Yingji Zhang, Shuai Zhang, Zeyuan Ding, Jiayu Hu, Haozhe Shan, Junbo Qi, et al.</span>
                                <span class="author-full" style="display: none;">Yi Zhang, Che Liu, Xiancong Ren, Hanchu Ni, Yingji Zhang, Shuai Zhang, Zeyuan Ding, Jiayu Hu, Haozhe Shan, Junbo Qi, Yan Bai, Dengjie Li, Jiachen Luo, Yidong Wang, Yong Dai, Zenglin Xu, Bin Shen, Qifan Wang, Jian Tang, Xiaozhu Ju</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Deliberate Practice Policy Optimization (DPPO) is introduced as a metacognitive &#34;Metaloop&#34; training framework that dynamically alternates supervised fine-tuning and reinforcement learning to maximize learning efficiency from sparse data, significantly improving embodied intelligence systems like Pelican-VL 1.0. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Developing a universal and versatile embodied intelligence system presents two primary challenges: the critical embodied data bottleneck, where real-world data is scarce and expensive, and the algorithmic inefficiency of existing methods, which are resource-prohibitive. To address these limitations, we introduce Deliberate Practice Policy Optimization (DPPO), a metacognitive ``Metaloop&#39;&#39; training framework that dynamically alternates between supervised fine-tuning (competence expansion) and reinforcement learning (skill refinement). This enables automatic weakness identification and targeted resource allocation, specifically designed to maximize learning efficiency from sparse, finite data. Theoretically, DPPO can be formalised as a unified preference-learning framework. Empirically, training a vision-language embodied model with DPPO, referred to as Pelican-VL 1.0, yields a 20.3% performance improvement over the base model and surpasses open-source models at the 100B-parameter scale by 10.6%. We are open-sourcing both the models and code, providing the first systematic framework that alleviates the data and resource bottleneck and enables the community to build versatile embodied agents efficiently.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.16602" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.16602" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.16602" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms / Representation Learning, Neural Architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">15. Majority Rules: LLM Ensemble is a Winning Approach for Content Categorization
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Ariel Kamen, Yakov Kamen</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> An ensemble large language model (eLLM) framework formalizes collective decision-making to mitigate individual model weaknesses like inconsistency and hallucination, resulting in substantial F1-score improvements and near human-expert performance in zero-shot text categorization. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">This study introduces an ensemble framework for unstructured text categorization using large language models (LLMs). By integrating multiple models, the ensemble large language model (eLLM) framework addresses common weaknesses of individual systems, including inconsistency, hallucination, category inflation, and misclassification. The eLLM approach yields a substantial performance improvement of up to 65\% in F1-score over the strongest single model. We formalize the ensemble process through a mathematical model of collective decision-making and establish principled aggregation criteria. Using the Interactive Advertising Bureau (IAB) hierarchical taxonomy, we evaluate ten state-of-the-art LLMs under identical zero-shot conditions on a human-annotated corpus of 8{,}660 samples. Results show that individual models plateau in performance due to the compression of semantically rich text into sparse categorical representations, while eLLM improves both robustness and accuracy. With a diverse consortium of models, eLLM achieves near human-expert-level performance, offering a scalable and reliable solution for taxonomy-based classification that may significantly reduce dependence on human expert labeling.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.15714" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.15714" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.15714" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms / Representation Learning, Neural Architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">16. Formal Abductive Latent Explanations for Prototype-Based Networks
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Jules Soria, Zakaria Chihani, Julien Girard-Satabin, Alban Grastien, Romain Xu-Darme, Daniela Cancila</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Abductive Latent Explanations (ALEs) introduce a formal XAI method for case-based reasoning networks, defining sufficient conditions on the latent representation to imply a prediction, thereby providing reliable guarantees that overcome the limitations of potentially misleading inherent explanations. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Case-based reasoning networks are machine-learning models that make predictions based on similarity between the input and prototypical parts of training samples, called prototypes. Such models are able to explain each decision by pointing to the prototypes that contributed the most to the final outcome. As the explanation is a core part of the prediction, they are often qualified as ``interpretable by design&#34;. While promising, we show that such explanations are sometimes misleading, which hampers their usefulness in safety-critical contexts. In particular, several instances may lead to different predictions and yet have the same explanation. Drawing inspiration from the field of formal eXplainable AI (FXAI), we propose Abductive Latent Explanations (ALEs), a formalism to express sufficient conditions on the intermediate (latent) representation of the instance that imply the prediction. Our approach combines the inherent interpretability of case-based reasoning models and the guarantees provided by formal XAI. We propose a solver-free and scalable algorithm for generating ALEs based on three distinct paradigms, compare them, and present the feasibility of our approach on diverse datasets for both standard and fine-grained image classification. The associated code can be found at https://github.com/julsoria/ale</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.16588" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.16588" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.16588" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms / Representation Learning, Neural Architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">17. From generative AI to the brain: five takeaways
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Claudius Gros</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Cognitive neuroscience should thoroughly investigate whether the clearly defined generative principles and resulting characterizations from machine learning, such as neural scaling laws and attention mechanisms, are operative within the brain&#39;s cognitive processes. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The big strides seen in generative AI are not based on somewhat obscure algorithms, but due to clearly defined generative principles. The resulting concrete implementations have proven themselves in large numbers of applications. We suggest that it is imperative to thoroughly investigate which of these generative principles may be operative also in the brain, and hence relevant for cognitive neuroscience. In addition, ML research led to a range of interesting characterizations of neural information processing systems. We discuss five examples, the shortcomings of world modelling, the generation of thought processes, attention, neural scaling laws, and quantization, that illustrate how much neuroscience could potentially learn from ML research.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.16432" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.16432" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.16432" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">18. The MeerKAT Fornax Survey VI. The collapse of the galaxy HI Mass Function in Fornax
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>D. Kleiner, P. Serra, A. Loni, S. H. A. Rajohnson, F. M. Maccagni, W. J. G. de Blok, P. Kamphuis, R. C. Kraan-Korteweg, M. A. W. Verheijen</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The deepest HI Mass Function measurement in the Fornax cluster confirms a distinct population of HI clouds and reveals the first robust measurement of HIMF collapse, marked by an abrupt drop in galaxy number density below $\log(M_{\text{HI}}/M_{\odot}) = 7$, likely caused by rapid HI removal. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We present the deepest HI mass Function (HIMF) ever measured, outside the Local Group. The observations are part of the MeerKAT Fornax Survey and cover a 4 x 4 deg^2 field, corresponding to ~ Rvir. The 3$σ$ detection limit is log(MHI/Msun) = 5.7 for a 50 km/s-wide point source. We detect HI in 35 galaxies and 44 clouds with no optical counterparts. Using deep optical images from the Fornax Deep Survey, we show that the clouds are a distinct population, separated by a four magnitude gap from the faintest HI-detected galaxies. The majority (33 out of 44) of the clouds are associated with the two galaxies with the most HI in the cluster -- NGC 1365 and NGC 1427A, although the clouds contribute a negligible amount to the total MHI budget. By performing a SNR analysis and computing the Rauzy statistic on the HI detections, we demonstrate that our catalogue is complete down log(MHI/Msun) = 6, and we are therefore able to probe the HIMF down to this level. We find an abrupt drop of the number density of HI-detected galaxies at log(MHI/Msun) = 7, signifying a clear absence of galaxies between 6 7, the range where the HIMF follows a power-law. The measured low-mass slope is $α$ = -1.31 $\pm$ 0.13, with a characteristic knee mass of log(M*/Msun) = 10.52 $\pm$ 1.89. The low-mass slope matches the slope in the field, while the knee is defined by a single galaxy and is unconstrained. Below log(MHI/Msun) = 7, there is a sharp departure from a Schechter function, and we report the first robust measurement of the collapse of a HIMF. For the HIMF below log(MHI/Msun) = 7 to follow a power-law, tens of galaxies are needed -- a factor ~ six higher than what is observed. The collapse of the Fornax HIMF is likely due to the rapid removal of HI from low-mass galaxies.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.15795" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.15795" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.15795" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Large-Scale Structure, Weak Lensing, Cosmological Constraints / Galaxy Clustering, Weak Lensing, Halo Modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">19. Collision frequency between dark matter subhaloes within Milky Way-like galaxies
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Koki Otaki, Yudai Kazuno, Masao Mori</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Dark Matter Subhaloes within massive host galaxies collide frequently, with N-body simulations and analytical models showing that violent encounters occur on timescales significantly shorter than the host halo&#39;s dynamical time, averaging $2.1\times 10^2\,\mathrm{Gyr}^{-1}$. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">In the standard cold dark matter (CDM) model, sub-galactic structures hierarchically collide and merge to build up larger structures. Mergers and collisions between dwarf galaxies and dark matter subhaloes (DMSHs) play an important role in the evolution and formation of structures within a massive galaxy. We investigate the collision frequency between DMSHs associated with a massive host galaxy such as the Milky Way. We analytically estimate the density distribution of DMSH pairs for the relative distance and relative velocity ($r_\mathrm{rel}$-$v_\mathrm{rel}$) and the distance from the centre of the host halo and relative velocity ($r$-$v_\mathrm{rel}$) planes, based on the distribution function of the host halo in the phase space. Then, we evaluate the collision frequencies of DMSHs by integrating the orbital evolution of DMSHs in Milky-Way-like host haloes selected from cosmological $N$-body simulations. The frequency of violent encounters, in which the relative distance of DMSHs is shorter than the sum of scale radii, is averaged as $2.1\times 10^2\,\mathrm{Gyr}^{-1}$. Since the time scale of violent encounters, $4.7\,\mathrm{Myr}$, is shorter than the dynamical time of the host halo, collisions between DMSHs occur frequently within the host halo. Although interactions between DMSHs produce pairs with higher relative velocities, the density distributions of all and colliding pairs between DMSHs provided by numerical results are approximately similar to those of the analytical model neglecting the interactions of DMSHs on $r_\mathrm{rel}$-$v_\mathrm{rel}$ plane for all pairs and $r$-$v_\mathrm{rel}$ plane for colliding pairs. We compare our results with observed colliding dwarf galaxies and provide insight into the abundance of DMSHs.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.16464" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.16464" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.16464" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Large-Scale Structure, Weak Lensing, Cosmological Constraints / Galaxy Clustering, Weak Lensing, Halo Modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">20. Ten years of extreme gravity tests of general theory of relativity with gravitational-wave observations
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Anuradha Gupta</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Gravitational wave observations from coalescing compact binaries provide the primary means to test General Relativity in the extreme gravity regime, necessitating continued refinement of methods to detect potential violations of Einstein&#39;s theory. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Ten years ago, the first direct detection of gravitational waves (GWs) from the merger of two black holes, GW150914, provided the very first opportunity to test Einstein&#39;s general theory of relativity (GR) in the extreme gravity regime, where the gravitational field is strong, characteristic speeds are highly relativistic, and spacetime is dynamical. Such a regime is currently accessible only through coalescing compact binaries. In this review, we summarize the status of testing GR with GW observations and discuss the lessons learned. We also touch upon the challenges we currently have in testing GR and the potential path forward to detect a credible violation of GR, should one exist in the data.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.15890" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.15890" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.15890" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">gr-qc</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">21. Do z&gt;6 quasars reside in protoclusters?
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Fabio Fontanot, Roberto Decarli, Gabriella De Lucia, Olga Cucciati, Lizhi Xie, Michaela Hirschmann</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Analysis using the GAEA model indicates that luminous high-redshift quasars reside in varied environments and only weakly trace the progenitors of massive galaxy clusters observed in the local universe. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We discuss the properties of a sample of z&gt;6 bright (bolometric luminosity L$_{\rm bolo}$&gt;10$^{46.25}$ erg/s) Quasars drawn from a realization of the GAlaxy Evolution and Assembly (GAEA) model coupled with the Planck Millennium Simulation. We focus on the properties and environment of host galaxies, and their evolution down to z=0, with the aim of assessing how well the bright high redshift QSOs population traces the progenitors of most massive haloes in the local Universe. Our results show that at z&gt;6 bright QSOs live in a variety of environments, and that secular processes like disc instability are responsible for triggering roughly the same number of QSOs as galaxy mergers. Half of cubic (7.5 $h^{-1}$ cMpc size) mock fields built around these high-z QSOs include other active galaxies (with L$_{\rm bolo}$&gt;10$^{44}$ erg/s) in sizeable number, the other host galaxies being relatively isolated. The large field-to-field variance in the the number of companions (both active and non-active) recently reported from JWST observations is fairly well reproduced by GAEA predictions. Descendants of host galaxies at z=0 cover a wide range of physical properties and environments with only a small fraction of the hosts of high-z QSOs ending up in massive galaxy clusters. Viceversa, GAEA predicts that only a small fraction of Bright Central Galaxies have a bright z&gt;6 QSOs among their progenitors. Our results suggest that luminous high-z QSO loosely trace the progenitors of low-z galaxy clusters, and that additional information about the environment of high-z QSOs are required to identify the most promising proto-cluster candidates.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.15789" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.15789" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.15789" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Large-Scale Structure, Weak Lensing, Cosmological Constraints / Galaxy Clustering, Weak Lensing, Halo Modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">22. Dark energy after pre-recombination early dark energy in light of DESI DR2 and the latest ACT and SPT data
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Hao Wang, Yun-Song Piao</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Incorporating Early Dark Energy to address the Hubble tension significantly weakens the observational preference for evolving dark energy, rendering a canonical quintessence-like component consistent with the tightest current cosmological constraints from CMB and DESI data. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">It has been noted that with the pre-recombination early dark energy (EDE) resolution of Hubble tension, the preference of recent datasets for the evolving dark energy (DE) can be suppressed significantly. In this work, we clarify and reconfirm this result with DESI DR2 and the latest ACT DR6 and SPT-3G D1, the tightest small-scale CMB constraints up to date. In the $w_0w_a$CDM model with EDE, a quintessence-like component ($w_0+w_a\geq-1$) can be 1$σ$ consistent with Planck+ACT+SPT+DESI+Pantheon+SH0ES datasets, and $Δχ^2\lesssim -14$ compared with $w_0w_a$CDM model without EDE. This reveals the possibility that when the potential resolutions of Hubble tension are considered, current accelerated expansion can attribute to a canonical evolving scalar field or cosmological constant, and again highlights the importance of re-examining the nature of DE within the broader context of cosmological tensions.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.16606" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.16606" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.16606" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">23. Comment to Comment to Black Hole in Dehnen $\left(1,4,\frac{1}{2}\right)$ Dark Matter Halo: Exact Solution, Lensing, Light Ring, and Thermodynamics
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>David Senjaya</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A recent critique asserting that typographical errors invalidate the foundational results of a prior work is dismissed as unfounded, confirming the original analyses and physical interpretations remain fully valid. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The claim in \cite{Al-Badawi:2025ipr} that *&#34;the errors in the foundational components (3) and (5) of Ref. [1] invalidate all subsequent analyses, numerical results, and physical interpretations that depend on them&#34;* is **entirely unfounded**. This statement reflects a fundamental misunderstanding of the typographical nature of the error and appears to be a misplaced critique originating from a competing author, rather than a substantive assessment of the results, which remain fully valid.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.15748" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.15748" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.15748" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">gr-qc</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">24. Asteroid phase curve modeling with empirical correction for shape and viewing geometry
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Dagmara Oszkiewicz. Przemysław Bartczak, Milagros Colazo, Antti Penttilä</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A novel empirical technique normalizes sparse asteroid photometry to a pole-on geometry using precomputed spin-and-shape models, facilitating consistent phase-curve fitting and establishing new, physically motivated constraints for the H,G phase function parameters. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We present a novel empirical method for correcting asteroid phase curves for rotational and geometrical effects using precomputed spin-and-shape models. Our approach normalizes sparse photometric data to a pole-on geometry, enabling consistent phase-curve fitting across apparitions. We fit both the H,G1,G2 and H,G12 phase functions to the normalized data. We also numerically derive new constraints on parameter ranges that ensure physically meaningful solutions. These constraints are based on the requirement that the reduced magnitude must monotonically decrease with phase angle and remain within plausible slope bounds. Compared to earlier bounds, our new constraints are more permissive. We also compare derivative-based and derivative-free optimization methods, highlighting convergence issues with the HG12 function and offering mitigation strategies. We applied our method to over 25,000 asteroids observed by the ATLAS survey, demonstrating its usability. The new method enables the selection of the preferred spin-and-shape solution based on either statistical phase-curve model selection criteria and/or physically motivated constraints on the phase-curve shape.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.16237" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.16237" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.16237" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">astro-ph.EP</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">25. Constraining interacting dark energy models with black hole superradiance
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Zhen-Hong Lyu, Rong-Gen Cai, Shao-Jiang Wang, Xiang-Xi Zeng</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Black hole superradiance is proposed as a novel astrophysical probe to constrain Dark Energy-Dark Matter coupling by measuring changes in the effective mass and instability rate of ultralight bosons around spinning black holes. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The recent preference for a dynamical dark energy (DE) from the Dark Energy Spectroscopic Instrument seems to call for interactions between DE and dark matter (DM), either from direct DM-DE interaction or indirect interaction induced by modified gravity. Therefore, an independent probe for these kinds of DE-DM interactions would be appealing from observational aspects. In this paper, we propose the black hole superradiance as a novel astrophysical probe for field-theoretic interacting DE-DM models, providing complementary constraints independent of large-scale cosmological observations. The core principle is that the DE-DM interaction can alter the effective mass of the superradiant ultralight boson, thereby modifying its superradiant instability rate around spinning black holes. We explore this connection through two distinct scenarios: a model where the DE field mediates a dark fifth force within the DM sector, affecting the superradiance from DM particles; and a novel mechanism where the DE field itself becomes superradiant due to the effective mass enhancement induced by dense DM spikes around supermassive black holes. By applying a statistical framework to black hole observations in both scenarios, we derive constraints on the fundamental DE-DM coupling strength. Although the current constraints are rather loose due to small samples and inaccurate measurements, our work provides new astrophysical constraints on these interacting DE-DM scenarios and establishes a new synergy between black hole physics and cosmology for probing the fundamental nature of the dark sector.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.16244" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.16244" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.16244" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">26. k-inflation: Non-separable case meets ACT measurements
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Tahere Fallahi Serish, Seyed Ali Hosseini Mansoori, Fereshteh Felegary, Özgür Akarsu, Mohamad Sami</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Closed analytic expressions for the inflationary observables $n_s(N_\ast)$ and $r(N_\ast)$ are derived for a non-separable $k$-essence model featuring an $X^\rho V(\phi)$ coupling, demonstrating a controlled shift in predictions while maintaining a constant sound speed. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We investigate a non-separable subset of $k$-essence in which the kinetic and potential sectors interact through an $X^ρV(φ)$ coupling, implemented via a potential-dependent prefactor $f(φ)=1+2\mathcal{K}V$. In slow roll, this structure preserves a constant sound speed $c_s^2=1/(2ρ-1)$ while modifying the Hubble flow in a controlled way, thereby shifting the inflationary observables relative to the separable template. For monomial potentials $V=Aφ^n$ (with $n=2$ and $n=2/3$ as representative cases) we derive closed analytic expressions for $n_s(N_\ast)$ and $r(N_\ast)$ to $\mathcal{O}(ε_{\rm mix}^2)$, where $ε_{\rm mix}\propto\mathcal{K}$ encodes the non-separable $X^ρV$ mixing, and we validate them against exact background integrations. The analytic and numerical predictions agree at the sub-per-mille level for $n_s$ and at the percent level for $r$, confirming the accuracy of the small-mixing expansion. For $\mathcal{K}0$, $ρ&gt;\tfrac12$, and the positivity bound $V0$). We also discuss parameter dependence and the expected equilateral-type non-Gaussianity, which remains comfortably within current bounds for the benchmarks considered.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.16621" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.16621" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.16621" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">gr-qc</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">27. Effects of New Forces on Scalar Dark Matter Solitons
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Alize Sucsuzer, Mark P. Hertzberg, Michiru Uwabo-Niibo</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The introduction of a light mediator communicating a new force between light bosonic dark matter particles modifies the density-radius relationship of gravitationally bound solitons (boson stars), providing a slight improvement in fitting observed galactic core data. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">New long range forces acting on ordinary matter are highly constrained. However it is possible such forces act on dark matter, as it is less constrained observationally. In this work, we consider dark matter to be made of light bosons, such as axions. We introduce a mediator that communicates a new force between dark matter particles, in addition to gravity. The mediator is taken to be light, but not massless, so that it can affect small scale galactic behavior, but not current cosmological behavior. As a concrete application of this idea, we analyze the effects on scalar dark matter solitons bound by gravitation, i.e., boson stars, which have been claimed to potentially provide cores of galaxies. We numerically determine the soliton&#39;s profiles in the presence of this new force. We also extend the analysis to multiple mediators. We show that this new force alters the relation between core density and core radius in a way that can provide improvement in fitting data to observed galactic cores, but for couplings of order the gravitational strength, the improvement is only modest.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.15916" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.15916" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.15916" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">28. The Noisy Universe
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Gabriela Barenboim, Aurora Ireland, Albert Stebbins</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Stringent upper bounds derived from the non-detection of large-scale white noise constrain the primordial power spectrum, necessitating a deviation from scale invariance on small scales through either a high-wavenumber cutoff or significant running of the spectral index. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We present observational constraints on large-scale white noise (LSWN) in the cosmic density field, a phenomenon predicted to arise from non-linear mode coupling during cosmological evolution. Building on the theoretical framework of Paper I, where we demonstrated that non-linearities inevitably redistribute power from small to large scales through mode mixing, we confront these predictions with current cosmological data. We modify the CLASS Boltzmann code to incorporate a white noise component $k_\mathrm{BH}/k$ in the primordial power spectrum and perform parameter estimation using current cosmological data. The non-detection of excess power on the largest observable scales places stringent upper bounds: $k_\mathrm{BH} \leq 1.80 \times 10^{-13}~\mathrm{Mpc}^{-1}$ at 99\% confidence. These constraints imply the primordial power spectrum must deviate from perfect scale invariance on small scales, either through a cutoff at $k_{\mathrm{cut}} \lesssim 3~\mathrm{pc}^{-1}$ or through running of the spectral index with $α_s \lesssim -0.015$. Our results demonstrate that LSWN provides a powerful probe of the primordial spectrum at scales orders of magnitude smaller than directly observable, offering unique constraints on early-universe physics.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.15803" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.15803" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.15803" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">29. Implicit and explicit treatments of model error in numerical simulation
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Danny Smyl</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A comprehensive review surveys two decades of techniques, such as Bayesian frameworks and machine learning corrections, developed to implicitly and explicitly quantify and account for model errors stemming from unmodeled physics and discretization in computational physics simulations. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Numerical simulations of physical systems invariably suffer from model errors stemming from unmodeled physics, idealizations, and discretization. This article provides a review of techniques developed in the past two decades to approximate and account for these model errors, both implicitly and explicitly. Beginning from fundamental definitions of model-form versus numerical error, we frame model error in inverse problems, data assimilation, and predictive modeling contexts. We then survey major approaches: the Bayesian approximation error framework for implicit error quantification, embedded internal error models for structural uncertainty, probabilistic numerical methods for discretization uncertainty, model discrepancy modeling in Bayesian calibration and its recent extensions, machine-learning-based discrepancy correction, multi-fidelity and hybrid modeling strategies, as well as residual-based, variational, and adjoint-driven error estimators. Throughout, we emphasize conceptual underpinnings of implicit versus explicit error treatment and highlight how these methods improve predictive performance and uncertainty quantification in practical applications ranging from engineering design to Earth-system science. Each section provides an overview of key developments with an extensive list of references to facilitate further reading. The review is written for practitioners of large-scale computational physics and engineering simulation, emphasizing how these methods can be incorporated into PDE solvers, inverse problem workflows, and data assimilation systems.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.15934" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.15934" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.15934" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">physics.comp-ph</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">30. Axiverse Baryogenesis
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Pouya Asadi, David Cyncynates, Stefania Gori</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The axiverse framework resolves tensions in minimal QCD axiogenesis by allowing the QCD axion to be a linear combination of multiple fields, which introduces dissipation channels that prevent dark matter overclosure while maintaining high axion quality. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The QCD axion may offer a unified origin for the baryon asymmetry and dark matter through axiogenesis. However, in the minimal QCD axion scenario, axiogenesis either underproduces baryons or overproduces dark matter, and the required kinetic misalignment initial conditions are in tension with axion quality. In this \textit{Letter}, we demonstrate that the axiverse naturally resolves these tensions: the QCD axion emerges as a linear combination of multiple axion-like fields, evading the overclosure problem thanks to new dissipation channels , while introducing additional Peccei--Quinn symmetries that ensure a high quality QCD axion. We illustrate these points in a toy model with two axions. This framework predicts a rich phenomenology within experimental reach, including dark matter detection prospects, astrophysical signals, and collider signatures.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.15794" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.15794" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.15794" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">hep-ph</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">31. Cosmological Constraints on the Phenomenological Interacting Dark Energy Model with Fermi Gamma-Ray Bursts and DESI DR2
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Ziyan Zhu, Qingquan Jiang, Yu Liu, Puxun Wu, Nan Liang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Cosmological constraints derived from Fermi gamma-ray bursts and DESI BAO data show that the phenomenological interacting dark energy model is consistent with the standard $\Lambda$CDM model at the $1\sigma$ confidence level. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">In this work, we constrain the phenomenological interacting dark energy (IDE) model using \emph{Fermi} gamma-ray burst (GRB) dataset and the latest baryon acoustic oscillation (BAO) data from the Dark Energy Spectroscopic Instrument (DESI) Data Release 2 (DR2). Through a joint Bayesian analysis, we perform a cosmological comparative assessment of the $Λ$CDM, $w$CDM, and CPL models with the phenomenological IDE model. For the phenomenological IDE model in a flat universe, we obtain: $ξ=2.644^{+1.144}_{-0.933}$, $ξ+ 3w_X = -1.001^{+2.827}_{-3.153}$ with the GOLD sample ($z \geq 1.4$) and DESI DR2; and $ξ=2.879^{+0.995}_{-0.990}$, $ξ+ 3w_X = 0.086^{+1.365}_{-1.440}$ with the FULL sample ($z \geq 1.4$) and DESI DR2. Our analysis shows that the $Λ$CDM model without interaction are consistent with the latest \emph{Fermi} sample and DESI DR2 at $1σ$ confidence level.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.16032" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.16032" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.16032" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">32. OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Kaichen Zhang, Keming Wu, Zuhao Yang, Kairui Hu, Bin Wang, Ziwei Liu, Xingxuan Li, Lidong Bing</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A transparent, two-stage training recipe called OpenMMReasoner, combining supervised fine-tuning and reinforcement learning with rigorously validated datasets, significantly improves multimodal reasoning performance, surpassing baselines by 11.6%. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Recent advancements in large reasoning models have fueled growing interest in extending such capabilities to multimodal domains. However, despite notable progress in visual reasoning, the lack of transparent and reproducible data curation and training strategies remains a major barrier to scalable research. In this work, we introduce OpenMMReasoner, a fully transparent two-stage recipe for multimodal reasoning spanning supervised fine-tuning (SFT) and reinforcement learning (RL). In the SFT stage, we construct an 874K-sample cold-start dataset with rigorous step-by-step validation, providing a strong foundation for reasoning capabilities. The subsequent RL stage leverages a 74K-sample dataset across diverse domains to further sharpen and stabilize these abilities, resulting in a more robust and efficient learning process. Extensive evaluations demonstrate that our training recipe not only surpasses strong baselines but also highlights the critical role of data quality and training design in shaping multimodal reasoning performance. Notably, our method achieves a 11.6% improvement over the Qwen2.5-VL-7B-Instruct baseline across nine multimodal reasoning benchmarks, establishing a solid empirical foundation for future large-scale multimodal reasoning research. We open-sourced all our codes, pipeline, and data at https://github.com/EvolvingLMMs-Lab/OpenMMReasoner.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.16334" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.16334" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.16334" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms / Representation Learning, Neural Architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">33. Finite-Dimensional ZX-Calculus for Loop Quantum Gravity
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Ben Priestley</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Canonical Loop Quantum Gravity calculations, including the Penrose Spin Calculus, are translated into the finite-dimensional ZX-calculus, establishing a flexible, high-level graphical language for handling changing spin network structures. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Loop quantum gravity (LQG) attempts to unify general relativity with quantum physics to offer a complete description of the universe by quantising spacetime geometry, but the numerical calculations we encounter are extraordinarily difficult. Progress has been made in the covariant formulation of LQG, but the tools do not carry over to the canonical formulation. These tools are graphical by nature, describing space with spin networks to make calculations in LQG more intuitive to the human hand. Recently, a new notation for working with spin networks has been used by arXiv:2412.20272 to offer the first accurate numerical results in canonical LQG by allowing the underlying graphs to change throughout the calculation, though they are forced to concede visual intuitiveness. In this thesis, we offer a more radical rephrasing of spin network calculations by translating them into the finite-dimensional ZX-calculus, extending previous attempts to translate into the standard (qubit) ZX-calculus (arXiv:2111.03114). Specifically, we derive the mixed-dimensional ZX-diagrams representing the generating objects of spin networks and the rules for the Penrose Spin Calculus (arXiv:2511.06012), and use these to present the ZX-form and correctness of &#34;loop removal&#34;. We also derive the forms for several fundamental LQG objects in the finite-dimensional ZX-calculus for the first time. This gives us a high-level, intuitive graphical language that retains a flexibility to handle changing graph structures, and thus we argue positions the PSC as the new definitive language for canonical LQG. Furthermore, we investigate the possibility for a matrix-like normal form for spin networks deriving from a novel perspective of the PSC in terms of W-nodes.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.15966" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.15966" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.15966" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">gr-qc</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">34. FlipVQA-Miner: Cross-Page Visual Question-Answer Mining from Textbooks
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Zhen Hao Wong, Jingwen Deng, Hao Liang, Runming He, Chengyu Shen, Wentao Zhang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> An automated pipeline leverages layout-aware OCR and large language model semantic parsing to accurately extract high-quality, aligned Question-Answer pairs from educational documents, providing a practical, scalable source of supervision data for reasoning-oriented LLMs. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The development of Large Language Models (LLMs) increasingly depends on high-quality supervised data, yet existing instruction-tuning and RL datasets remain costly to curate and often rely on synthetic samples that introduce hallucination and limited diversity. At the same time, textbooks and exercise materials contain abundant, high-quality human-authored Question-Answer(QA) content that remains underexploited due to the difficulty of transforming raw PDFs into AI-ready supervision. Although modern OCR and vision-language models can accurately parse document structure, their outputs lack the semantic alignment required for training. We propose an automated pipeline that extracts well-formed QA and visual-QA (VQA) pairs from educational documents by combining layout-aware OCR with LLM-based semantic parsing. Experiments across diverse document types show that the method produces accurate, aligned, and low-noise QA/VQA pairs. This approach enables scalable use of real-world educational content and provides a practical alternative to synthetic data generation for improving reasoning-oriented LLM training. All code and data-processing pipelines are open-sourced at https://github.com/OpenDCAI/DataFlow.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.16216" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.16216" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.16216" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.01</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms / Representation Learning, Neural Architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">35. Modular TM$_1$ mixing in light of precision measurement in JUNO
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Wen-Hao Jiang, Ruiwen Ouyang, Ye-Ling Zhou</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Analyzing modular $S_4$ symmetry models that predict the trimaximal TM$_1$ leptonic mixing pattern, three distinct model-building strategies are shown to produce unique, distinguishable predictions for the CP-violating phase and neutrinoless double beta decay effective mass. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">This paper investigates the landscape of models based on modular $S_4$ symmetry that predicts the trimaximal TM$_1$ mixing pattern for leptonic flavor mixing, and explores their parameter spaces with constraints from the latest high-precision measurement on $θ_{12}$ and $Δm^2_{21}$ given by JUNO experiment. We review on how the mixing pattern arises from residual symmetries after the spontaneous breaking of a flavor symmetry, via an appropriate vacuum alignment of modular fields and flavon fields. We show three different models that realize the TM$_1$ in three approaches with the same symmetry structure. Due to different model building strategies used, predictions on the CP-violating phase and the effective mass in neutrinoless double beta decay are different, making them distinguishable.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.16348" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.16348" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.16348" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">hep-ph</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">36. Uncertainty-Resilient Multimodal Learning via Consistency-Guided Cross-Modal Transfer
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Hyo-Jeong Jang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Uncertainty-resilient multimodal learning is achieved through consistency-guided cross-modal transfer, which projects heterogeneous data into a shared latent space to improve model stability, discriminative ability, and robustness against noisy supervision. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Multimodal learning systems often face substantial uncertainty due to noisy data, low-quality labels, and heterogeneous modality characteristics. These issues become especially critical in human-computer interaction settings, where data quality, semantic reliability, and annotation consistency vary across users and recording conditions. This thesis tackles these challenges by exploring uncertainty-resilient multimodal learning through consistency-guided cross-modal transfer. The central idea is to use cross-modal semantic consistency as a basis for robust representation learning. By projecting heterogeneous modalities into a shared latent space, the proposed framework mitigates modality gaps and uncovers structural relations that support uncertainty estimation and stable feature learning. Building on this foundation, the thesis investigates strategies to enhance semantic robustness, improve data efficiency, and reduce the impact of noise and imperfect supervision without relying on large, high-quality annotations. Experiments on multimodal affect-recognition benchmarks demonstrate that consistency-guided cross-modal transfer significantly improves model stability, discriminative ability, and robustness to noisy or incomplete supervision. Latent space analyses further show that the framework captures reliable cross-modal structure even under challenging conditions. Overall, this thesis offers a unified perspective on resilient multimodal learning by integrating uncertainty modeling, semantic alignment, and data-efficient supervision, providing practical insights for developing reliable and adaptive brain-computer interface systems.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.15741" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.15741" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.15741" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms / Representation Learning, Neural Architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">37. A Hybrid Proactive And Predictive Framework For Edge Cloud Resource Management
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Hrikshesh Kumar, Anika Garg, Anshul Gupta, Yashika Agarwal</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A proactive hybrid architecture for cloud edge resource management integrates CNN-LSTM forecasting directly into a multi-agent Deep Reinforcement Learning orchestrator, enabling smarter, long-term decisions that balance cost savings and system performance. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Old cloud edge workload resource management is too reactive. The problem with relying on static thresholds is that we are either overspending for more resources than needed or have reduced performance because of their lack. This is why we work on proactive solutions. A framework developed for it stops reacting to the problems but starts expecting them. We design a hybrid architecture, combining two powerful tools: the CNN LSTM model for time series forecasting and an orchestrator based on multi agent Deep Reinforcement Learning In fact the novelty is in how we combine them as we embed the predictive forecast from the CNN LSTM directly into the DRL agent state space. That is what makes the AI manager smarter it sees the future, which allows it to make better decisions about a long term plan for where to run tasks That means finding that sweet spot between how much money is saved while keeping the system healthy and apps fast for users That is we have given it eyes in order to see down the road so that it does not have to lurch from one problem to another it finds a smooth path forward Our tests show our system easily beats the old methods It is great at solving tough problems like making complex decisions and juggling multiple goals at once like being cheap fast and reliable</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.16075" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.16075" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.16075" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms / Representation Learning, Neural Architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">38. Bias Reduction for nonparametric Estimators applied to functional Data Analysis
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Melanie Birke, Tim Greger</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Bias-corrected kernel estimators are proposed for functional data models to mitigate the large bias inherent in existing nonparametric methods, achieving a smaller bias order and maintaining the original variance magnitude while demonstrating asymptotic normality. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Compared to nonparametric estimators in the multivariate setting, kernel estimators for functional data models have a larger order of bias. This is problematic for constructing confidence regions or statistical tests since the bias might not be negligible. It stems from the fact that one sided kernels are used where already the first moment of the kernel is different from 0. It cannot be cured by assuming the existence of higher order derivatives. In the following, we propose bias corrected estimators based on the idea in \cite{Cheng2018} which still have an appealing structure, but have a bias of smaller order as in multiple regression settings while the variance is of the same order of magnitude as before. In addition we show asymptotic normality of such estimators and derive uniform rates. The performance of the estimator in finite samples is in addition checked in a simulation study.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.16389" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.16389" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.16389" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">math.ST</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">39. Revisiting Fairness-aware Interactive Recommendation: Item Lifecycle as a Control Knob
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Yun Lu, Xiaoyu Shi, Hong Xie, Chongjun Xia, Zhenhui Gong, Mingsheng Shang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A lifecycle-aware hierarchical reinforcement learning framework (LHRL) dynamically harmonizes fairness and accuracy in interactive recommendation systems by detecting the compressed three-phase item lifecycle and applying phase-specific exposure constraints. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">This paper revisits fairness-aware interactive recommendation (e.g., TikTok, KuaiShou) by introducing a novel control knob, i.e., the lifecycle of items. We make threefold contributions. First, we conduct a comprehensive empirical analysis and uncover that item lifecycles in short-video platforms follow a compressed three-phase pattern, i.e., rapid growth, transient stability, and sharp decay, which significantly deviates from the classical four-stage model (introduction, growth, maturity, decline). Second, we introduce LHRL, a lifecycle-aware hierarchical reinforcement learning framework that dynamically harmonizes fairness and accuracy by leveraging phase-specific exposure dynamics. LHRL consists of two key components: (1) PhaseFormer, a lightweight encoder combining STL decomposition and attention mechanisms for robust phase detection; (2) a two-level HRL agent, where the high-level policy imposes phase-aware fairness constraints, and the low-level policy optimizes immediate user engagement. This decoupled optimization allows for effective reconciliation between long-term equity and short-term utility. Third, experiments on multiple real-world interactive recommendation datasets demonstrate that LHRL significantly improves both fairness and user engagement. Furthermore, the integration of lifecycle-aware rewards into existing RL-based models consistently yields performance gains, highlighting the generalizability and practical value of our approach.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.16248" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.16248" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.16248" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms / Representation Learning, Neural Architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">40. Search for Ultralight Dark Matter with Quantum Magnetometry in the Earth&#39;s Cavity
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">Ariel Arza, Yuanlin Gong, Jun Guo, Xiaofei Huang, Jing Shu, Hongliang Tian, Wenyu Wang, Kai Wei, Lei Wu, Mingming Xia, et al.</span>
                                <span class="author-full" style="display: none;">Ariel Arza, Yuanlin Gong, Jun Guo, Xiaofei Huang, Jing Shu, Hongliang Tian, Wenyu Wang, Kai Wei, Lei Wu, Mingming Xia, Jin Min Yang, Qiang Yuan, Yang Zhang, Yi Zhang, Bin Zhu</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Using an unshielded atomic magnetometer (GPEX) within the Earth resonant cavity, a search for ultralight axion and dark photon dark matter established new constraints on the axion-photon coupling and the dark photon kinetic-mixing parameter in the low mass range. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Ultralight dark matter candidates, such as axions and dark photons, are leading dark matter candidates. They may couple feebly to photons, sourcing oscillating electromagnetic signals in the presence of magnetic field. The Earth resonant cavity formed between the ground and the ionosphere provides a natural waveguide that can amplify such signals. We carry out a project aiming to search for new physics using the unshielded high-sensitivity atomic magnetometer, termed the Geomagnetic Probe for nEw physiCS (GPEX). In this work, we report our first search for axion and dark photon dark matter, conducted in the desert of XiaoDushan in Gansu Province, China. Analysis of the collection of one-hour data shows no evidence for axion- or dark photon-induced magnetic signals. Correspondingly, we set the constraints on the axion-photon coupling with $g_{aγγ} &lt; 7\times10^{-10}\, \mathrm{GeV^{-1}}$ and the dark photon kinetic-mixing parameter $ε&lt; 2\times10^{-6}$ in the mass range $3.5 \times 10^{-16}\, \mathrm{eV} \sim 1.8 \times 10^{-14}\, \mathrm{eV}$. Our findings demonstrate the feasibility of using ground-based quantum magnetic sensors for ultralight dark matter searches. Future networks of such detectors operating over extended periods could further enhance sensitivity, approaching the limits set by astrophysical observations.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.16553" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.16553" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.16553" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">hep-ph</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">41. Multidimensional Rubric-oriented Reward Model Learning via Geometric Projection Reference Constraints
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Yongnan Jin, Xurui Li, Feng Cao, Liucun Gao, Juanjuan Yao</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A novel alignment framework, MR-RML, uses structured medical standards and geometric projection constraints to significantly boost the clinical reasoning and performance of large language models on authoritative medical benchmarks. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The integration of large language models (LLMs) into medical practice holds transformative potential, yet their real-world clinical utility remains limited by critical alignment challenges: (1) a disconnect between static evaluation benchmarks and dynamic clinical cognitive needs, (2) difficulties in adapting to evolving, multi-source medical standards, and (3) the inability of conventional reward models to capture nuanced, multi-dimensional medical quality criteria. To address these gaps, we propose MR-RML (Multidimensional Rubric-oriented Reward Model Learning) via GPRC (Geometric Projection Reference Constraints), a novel alignment framework that integrates medical standards into a structured &#34;Dimensions-Scenarios-Disciplines&#34; matrix to guide data generation and model optimization. MR-RML introduces three core innovations: (1) a &#34;Dimensions-Scenarios-Disciplines&#34; medical standard system that embeds domain standards into the full training pipeline; (2) an independent multi-dimensional reward model that decomposes evaluation criteria, shifting from real-time rubric-based scoring to internalized reward modeling for improved consistency and cost-efficiency; (3) geometric projection reference constraints that transform medical cognitive logic into mathematical regularization, aligning scoring gradients with clinical reasoning and enabling synthetic data-driven training. Through extensive evaluations on the authoritative medical benchmark Healthbench, our method yields substantial performance gains over the base LLM Qwen-32B (45% on the full subset and 85% on Hard subset, respectively). It achieves a SOTA among open-source LLMs with scores of 62.7 (full subset) and 44.7 (hard subset), while also outperforming the majority of closed-source models.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.16139" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.16139" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.16139" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms / Representation Learning, Neural Architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">42. Grey-body Factors and Absorption Cross Sections of Non-Commutative Black Holes under Einstein-Coupled Scalar Fields
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>SiHao Fan, Chen Wu, WenJun Guo</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Analyzing scalar field perturbations around non-commutative black holes reveals that increased non-commutativity and coupling parameters diminish absorption cross-sections, confirming the grey-body factor/quasinormal mode correspondence in the large angular momentum limit. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">This paper investigates scalar field perturbations coupled to the Einstein tensor of non-commutative black holes . We compute the grey-body factors and absorption cross-sections for different choices of the parameters using the partial wave method , and verify the latest correspondence between grey-body factors and quasinormal modes. The results show that larger values of the non-commutativity parameter $θ$ and the coupling constant $η$ introduced in this model lead to smaller absorption cross-sections. Furthermore, we find that this correspondence is accurate for non-commutative black holes in the limit of large angular momentum quantum number $l$.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.16012" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.16012" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.16012" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">gr-qc</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">43. From Performance to Understanding: A Vision for Explainable Automated Algorithm Design
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Niki van Stein, Anna V. Kononova, Thomas Bäck</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Future breakthroughs in automated algorithm design require shifting from opaque, performance-driven LLM generation to an explainable framework that systematically benchmarks components and links algorithmic behavior to underlying problem structures for reusable scientific insight. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Automated algorithm design is entering a new phase: Large Language Models can now generate full optimisation (meta)heuristics, explore vast design spaces and adapt through iterative feedback. Yet this rapid progress is largely performance-driven and opaque. Current LLM-based approaches rarely reveal why a generated algorithm works, which components matter or how design choices relate to underlying problem structures. This paper argues that the next breakthrough will come not from more automation, but from coupling automation with understanding from systematic benchmarking. We outline a vision for explainable automated algorithm design, built on three pillars: (i) LLM-driven discovery of algorithmic variants, (ii) explainable benchmarking that attributes performance to components and hyperparameters and (iii) problem-class descriptors that connect algorithm behaviour to landscape structure. Together, these elements form a closed knowledge loop in which discovery, explanation and generalisation reinforce each other. We argue that this integration will shift the field from blind search to interpretable, class-specific algorithm design, accelerating progress while producing reusable scientific insight into when and why optimisation strategies succeed.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.16201" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.16201" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.16201" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">44. A physics-inspired momentum-based gradient method
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Jianing Zhang, Rumei Liu</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A novel nonlinear momentum method, derived from non-Newtonian mechanical dynamics, enhances gradient optimization convergence and robustness by employing anharmonic kinetic energy and nonlinear damping, proving highly effective for nonconvex objectives such as inverse photonic design. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">In this work, a nonlinear momentum method is introduced to improve the convergence performance of momentum-based gradient optimization algorithms. The method is motivated by the dynamics of non-Newtonian mechanical systems, where conventional momentum schemes can be interpreted as a dynamical model with quadratic kinetic energy and linear damping. Based on this analogy, a generalized optimization dynamics is constructed by extending the kinetic energy formulation and incorporating a nonlinear damping term. An anharmonic kinetic energy function can be employed to represent the inertial effect of accumulated gradient information during the iterations, while the nonlinear damping mechanism enables a more flexible control of the momentum contribution along the convergence trajectory. Numerical experiments indicate that the method exhibits faster convergence and higher robustness compared to classical momentum algorithms. Moreover, its strong performance on nonconvex objectives makes it particularly suitable for inverse photonic design problems. The results suggest that dynamical systems from physics can provide a view towards the development of efficient optimization methods.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.16441" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.16441" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.16441" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">physics.comp-ph</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms / Numerical Methods, MCMC, Integral Transforms</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">45. Dark Matter-Dark Radiation Interactions and the Hubble Tension
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Manuel A. Buen-Abad, Zackaria Chacko, Ina Flood, Can Kilic, Gustavo Marques-Tavares, Taewook Youn</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Models featuring interacting dark matter and dark radiation significantly alleviate the Hubble tension when fit to cosmological data excluding ACT DR6, but the inclusion of ACT DR6 data substantially worsens the fit quality and reduces the tension mitigation effect. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Models in which a subcomponent of dark matter interacts with dark radiation have been proposed as a solution to the Hubble tension. In this framework, the interacting subcomponent of dark matter is in thermal equilibrium with the dark radiation in the early universe, but decouples from it around the time of matter-radiation equality. We study this general class of models and evaluate the quality of fit to recent cosmological data on the cosmic microwave background (from Planck 2018 and ACT DR6), baryon acoustic oscillations, large-scale structure, supernovae type Ia, and Cepheid variables. We focus on three benchmark scenarios that differ in the rate at which the dark matter decouples from the dark radiation, resulting in different patterns of dark acoustic oscillations. Fitting without ACT DR6 data, we find that all three scenarios significantly reduce the Hubble tension relative to $Λ$CDM, with an exponentially fast decoupling being the most preferred. The tension is reduced to less than $2 \, σ$ in fits that don&#39;t include the SH0ES collaboration results as part of the data and to less than $1 \, σ$ when these are included. When ACT DR6 data is included, the fit is significantly worsened. We find that the largest $H_0$ value at the $95 \%$ confidence region is $70.1$ km/s/Mpc without the SH0ES data, leading to only a mild reduction in the tension. This increases to $72.5$ km/s/Mpc, corresponding to a reduction in the tension to less than $3 \, σ$, if the SH0ES results are included in the fit.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.16554" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.16554" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.16554" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">46. You Only Forward Once: An Efficient Compositional Judging Paradigm
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Tianlong Zhang, Hongwei Xue, Shilin Yan, Di Wu, Chen Xu, Yunyun Yang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The YOFO method enables Multimodal Large Language Models to function as rapid, interpretable judges by processing structured requirement templates in a single forward pass, yielding significant speedups and state-of-the-art performance on recommendation tasks. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Multimodal large language models (MLLMs) show strong potential as judges. However, existing approaches face a fundamental trade-off: adapting MLLMs to output a single score misaligns with the generative nature of MLLMs and limits fine-grained requirement understanding, whereas autoregressively generating judging analyses is prohibitively slow in high-throughput settings. Observing that judgment reduces to verifying whether inputs satisfy a set of structured requirements, we propose YOFO, a template-conditioned method that judges all requirements in a single forward pass. Built on an autoregressive model, YOFO accepts a structured requirement template and, in one inference step, produces a binary yes/no decision for each requirement by reading the logits of the final token associated with that requirement. This design yields orders-of-magnitude speedups while preserving interpretability. Extensive experiments show that YOFO not only achieves state-of-the-art results on standard recommendation datasets, but also supports dependency-aware analysis-where subsequent judgments are conditioned on previous ones-and further benefits from post-hoc CoT.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.16600" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.16600" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.16600" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms / Representation Learning, Neural Architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">47. SkyRL-Agent: Efficient RL Training for Multi-turn LLM Agent
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">Shiyi Cao, Dacheng Li, Fangzhou Zhao, Shuo Yuan, Sumanth R. Hegde, Connor Chen, Charlie Ruan, Tyler Griggs, Shu Liu, Eric Tang, et al.</span>
                                <span class="author-full" style="display: none;">Shiyi Cao, Dacheng Li, Fangzhou Zhao, Shuo Yuan, Sumanth R. Hegde, Connor Chen, Charlie Ruan, Tyler Griggs, Shu Liu, Eric Tang, Richard Liaw, Philipp Moritz, Matei Zaharia, Joseph E. Gonzalez, Ion Stoica</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The SkyRL-Agent framework, utilizing an optimized asynchronous dispatcher and AST-based tool enhancement, efficiently trains the SA-SWE-32B software engineering agent, achieving state-of-the-art performance on SWE-Bench Verified with significant cost reduction and strong generalization capabilities. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We introduce SkyRL-Agent, a framework for efficient, multi-turn, long-horizon agent training and evaluation. It provides efficient asynchronous dispatching, lightweight tool integration, and flexible backend interoperability, enabling seamless use with existing RL frameworks such as SkyRL-train, VeRL, and Tinker. Using SkyRL-Agent, we train SA-SWE-32B, a software engineering agent trained from Qwen3-32B (24.4% Pass@1) purely with reinforcement learning. We introduce two key components: an optimized asynchronous pipeline dispatcher that achieves a 1.55x speedup over naive asynchronous batching, and a tool-enhanced training recipe leveraging an AST-based search tool to facilitate code navigation, boost rollout Pass@K, and improve training efficiency. Together, these optimizations enable SA-SWE-32B to reach 39.4% Pass@1 on SWE-Bench Verified with more than 2x cost reduction compared to prior models reaching similar performance. Despite being trained solely on SWE tasks, SA-SWE-32B generalizes effectively to other agentic tasks, including Terminal-Bench, BrowseComp-Plus, and WebArena. We further demonstrate SkyRL-Agent&#39;s extensibility through case studies on deep research, computer use, and memory agents, each trained using a different training backend.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.16108" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.16108" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.16108" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms / Representation Learning, Neural Architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">48. Enhancing Forex Forecasting Accuracy: The Impact of Hybrid Variable Sets in Cognitive Algorithmic Trading Systems
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Juan C. King, Jose M. Amigo</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> An advanced AI-based algorithmic trading system for high-frequency EUR-USD Forex utilizes a comprehensive feature set combining fundamental macroeconomic data and technical indicators, with the study concluding by comparing the predictive reliability of these two feature classes for generating profitable signals. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">This paper presents the implementation of an advanced artificial intelligence-based algorithmic trading system specifically designed for the EUR-USD pair within the high-frequency environment of the Forex market. The methodological approach centers on integrating a holistic set of input features: key fundamental macroeconomic variables (for example, Gross Domestic Product and Unemployment Rate) collected from both the Euro Zone and the United States, alongside a comprehensive suite of technical variables (including indicators, oscillators, Fibonacci levels, and price divergences). The performance of the resulting algorithm is evaluated using standard machine learning metrics to quantify predictive accuracy and backtesting simulations across historical data to assess trading profitability and risk. The study concludes with a comparative analysis to determine which class of input features, fundamental or technical, provides greater and more reliable predictive capacity for generating profitable trading signals.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.16657" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.16657" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.16657" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">49. Atlas Gaussian processes on restricted domains and point clouds
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Mu Niu, Yue Zhang, Ke Ye, Pokman Cheung, Yizhu Wang, Xiaochen Yang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> To improve statistical inference on high-dimensional data residing on unknown manifolds, the Riemannian-corrected Atlas Gaussian Processes (RC-AGPs) framework utilizes Atlas Brownian Motion to estimate the global heat kernel, significantly enhancing regression accuracy over existing methods. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">In real-world applications, data often reside in restricted domains with unknown boundaries, or as high-dimensional point clouds lying on a lower-dimensional, nontrivial, unknown manifold. Traditional Gaussian Processes (GPs) struggle to capture the underlying geometry in such settings. Some existing methods assume a flat space embedded in a point cloud, which can be represented by a single latent chart (latent space), while others exhibit weak performance when the point cloud is sparse or irregularly sampled. The goal of this work is to address these challenges. The main contributions are twofold: (1) We establish the Atlas Brownian Motion (BM) framework for estimating the heat kernel on point clouds with unknown geometries and nontrivial topological structures; (2) Instead of directly using the heat kernel estimates, we construct a Riemannian corrected kernel by combining the global heat kernel with local RBF kernel and leading to the formulation of Riemannian-corrected Atlas Gaussian Processes (RC-AGPs). The resulting RC-AGPs are applied to regression tasks across synthetic and real-world datasets. These examples demonstrate that our method outperforms existing approaches in both heat kernel estimation and regression accuracy. It improves statistical inference by effectively bridging the gap between complex, high-dimensional observations and manifold-based inferences.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.15822" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.15822" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.15822" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">stat.ML</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">50. KRAL: Knowledge and Reasoning Augmented Learning for LLM-assisted Clinical Antimicrobial Therapy
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Zhe Li, Yehan Qiu, Yujie Chen, Xiang Zhou</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The KRAL framework enhances local LLMs for complex clinical decision support by using teacher-model reasoning distillation, semi-supervised data augmentation, and agentic reinforcement learning, resulting in superior knowledge and reasoning performance at significantly reduced training costs compared to RAG and SFT. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Clinical antimicrobial therapy requires the dynamic integration of pathogen profiles, host factors, pharmacological properties of antimicrobials, and the severity of infection.This complexity imposes fundamental limitations on the applicability of Large Language Models (LLMs) in high-stakes clinical decision-making including knowledge gaps, data privacy concerns, high deployment costs, and limited reasoning capabilities. To address these challenges, we propose KRAL (Knowledge and Reasoning Augmented Learning), a low-cost, scalable, privacy-preserving paradigm that leverages teacher-model reasoning to automatically distill knowledge and reasoning trajectories via answer-to-question reverse generation, employs heuristic learning for semi-supervised data augmentation (reducing manual annotation requirements by approximately 80%), and utilizes agentic reinforcement learning to jointly enhance medical knowledge and reasoning while optimizing computational and memory efficiency. A hierarchical evaluation employing diverse teacher-model proxies reduces assessment costs, while modular interface design facilitates seamless system updates. Experimental results demonstrate that KRAL significantly outperforms traditional Retrieval-Augmented Generation (RAG) and Supervised Fine-Tuning (SFT) methods. It improves knowledge question-answering capability (Accuracy@1 on the external open-source benchmark MEDQA increased by 1.8% vs. SFT and 3.6% vs. RAG) and reasoning capability (Pass@1 on the external benchmark PUMCH Antimicrobial increased by 27% vs. SFT and 27.2% vs. RAG), achieved at ~20% of SFT&#39;s long-term training costs. This establishes KRAL as an effective solution for enhancing local LLMs&#39; clinical diagnostic capabilities, enabling low-cost, high-safety deployment in complex medical decision support.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.15974" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.15974" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.15974" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Modeling, Sampling Algorithms / Representation Learning, Neural Architectures</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
    </div>

    <footer class="footer">
        &copy; 2025 arXiv Daily · Powered by <a href="https://arxiv.org/" target="_blank">arXiv</a>
    </footer>
</body>
</html>