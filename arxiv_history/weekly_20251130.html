<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>arXiv Daily: Backfill (2025-11-23 to 2025-11-30)</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Roboto:400,700&display=swap" rel="stylesheet">
    <style>
        body { font-family: 'Roboto', Arial, sans-serif; background: #f8f9fa; transition: background 0.3s; }
        .arxiv-card { margin: 2em auto; max-width: 900px; box-shadow: 0 2px 8px rgba(0,0,0,0.08); border-radius: 16px; transition: box-shadow 0.3s, transform 0.3s; }
        .arxiv-card:hover { box-shadow: 0 4px 12px rgba(0,0,0,0.1); transform: translateY(-1px); }
        .arxiv-title { background: linear-gradient(90deg, #0d6efd 60%, #6610f2 100%); color: #fff; border-radius: 16px 16px 0 0; padding: 1.5em; font-size: 1.5em; font-weight: 700; letter-spacing: 0.5px;}
        .arxiv-meta { font-size: 1em; color: #555; margin-bottom: 1em; }
        .arxiv-abstract { background: #fff; padding: 1.5em; border-radius: 0 0 16px 16px; font-size: 1.1em; line-height: 1.7;}
        .arxiv-links a { margin-right: 1em; }
        .arxiv-scores { margin-top: 1em; font-size: 1em; }
        .navbar { background: #fff; box-shadow: 0 2px 8px rgba(0,0,0,0.04);}
        .footer { text-align: center; color: #888; padding: 2em 0 1em 0; font-size: 0.95em;}
        @media (prefers-color-scheme: dark) {
            body { background: #181a1b; color: #e4e6eb; }
            .arxiv-card { background: #23272b; box-shadow: 0 2px 8px rgba(0,0,0,0.28);}
            .arxiv-card:hover { box-shadow: 0 5px 15px rgba(0,0,0,0.25); transform: translateY(-1px); }
            .arxiv-title { background: linear-gradient(90deg, #375a7f 60%, #6f42c1 100%);}
            .arxiv-abstract { background: #23272b; color: #e4e6eb;}
            .navbar { background: #23272b; color: #e4e6eb;}
            .text-muted { color: #adb5bd !important; }
        }
        /* Improved abstract readability */
        .arxiv-abstract-text {
            font-size: 1.1em;
            line-height: 1.7;
        }
        p.big {
            line-height: 1.6;
            font-size: large;
        }
    </style>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'] ],
          processEscapes: true
        }
      });
    </script>
    <script>
    function toggleAuthors(element) {
        const fullList = element.querySelector('.author-full');
        const shortList = element.querySelector('.author-short');
        const toggleText = element.querySelector('.author-toggle');
        
        fullList.style.display = fullList.style.display === 'none' ? 'inline' : 'none';
        shortList.style.display = shortList.style.display === 'none' ? 'inline' : 'none';
        toggleText.textContent = fullList.style.display === 'none' ? ' (show all)' : ' (show less)';
    }
    </script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
</head>
<body>
    <nav class="navbar navbar-expand-lg mb-4">
        <div class="container">
            <a class="navbar-brand fw-bold text-primary" href="#">arXiv Daily</a>
            <span class="navbar-text">Modern arXiv Reader</span>
        </div>
    </nav>

    
    <div class="container py-4">
        <header class="mb-4"><h2 class="display-6 text-center">Analysis of Your Favorites</h2></header>
        
        <div class="row justify-content-center">
            <div class="col-lg-8 mb-4">
                <div class="card">
                    <div class="card-header fw-bold">Interest Word Cloud</div>
                    <div class="card-body text-center p-2">
                        <img src="analysis_results/word_cloud.png" class="img-fluid rounded" alt="Word Cloud of favorite paper topics">
                    </div>
                </div>
            </div>
        </div>
        
        
        <div class="row justify-content-center">
            <div class="col-lg-8 mb-4">
                <div class="card">
                    <div class="card-header fw-bold">Interest Clusters</div>
                    <div class="card-body text-center p-2">
                        <img src="analysis_results/backfill_cluster_map.png" class="img-fluid rounded" alt="2D Cluster plot of favorite papers">
                    </div>
                </div>
            </div>
        </div>
        
    </div>
    

    <div class="container py-4">
        <header class="mb-4"><h1 class="display-5 text-center text-primary">arXiv: Backfill (2025-11-23 to 2025-11-30)</h1></header>

        
        <div class="row justify-content-center">
            <div class="col-lg-8 mb-4">
                <div class="card">
                    <div class="card-header fw-bold">Score Distribution of All Papers Found Today</div>
                    <div class="card-body text-center p-2">
                        <img src="analysis_results/score_distribution.png" class="img-fluid rounded" alt="Score distribution of all papers found today">
                    </div>
                </div>
            </div>
        </div>
        

        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">1. Euclid preparation. Controlling angular systematics in the Euclid spectroscopic galaxy sample
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">Euclid Collaboration, P. Monaco, M. Y. Elkhashab, B. R. Granett, J. Salvalaggio, E. Sefusatti, C. Scarlata, B. Zabelle, M. Bethermin, S. Bruton, et al.</span>
                                <span class="author-full" style="display: none;">Euclid Collaboration, P. Monaco, M. Y. Elkhashab, B. R. Granett, J. Salvalaggio, E. Sefusatti, C. Scarlata, B. Zabelle, M. Bethermin, S. Bruton, C. Carbone, S. de la Torre, S. Dusini, A. Eggemeier, L. Guzzo, G. Lavaux, S. Lee, K. Markovic, K. S. McCarthy, M. Moresco, F. Passalacqua, W. J. Percival, I. Risso, A. G. Sánchez, D. Scott, C. Sirignano, Y. Wang, B. Altieri, S. Andreon, N. Auricchio, C. Baccigalupi, M. Baldi, S. Bardelli, A. Biviano, E. Branchini, M. Brescia, J. Brinchmann, S. Camera, G. Cañas-Herrera, V. Capobianco, V. F. Cardone, J. Carretero, S. Casas, F. J. Castander, M. Castellano, G. Castignani, S. Cavuoti, A. Cimatti, C. Colodro-Conde, G. Congedo, C. J. Conselice, L. Conversi, Y. Copin, F. Courbin, H. M. Courtois, H. Degaudenzi, G. De Lucia, H. Dole, F. Dubath, C. A. J. Duncan, X. Dupac, S. Escoffier, M. Farina, R. Farinelli, S. Ferriol, N. Fourmanoit, M. Frailis, E. Franceschi, M. Fumana, S. Galeotta, K. George, W. Gillard, B. Gillis, C. Giocoli, J. Gracia-Carpio, A. Grazian, F. Grupp, S. V. H. Haugan, W. Holmes, F. Hormuth, A. Hornstrup, K. Jahnke, M. Jhabvala, B. Joachimi, E. Keihänen, S. Kermiche, A. Kiessling, B. Kubik, M. Kümmel, M. Kunz, H. Kurki-Suonio, A. M. C. Le Brun, S. Ligori, P. B. Lilje, V. Lindholm, I. Lloro, G. Mainetti, D. Maino, E. Maiorano, O. Mansutti, S. Marcin, O. Marggraf, M. Martinelli, N. Martinet, F. Marulli, R. J. Massey, E. Medinaceli, S. Mei, Y. Mellier, M. Meneghetti, E. Merlin, G. Meylan, A. Mora, L. Moscardini, C. Neissner, S. -M. Niemi, C. Padilla, S. Paltani, F. Pasian, K. Pedersen, V. Pettorino, S. Pires, G. Polenta, M. Poncet, L. A. Popa, L. Pozzetti, F. Raison, A. Renzi, J. Rhodes, G. Riccio, E. Romelli, M. Roncarelli, E. Rossetti, R. Saglia, Z. Sakr, D. Sapone, B. Sartoris, P. Schneider, T. Schrabback, M. Scodeggio, A. Secroun, G. Seidel, S. Serrano, P. Simon, G. Sirri, A. Spurio Mancini, L. Stanco, J. Steinwagner, C. Surace, P. Tallada-Crespí, A. N. Taylor, H. I. Teplitz, I. Tereno, N. Tessore, S. Toft, R. Toledo-Moreo, F. Torradeflot, I. Tutusaus, L. Valenziano, J. Valiviita, T. Vassallo, A. Veropalumbo, D. Vibert, J. Weller, A. Zacchei, G. Zamorani, F. M. Zerbi, E. Zucca, V. Allevato, M. Ballardini, M. Bolzonella, A. Boucaud, E. Bozzo, C. Burigana, R. Cabanac, M. Calabrese, A. Cappi, J. A. Escartin Vigo, G. Fabbian, L. Gabarra, W. G. Hartley, R. Maoli, J. Martín-Fleitas, S. Matthew, N. Mauri, R. B. Metcalf, A. Pezzotta, M. Pöntinen, V. Scottez, M. Sereno, M. Tenti, M. Viel, M. Wiesmann, Y. Akrami, I. T. Andika, S. Anselmi, M. Archidiacono, F. Atrio-Barandela, S. Avila, D. Bertacca, A. Blanchard, L. Blot, M. Bonici, S. Borgani, M. L. Brown, A. Calabro, B. Camacho Quevedo, F. Caro, C. S. Carvalho, T. Castro, F. Cogato, S. Conseil, A. R. Cooray, O. Cucciati, S. Davini, G. Desprez, A. Díaz-Sánchez, J. J. Diaz, S. Di Domizio, J. M. Diego, A. Enia, Y. Fang, A. G. Ferrari, A. Finoguenov, A. Fontana, A. Franco, J. García-Bellido, T. Gasparetto, V. Gautard, E. Gaztanaga, F. Giacomini, F. Gianotti, G. Gozaliasl, M. Guidi, C. M. Gutierrez, A. Hall, C. Hernández-Monteagudo, H. Hildebrandt, J. Hjorth, S. Joudaki, J. J. E. Kajava, Y. Kang, V. Kansal, D. Karagiannis, K. Kiiveri, J. Kim, C. C. Kirkpatrick, S. Kruk, M. Lattanzi, V. Le Brun, L. Legrand, M. Lembo, F. Lepori, G. Leroy, G. F. Lesci, J. Lesgourgues, L. Leuzzi, T. I. Liaudat, S. J. Liu, A. Loureiro, J. Macias-Perez, M. Magliocchetti, F. Mannucci, C. J. A. P. Martins, L. Maurin, M. Miluzio, C. Moretti, G. Morgante, S. Nadathur, K. Naidoo, A. Navarro-Alsina, S. Nesseris, D. Paoletti, K. Paterson, L. Patrizii, A. Pisani, D. Potter, S. Quai, M. Radovich, G. Rodighiero, S. Sacquegna, M. Sahlén, D. B. Sanders, E. Sarpa, A. Schneider, D. Sciotti, E. Sellentin, L. C. Smith, K. Tanidis, C. Tao, G. Testera, R. Teyssier, S. Tosi, A. Troja, M. Tucci, A. Venhola, D. Vergani, F. Vernizzi, G. Verza, P. Vielzeuf, N. A. Walton</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Using a random catalog constructed from a visibility mask and a redshift detection model, researchers demonstrated that angular systematics in the Euclid spectroscopic survey can be mitigated to recover the galaxy power spectrum with sub-percent accuracy, ensuring robust cosmological parameter estimation. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We present the strategy to identify and mitigate potential sources of angular systematics in the Euclid spectroscopic galaxy survey, and we quantify their impact on galaxy clustering measurements and cosmological parameter estimation. We first survey the Euclid processing pipeline to identify all evident, potential sources of systematics, and classify them into two broad classes: angular systematics, which modulate the galaxy number density across the sky, and catastrophic redshift errors, which lead to interlopers in the galaxy sample. We then use simulated spectroscopic surveys to test our ability to mitigate angular systematics by constructing a random catalogue that represents the visibility mask of the survey; this is a dense set of intrinsically unclustered objects, subject to the same selection effects as the data catalogue. The construction of this random catalogue relies on a detection model, which gives the probability of reliably measuring the galaxy redshift as a function of the signal-to-noise ratio (S/N) of its emission lines. We demonstrate that, in the ideal case of a perfect knowledge of the visibility mask, the galaxy power spectrum in the presence of systematics is recovered, to within sub-percent accuracy, by convolving a theory power spectrum with a window function obtained from the random catalogue itself. In the case of only approximate knowledge of the visibility mask, we test the stability of power spectrum measurements and cosmological parameter posteriors by using perturbed versions of the random catalogue. We find that significant effects are limited to very large scales, and parameter estimation remains robust, with the most impacting effects being connected to the calibration of the detection model.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.20856" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.20856" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.20856" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 14.5</span>
                        <span class="badge bg-info text-dark">Author Score: 0.99</span>
                        <span class="badge bg-primary">Semantic Score: 0.95</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Weak Lensing, Cosmological Constraints, Survey Systematics</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">2. Impact of Simulation Box Size for Weak Lensing: Replication and Super-Sample Effects
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Akira Tokiwa, Adrian E. Bayer, Joaquin Armijo, Jia Liu, Ryo Terasawa, Leander Thiele, Marcelo Alvarez, Linda Blot, Masahiro Takada</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Analysis of weak lensing statistics using small simulation boxes revealed that replication effects cause O(10%) biases in the PDF, Minkowski functionals, and covariances, emphasizing that large simulation volumes are critical for accurate covariance estimation in future surveys. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We quantify the bias caused by small simulation box size on weak lensing observables and covariances, considering both replication and super-sample effects for a range of higher-order statistics. Using two simulation suites -- one comprising large boxes ($3750\,h^{-1}{\rm Mpc}$) and another constructed by tiling small boxes ($625\,h^{-1}{\rm Mpc}$) -- we generate full-sky convergence maps and extract $10^\circ \times 10^\circ$ patches via a Fibonacci grid. We consider biases in the mean and covariance of the angular power spectrum, bispectrum (up to $\ell=3000$), PDF, peak/minima counts, and Minkowski functionals. By first identifying lines of sight that are impacted by replications, we find that replication causes a O$(10\%)$ bias in the PDF and Minkowski functionals, and a O$(1\%)$ bias in other summary statistics. Replication also causes a O$(10\%)$ bias in the covariances, increasing with source redshift and $\ell$, reaching $\sim25\%$ for $z_s=2.5$. We additionally show that replication leads to heavy biases (up to O$(100\%)$ at high redshift) when performing gnomonic projection on a patch that is centered along a direction of replication. We then identify the lines of sight that are minimally affected by replication, and use the corresponding patches to isolate and study super-sample effects, finding that, while the mean values agree to within $1\%$, the variances differ by O$(10\%)$ for $z_s\leq2.5$. We show that these effects remain in the presence of noise and smoothing scales typical of the DES, KiDS, HSC, LSST, Euclid, and Roman surveys. We also discuss how these effects scale as a function of box size. Our results highlight the importance of large simulation volumes for accurate lensing statistics and covariance estimation.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.20423" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.20423" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.20423" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 10.5</span>
                        <span class="badge bg-info text-dark">Author Score: 0.20</span>
                        <span class="badge bg-primary">Semantic Score: 0.95</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">3. The Speed of Gravity and the Fate of Dark Energy
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Jeremy Sakstein, Bhuvnesh Jain</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The landmark detection of gravitational waves and light from the GW170817 binary neutron star merger constrained the speed difference between them to $10^{-15}$, thereby ruling out significant categories of modified gravity theories that attempt to explain cosmic acceleration. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">On August 17$^{\rm th}$ 2017, observatories worldwide made a landmark detection: gravitational waves and light from a binary neutron star merger. This event revolutionized our understanding of astrophysics, cosmology, and gravitation. In this proceeding of the 2025 International Congress of Basic Science, we describe how it transformed our view of cosmic acceleration (dark energy). The near-simultaneous arrival of light and gravitational waves shows that their speeds agree to within one part in $10^{15}$, excluding large classes of modified gravity theories and interactions between dark energy and matter.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.19762" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.19762" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.19762" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.9</span>
                        <span class="badge bg-info text-dark">Author Score: 0.11</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">4. Testing modified gravity with 3x2pt analyses in galaxy mocks
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Marc Alemany-Gotor, Cristian Viglione, Pablo Fosalba, Isaac Tutusaus</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Applying the standard General Relativity assumption to analyze galaxy clustering and weak lensing data from an $f(R)$ modified gravity universe introduces severe cosmological parameter biases, with the Figure of Bias reaching approximately $12\sigma$ for key parameters like $S_8$. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Stage-IV surveys will enable unprecedented tests of gravity on cosmological scales. However, assuming General Relativity in the analysis of large-scale structure could introduce systematic biases if gravity deviates from GR at these scales. Modified gravity theories, such as the Hu-Sawicki formulation of $f(R)$ gravity, offer an alternative explanation for cosmic acceleration without invoking a cosmological constant, while remaining consistent with Solar System tests through screening mechanisms. In this work, we quantify the cosmological parameter biases that arise when using a combination of galaxy clustering and weak-lensing data-vectors, the so-called 3x2pt analysis, from an $f(R)$ galaxy mock under the incorrect assumption of GR, using for the first time high-fidelity full-sky galaxy mock catalogues. We employ a pair of twin simulations: one with GR and one with Hu--Sawicki $f(R)$ gravity with $|f_{R0}| = 10^{-5}$. The mocks are built using an HOD method to populate the dark matter haloes with galaxies, calibrated against SDSS observations at low redshift. Using conservative scale cuts to minimise modelling uncertainties, we perform 3x2pt analyses and infer cosmological parameters through nested sampling, validating our pipeline with the GR mock. Our results show that when analysing the $f(R)$ galaxy mock assuming GR, the recovered cosmological parameters are very significantly biased, even when considering conservative scale cuts: the Figure of Bias reaches $\sim12σ$ for both $\{Ω_{\rm m}, σ_8\}$ and $S_8$. These biases persist even when marginalising over the galaxy bias and baryonic feedback, demonstrating that nuisance parameters cannot absorb the effects of modified gravity. We conclude that incorrectly assuming GR in a universe governed by $f(R)$ gravity leads to severe and detectable biases in cosmological inference for Stage-IV surveys.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.21468" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.21468" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.21468" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.6</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.95</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods / Cosmological Inference, Statistical Modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">5. ModHiFi: Identifying High Fidelity predictive components for Model Modification
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Dhruva Kashyap, Chaitanya Murti, Pranav K Nayak, Tanay Narshana, Chiranjib Bhattacharyya</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Leveraging the theoretical finding that global reconstruction error is linearly bounded by local errors in Lipschitz-continuous networks, the new metric Subset Fidelity allows for gradient-free model modification algorithms, ModHiFi-P and ModHiFi-U, which achieve competitive performance in structured pruning and classwise unlearning without access to training data or loss functions. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Open weight models, which are ubiquitous, rarely provide access to their training data or loss function. This makes modifying such models for tasks such as pruning or unlearning constrained by this unavailability an active area of research. Existing techniques typically require gradients or ground-truth labels, rendering them infeasible in settings with limited computational resources. In this work, we investigate the fundamental question of identifying components that are critical to the model&#39;s predictive performance, without access to either gradients or the loss function, and with only distributional access such as synthetic data. We theoretically demonstrate that the global reconstruction error is linearly bounded by local reconstruction errors for Lipschitz-continuous networks such as CNNs and well-trained Transformers (which, contrary to existing literature, we find exhibit Lipschitz continuity). This motivates using the locally reconstructive behavior of component subsets to quantify their global importance, via a metric that we term Subset Fidelity. In the uncorrelated features setting, selecting individual components via their Subset Fidelity scores is optimal, which we use to propose ModHiFi, an algorithm for model modification that requires no training data or loss function access. ModHiFi-P, for structured pruning, achieves an 11% speedup over the current state of the art on ImageNet models and competitive performance on language models. ModHiFi-U, for classwise unlearning, achieves complete unlearning on CIFAR-10 without fine-tuning and demonstrates competitive performance on Swin Transformers.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.19566" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.19566" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.19566" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.5</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.95</span>
                        
                            <span class="badge bg-secondary">cs.LG</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods / Deep Learning, Advanced Architectures, Representation</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">6. Improved constraints on ultralight axions using latest observations of the early and late Universe
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Qianshuo Liu, Chang Feng, Filipe B. Abdalla</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Combining Planck 2018 Cosmic Microwave Background data with DESI Baryon Acoustic Oscillation measurements yielded a new, tighter upper bound on the energy density fraction ratio of Ultralight Axions relative to total dark matter ($\Omega_a/\Omega_d$). (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Ultralight axions (ULAs) are hypothetical particles which can behave like dark matter (DM) or dark energy (DE) depending on masses generated at the symmetry-breaking scale. It remains a mystery whether the ULAs can make up a fraction of DM or DE. Although theoretical predictions indicate that the ULAs may leave distinct imprints on cosmological signals, these signatures may exist in a broad spatial and temporal scales, and may be degenerate with the known effects of the standard model. The ULA signatures are extremely subtle and the observational evidence of the ULAs remain elusive. In this work, we infer the ULA properties using both the early and late universe observations from the cosmic microwave background (CMB) and baryon acoustic oscillations (BAO). We validate modeling of the ULA effects using the CMB and BAO mock data and perform different tests to cross-check the results. By analyzing the Planck 2018 CMB measurements and the BAO measurements from the Data Release 2 of Dark Energy Spectroscopic Instrument (DESI), we constrain the energy density fraction ratio of the ULAs to total dark matter $Ω_a/Ω_d$ and obtain a new upper bound of $Ω_a/Ω_d$. Future CMB and BAO measurements will achieve unprecedented precision and will be crucial for understanding the nature of the ULAs.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.18917" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.18917" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.18917" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.5</span>
                        <span class="badge bg-info text-dark">Author Score: 0.01</span>
                        <span class="badge bg-primary">Semantic Score: 0.95</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods / Cosmological Inference, Statistical Modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">7. Inferring the Impacts of Baryonic Feedback from Kinetic Sunyaev-Zeldovich Cross-Correlations
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Alex Laguë, Mathew S. Madhavacheril, Josh Borrow, Kendrick M. Smith, Xinyi Chen, Matthieu Schaller, Joop Schaye</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The first fully data-driven matter power spectrum emulator was developed using a neural network trained on hydrodynamical simulations, mapping the kinematic Sunyaev-Zeldovich (kSZ) power spectrum to matter power suppression, achieving sub-percent accuracy and effectively breaking degeneracies associated with baryonic feedback. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The complex processes of baryonic feedback associated with galaxy evolution are still poorly understood, and their impact on the clustering of matter on small scales remains difficult to quantify. While many fitting functions and emulators exist to model the matter power spectrum, their input parameters are not directly observable. However, recent studies using hydrodynamical simulations have identified a promising correlation between the gas content of halos and changes to the matter power spectrum from feedback. Building on these findings, we create the first fully data-driven power spectrum emulator. We utilize the kinematic Sunyaev-Zeldovich (kSZ) effect, a secondary anisotropy in the cosmic microwave background, as a tracer of free electrons in and around halos. We train a neural network to learn the mapping between the suppression of the matter power spectrum and the shape of the kSZ power spectrum extracted with a radial velocity template. We train and validate our algorithm using the FLAMINGO suite of hydrodynamical simulations, which encompasses a wide range of feedback models. Our emulator can reconstruct the matter power spectrum at the sub-percent level for scales $k\leq 5\;h/$Mpc and $0.2\leq z \leq 1.25$ directly from the data. Our model is robust and retains percent-level accuracy even for feedback models and cosmological parameter values not seen during training (except in a few extreme cases drastically different from the fiducial model). Due to its robustness, our algorithm offers a new way to identify the sources of suppression in the matter power spectrum, breaking the degeneracies between baryonic feedback and new physics. Finally, we present a forecast for reconstruction of the matter power spectrum combining maps of the microwave background anisotropies from a Simons Observatory-like experiment and galaxy catalogs from the Dark Energy Spectroscopic Instrument.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.20595" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.20595" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.20595" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.5</span>
                        <span class="badge bg-info text-dark">Author Score: 0.02</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">8. Separating the Inseparable: Constraining Arbitrary Primordial Bispectra with Cosmic Microwave Background Data
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Oliver H. E. Philcox, Kunhao Zhong, Salvatore Samuele Sirletti</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A novel machine-learning framework constructs highly correlated, separable approximations of complex primordial bispectra using neural network basis functions, facilitating the creation of efficient Cosmic Microwave Background estimators used to place new constraints on non-Gaussianity in cosmological collider models using Planck PR4 data. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">To efficiently probe primordial non-Gaussianity using Cosmic Microwave Background (CMB) data, we require theoretical predictions that are factorizable, \textit{i.e.}\ those whose kinematic dependence can be separated. This property does not hold for many models, hindering their application to data. In this work, we introduce a general framework for constructing separable approximations to primordial bispectra, enabling direct CMB constraints on arbitrary models including those computed using numerical tools. In contrast to other approaches such as modal decompositions, we learn the basis functions directly from the data, allowing high-fidelity representations with just a handful of terms. This is practically implemented using machine-learning techniques, utilizing neural network basis functions and a loss function designed to mimic the CMB cosine similarity. We validate our pipeline using a variety of input bispectra, demonstrating that the approximations are $&gt;99.5\%$ correlated with the truth with just three terms. By incorporating the neural basis into the \textsc{PolySpec} code, we derive KSW-type CMB estimators, which reproduce local- and equilateral-type non-Gaussianity to within $0.1σ$. As a proof-of-concept, we constrain two inflationary bispectra from the `cosmological collider&#39; scenario; these feature an additional strongly-mixed particle sector and cannot be computed analytically. By combining the numerical predictions from \textsc{CosmoFlow} with our factorizable approach (with just three terms), we place novel constraints on the collider models using \textit{Planck} PR4 data, finding no detection of non-Gaussianity. Our method facilitates detailed studies of the inflationary paradigm, connecting modern theoretical tools with high-resolution observational data.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.19179" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.19179" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.19179" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.5</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.95</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">9. Toward a Unified Understanding of the Dense Matter Equation of State
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Kshitij Agarwal, Johannes Jahan, Behruz Kardan, Peter T. H. Pang, Tom Reichert, Alexandra C. Semposki</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Achieving a coherent, predictive understanding of dense nuclear matter requires systematic, integrated frameworks like MUSES and Bayesian multi-source analyses (NMMA, BAND) to combine constraints on the Equation of State derived from heavy-ion collisions and multi-messenger astrophysics observations. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Efforts to understand the equation of state (EOS) of dense nuclear matter at supra-saturation densities have grown more sophisticated over the past decade, driven by a surge in high-precision data from both terrestrial experiments and astrophysical observations. While for the former, heavy-ion collisions (HIC) represent a unique opportunity to constraint the EOS in a controlled laboratory setting, the latter can be precisely probed thanks to the advent of multi-messenger astronomy (MMA). However, as we move away from our understanding drawn from individual sources and limited statistics to the era of precision physics with improved datasets, the need for a systematic way to combine them becomes clear. In this article, we trace the individual methods for extracting the EOS both for HIC and MMA. We then review the current state-of-the-art efforts to combine these individual information sources from Bayesian multi-source analysis, e.g., the Nuclear Physics and Multi-Messenger Astrophysics (NMMA) and Bayesian Analysis of Nuclear Dynamics (BAND) frameworks, and fully integrated EOS frameworks, i.e., the Modular Unified Solver for the Equation of State (MUSES) calculation engine. We highlight the scientific advances made possible by each step and outline the remaining challenges that must be addressed to build a coherent, predictive picture of dense nuclear matter across all relevant regimes.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.20378" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.20378" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.20378" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.5</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.95</span>
                        
                            <span class="badge bg-secondary">nucl-th</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">10. Demystifying Diffusion Objectives: Reweighted Losses are Better Variational Bounds
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Jiaxin Shi, Michalis K. Titsias</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A new theoretical interpretation based on constructing a cascade of time-dependent variational lower bounds on the data log-likelihood provides justification for reweighted losses in diffusion models and significantly improves sample quality in masked diffusion models. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We derive a new theoretical interpretation of the reweighted losses that are widely used for training diffusion models. Our method is based on constructing a cascade of time-dependent variational lower bounds on the data log-likelihood, that provably improves upon the standard evidence lower bound and results in reduced data-model KL-divergences. Combining such bounds gives rise to reweighted objectives that can be applied to any generative diffusion model including both continuous Gaussian diffusion and masked (discrete) diffusion models. Then, we showcase this framework in masked diffusion and report significant improvements over previous training losses in pixel-space image modeling, approaching sample quality comparable to continuous diffusion models. Our results also provide a theoretical justification for the simple weighting scheme widely used in masked image models.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.19664" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.19664" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.19664" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.5</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.95</span>
                        
                            <span class="badge bg-secondary">cs.LG</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods / Deep Learning, Advanced Architectures, Representation</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">11. MambaEye: A Size-Agnostic Visual Encoder with Causal Sequential Processing
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Changho Choi, Minho Kim, Jinkyu Kim</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Leveraging a strictly unidirectional Mamba2 backbone and relative move embedding, MambaEye functions as an input-size agnostic visual encoder that achieves robust high-resolution classification with linear time and memory complexity. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Despite decades of progress, a truly input-size agnostic visual encoder-a fundamental characteristic of human vision-has remained elusive. We address this limitation by proposing \textbf{MambaEye}, a novel, causal sequential encoder that leverages the low complexity and causal-process based pure Mamba2 backbone. Unlike previous Mamba-based vision encoders that often employ bidirectional processing, our strictly unidirectional approach preserves the inherent causality of State Space Models, enabling the model to generate a prediction at any point in its input sequence. A core innovation is our use of relative move embedding, which encodes the spatial shift between consecutive patches, providing a strong inductive bias for translation invariance and making the model inherently adaptable to arbitrary image resolutions and scanning patterns. To achieve this, we introduce a novel diffusion-inspired loss function that provides dense, step-wise supervision, training the model to build confidence as it gathers more visual evidence. We demonstrate that MambaEye exhibits robust performance across a wide range of image resolutions, especially at higher resolutions such as $1536^2$ on the ImageNet-1K classification task. This feat is achieved while maintaining linear time and memory complexity relative to the number of patches.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.19963" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.19963" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.19963" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.5</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.95</span>
                        
                            <span class="badge bg-secondary">cs.CV</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods / Deep Learning, Advanced Architectures, Representation</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">12. Reanalyzing DESI DR1: 2. Constraints on Dark Energy, Spatial Curvature, and Neutrino Masses
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Anton Chudaykin, Mikhail M. Ivanov, Oliver H. E. Philcox</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Re-analyzing the DESI dataset using full-shape power spectrum and bispectrum measurements substantially improves constraints on non-minimal cosmological models, notably yielding the strongest CMB-independent limit on total neutrino mass and doubling the precision on spatial curvature compared to BAO-only results. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We carry out an independent re-analysis of the Dark Energy Spectroscopic Instrument (DESI) public dataset, focusing on extensions to the standard cosmological model, $Λ$CDM. Utilizing the dataset and Effective Field Theory (EFT)-based pipeline described in Paper 1, we constrain cosmological models with massive neutrinos ($Λ$CDM+$M_ν$), spatial curvature ($oΛ$CDM), dynamical dark energy ($w_0w_a$CDM), and their combinations using the power spectrum and bispectrum of DESI galaxies and quasars. Our work also presents the first measurements of relevant non-minimal cosmological parameters from the combination of cosmic microwave background (CMB) and DESI full-shape (FS) data, which are made possible thanks to carefully chosen priors on EFT parameters. We find that the addition the FS likelihood to DESI&#39;s baryon acoustic oscillation (BAO) data improves the limits on the spatial curvature by a factor of two over the BAO only results, though the improvements are less significant with the CMB data. The dark energy equation of state figure-of-merit increases both with and without the supernovae data (SNe), by $\approx30\%$ and $\approx20\%$ relative to the CMB+BAO and CMB+BAO+SNe results, respectively. Our FS likelihood also yields the strongest CMB-independent constraint on the total neutrino mass $M_ν&lt;0.32\,{\rm eV}$, with the $30\%$ improvement due to the bispectrum. In combination with the CMB, we find a $14\%$ improvement assuming the $Λ$CDM+$M_ν$ model (yielding $M_ν&lt;0.059\,{\rm eV}$), but this increases to $22\%$ when using non-minimal backgrounds: $M_ν&lt;0.097\,{\rm eV}$ in $oΛ$CDM+$M_ν$ and $M_ν&lt;0.13\,{\rm eV}$ in $w_0w_a$CDM+$M_ν$. Overall, our work illustrates that robust and substantial gains in constraining power can be obtained by incorporating the FS power spectrum and bispectrum measurements in analyses of non-minimal cosmological models.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.20757" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.20757" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.20757" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.5</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Weak Lensing, Cosmological Constraints, Survey Systematics</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">13. Estimating the triaxiality of massive clusters from 2D observables in MillenniumTNG with machine learning
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Ana Maria Delgado, Michelle Ntampaka, Sownak Bose, Fulvio Ferlito, Boryana Hadzhiyska, Lars Hernquist, John Soltis, John F. Wu, Mikaeel Yunus, John ZuHone</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Massive galaxy cluster geometry, including triaxiality and orientation, can be accurately estimated from 2D multi-wavelength and member data using a multi-modal fusion network combining CNN and GNN components, achieving a 30% improvement over models assuming spherical symmetry. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Properties of massive galaxy clusters, such as mass abundance and concentration, are sensitive to cosmology, making cluster statistics a powerful tool for cosmological studies. However, favoring a more simplified, spherically symmetric model for galaxy clusters can lead to biases in the estimates of cluster properties. In this work, we present a deep-learning approach for estimating the triaxiality and orientations of massive galaxy clusters (those with masses $\gtrsim 10^{14}\,M_\odot h^{-1}$) from 2D observables. We utilize the flagship hydrodynamical volume of the suite of cosmological-hydrodynamical MillenniumTNG (MTNG) simulations as our ground truth. Our model combines the feature extracting power of a convolutional neural network (CNN) and the message passing power of a graph neural network (GNN) in a multi-modal, fusion network. Our model is able to extract 3D geometry information from 2D idealized cluster multi-wavelength images (soft X-ray, medium X-ray, hard X-ray and tSZ effect) and mathematical graph representations of 2D cluster member observables (line-of-sight radial velocities, 2D projected positions and V-band luminosities). Our network improves cluster geometry estimation in MTNG by $30\%$ compared to assuming spherical symmetry. We report an $R^2 = 0.85$ regression score for estimating the major axis length of triaxial clusters and correctly classifying $71\%$ of prolate clusters with elongated orientations along our line-of-sight.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.20429" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.20429" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.20429" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.5</span>
                        <span class="badge bg-info text-dark">Author Score: 0.01</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">14. Which Layer Causes Distribution Deviation? Entropy-Guided Adaptive Pruning for Diffusion and Flow Models
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Changlin Li, Jiawei Zhang, Zeyi Shi, Zongxin Yang, Zhihui Li, Xiaojun Chang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> EntPruner introduces an entropy-guided automatic progressive pruning framework that uses Conditional Entropy Deviation to assess block importance in diffusion and flow models, enabling up to 2.22x inference speedup while maintaining competitive generation quality across various downstream tasks. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Large-scale vision generative models, including diffusion and flow models, have demonstrated remarkable performance in visual generation tasks. However, transferring these pre-trained models to downstream tasks often results in significant parameter redundancy. In this paper, we propose EntPruner, an entropy-guided automatic progressive pruning framework for diffusion and flow models. First, we introduce entropy-guided pruning, a block-level importance assessment strategy specifically designed for generative models. Unlike discriminative models, generative models require preserving the diversity and condition-fidelity of the output distribution. As the importance of each module can vary significantly across downstream tasks, EntPruner prioritizes pruning of less important blocks using data-dependent Conditional Entropy Deviation (CED) as a guiding metric. CED quantifies how much the distribution diverges from the learned conditional data distribution after removing a block. Second, we propose a zero-shot adaptive pruning framework to automatically determine when and how much to prune during training. This dynamic strategy avoids the pitfalls of one-shot pruning, mitigating mode collapse, and preserving model performance. Extensive experiments on DiT and SiT models demonstrate the effectiveness of EntPruner, achieving up to 2.22$\times$ inference speedup while maintaining competitive generation quality on ImageNet and three downstream datasets.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.21122" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.21122" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.21122" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.CV</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods / Deep Learning, Advanced Architectures, Representation</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">15. Shortcut Invariance: Targeted Jacobian Regularization in Disentangled Latent Space
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Shivam Pal, Sakshi Varshney, Piyush Rai</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A novel training method achieves state-of-the-art out-of-distribution generalization by learning a robust classifier function that is desensitized to shortcut features—identified in a disentangled latent space—via targeted anisotropic latent noise injection, which acts as Jacobian regularization. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Deep neural networks are prone to learning shortcuts, spurious and easily learned correlations in training data that cause severe failures in out-of-distribution (OOD) generalization. A dominant line of work seeks robustness by learning a robust representation, often explicitly partitioning the latent space into core and spurious components; this approach can be complex, brittle, and difficult to scale. We take a different approach, instead of a robust representation, we learn a robust function. We present a simple and effective training method that renders the classifier functionally invariant to shortcut signals. Our method operates within a disentangled latent space, which is essential as it isolates spurious and core features into distinct dimensions. This separation enables the identification of candidate shortcut features by their strong correlation with the label, used as a proxy for semantic simplicity. The classifier is then desensitized to these features by injecting targeted, anisotropic latent noise during training. We analyze this as targeted Jacobian regularization, which forces the classifier to ignore spurious features and rely on more complex, core semantic signals. The result is state-of-the-art OOD performance on established shortcut learning benchmarks.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.19525" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.19525" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.19525" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.LG</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods / Deep Learning, Advanced Architectures, Representation</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">16. Understanding, Accelerating, and Improving MeanFlow Training
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Jin-Young Kim, Hyojun Go, Lea Bogensperger, Julius Erbach, Nikolai Kalischek, Federico Tombari, Konrad Schindler, Dominik Narnhofer</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Analyzing MeanFlow training dynamics informed an enhanced scheme that prioritizes instantaneous velocity formation before focusing on long-interval average velocity, leading to significantly faster convergence and superior few-step generation performance, achieving an FID of 2.87 on ImageNet 256x256 at 1-NFE. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">MeanFlow promises high-quality generative modeling in few steps, by jointly learning instantaneous and average velocity fields. Yet, the underlying training dynamics remain unclear. We analyze the interaction between the two velocities and find: (i) well-established instantaneous velocity is a prerequisite for learning average velocity; (ii) learning of instantaneous velocity benefits from average velocity when the temporal gap is small, but degrades as the gap increases; and (iii) task-affinity analysis indicates that smooth learning of large-gap average velocities, essential for one-step generation, depends on the prior formation of accurate instantaneous and small-gap average velocities. Guided by these observations, we design an effective training scheme that accelerates the formation of instantaneous velocity, then shifts emphasis from short- to long-interval average velocity. Our enhanced MeanFlow training yields faster convergence and significantly better few-step generation: With the same DiT-XL backbone, our method reaches an impressive FID of 2.87 on 1-NFE ImageNet 256x256, compared to 3.43 for the conventional MeanFlow baseline. Alternatively, our method matches the performance of the MeanFlow baseline with 2.5x shorter training time, or with a smaller DiT-L backbone.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.19065" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.19065" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.19065" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.CV</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods / Deep Learning, Advanced Architectures, Representation</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">17. Inclinations and Position Angles for Disc Galaxies in the SGA sample
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Megan H. Martinez, Michael S. Petersen, Carrie Filion, Rashid Yaaqib, Claire Larson</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Inclination and position angle measurements for disc galaxies are automated and made robust using a computationally inexpensive, data-driven method that relies on a dimensionless metric derived from the Fourier-Laguerre basis decomposition of imaging data. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We present a data-driven method for determining the inclination and position angle (PA) of disc galaxies using a Fourier-Laguerre basis decomposition of imaging data. We define a dimensionless metric, $η$, that characterises the ratio of the quadrupole and monopole coefficients in the Fourier-Laguerre basis function expansion. This metric serves as a robust measure which is related to the inclination of a galaxy. We find an empirical relationship between $η$ and inclination which is agnostic to the galaxy morphology. The PA is derived directly from the phase of the quadrupolar Fourier-Laguerre functions. Across a benchmark sample of galaxies, the method reproduces published inclination and PA values to within a median of 10$^\circ$ and 5$^\circ$, respectively, while also demonstrating essentially zero catastrophic failures. Applying this pipeline to galaxies from the Siena Galaxy Atlas (SGA), we report measurements of $η$, scale length and PA for three different bands of 133,942 disc galaxies. Our computationally inexpensive technique automates parametrisation analysis and returns reproducible results for large surveys. We release a Python package ready for application to next generation surveys.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.19207" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.19207" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.19207" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">18. Mosaic Pruning: A Hierarchical Framework for Generalizable Pruning of Mixture-of-Experts Models
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Wentao Hu, Mingkuan Zhao, Shuangyong Song, Xiaoyan Zhu, Xin Lai, Jiayin Wang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> To overcome the domain-specific limitations of existing pruning methods for Sparse Mixture-of-Experts models, Mosaic Pruning introduces a structured cluster-then-select process based on cross-domain similarity and Activation Variability Score, yielding a functionally comprehensive expert subset that generalizes robustly across diverse tasks. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Sparse Mixture-of-Experts (SMoE) architectures have enabled a new frontier in scaling Large Language Models (LLMs), offering superior performance by activating only a fraction of their total parameters during inference. However, their practical deployment is severely hampered by substantial static memory overhead, as all experts must be loaded into memory. Existing post-training pruning methods, while reducing model size, often derive their pruning criteria from a single, general-purpose corpus. This leads to a critical limitation: a catastrophic performance degradation when the pruned model is applied to other domains, necessitating a costly re-pruning for each new domain. To address this generalization gap, we introduce Mosaic Pruning (MoP). The core idea of MoP is to construct a functionally comprehensive set of experts through a structured ``cluster-then-select&#34; process. This process leverages a similarity metric that captures expert performance across different task domains to functionally cluster the experts, and subsequently selects the most representative expert from each cluster based on our proposed Activation Variability Score. Unlike methods that optimize for a single corpus, our proposed Mosaic Pruning ensures that the pruned model retains a functionally complementary set of experts, much like the tiles of a mosaic that together form a complete picture of the original model&#39;s capabilities, enabling it to handle diverse downstream tasks.Extensive experiments on various MoE models demonstrate the superiority of our approach. MoP significantly outperforms prior work, achieving a 7.24\% gain on general tasks and 8.92\% on specialized tasks like math reasoning and code generation.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.19822" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.19822" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.19822" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.LG</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods / Deep Learning, Advanced Architectures, Representation</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">19. Connecting clustering and the cosmic web:Observational constraints on secondary halo bias
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Facundo Rodriguez, Antonio D. Montero-Dorta</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Analyzing SDSS galaxy groups reveals a robust observational hierarchy for secondary halo bias, demonstrating that clustering strength at fixed mass is most strongly correlated with local group overdensity, followed by central galaxy color, establishing a link between halo assembly history and bias. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Cosmological simulations predict significant secondary dependencies of halo clustering on internal properties and environment. Detecting these subtle signals in observational data remains challenging, with important ramifications for galaxy evolution and cosmology. We probe secondary halo bias in observational survey data, using galaxy groups as dark matter halo proxies. We quantify secondary bias using central galaxy colour and environmental diagnostics. We use an extended, refined galaxy group catalogue from the Sloan Digital Sky Survey. Secondary bias is defined as any deviation in group clustering strength at fixed mass, quantified through the projected two-point correlation function. Our environmental analysis uses DisPerSE to compute distances to critical points of the density field, incorporating local group overdensity measurements on multiple scales. We robustly detect several forms of secondary bias in the clustering of galaxy groups. At fixed mass, groups hosting red central galaxies are more strongly clustered than those with blue centrals, with $b_{\rm relative}$ ranging from $\sim 1.2$ for the 15\% reddest centrals to $\sim 0.8$ for the bluest ones. Environmental dependencies based on cosmic-web distances are also present, though significantly weaker and largely mass-independent. The strongest signal arises from local overdensity: groups in the densest 15\% of environments reach $b_{\rm relative} \sim 1.4$, while those in the least dense regions fall to $b_{\rm relative} \sim 0.7$. These results establish a clear observational hierarchy for secondary halo bias. The colour of central galaxies correlates with the local group overdensity, which, in turn, correlates with the bias at fixed group mass. Assuming that central galaxy colour traces halo assembly history, this three-stage picture offers a conceptual link between our results and halo assembly bias.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.19607" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.19607" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.19607" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.01</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Weak Lensing, Cosmological Constraints, Survey Systematics / Weak Lensing, Galaxy Clustering, Halo Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">20. Scaling Implicit Fields via Hypernetwork-Driven Multiscale Coordinate Transformations
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Plein Versace</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Hyper-Coordinate Implicit Neural Representations (HC-INR) resolve the representation bottleneck in INRs by using a hierarchical hypernetwork to learn dynamic, signal-adaptive coordinate transformations, significantly increasing representable frequency bands and achieving superior reconstruction fidelity with reduced parameter counts. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Implicit Neural Representations (INRs) have emerged as a powerful paradigm for representing signals such as images, 3D shapes, signed distance fields, and radiance fields. While significant progress has been made in architecture design (e.g., SIREN, FFC, KAN-based INRs) and optimization strategies (meta-learning, amortization, distillation), existing approaches still suffer from two core limitations: (1) a representation bottleneck that forces a single MLP to uniformly model heterogeneous local structures, and (2) limited scalability due to the absence of a hierarchical mechanism that dynamically adapts to signal complexity. This work introduces Hyper-Coordinate Implicit Neural Representations (HC-INR), a new class of INRs that break the representational bottleneck by learning signal-adaptive coordinate transformations using a hypernetwork. HC-INR decomposes the representation task into two components: (i) a learned multiscale coordinate transformation module that warps the input domain into a disentangled latent space, and (ii) a compact implicit field network that models the transformed signal with significantly reduced complexity. The proposed model introduces a hierarchical hypernetwork architecture that conditions coordinate transformations on local signal features, enabling dynamic allocation of representation capacity. We theoretically show that HC-INR strictly increases the upper bound of representable frequency bands while maintaining Lipschitz stability. Extensive experiments across image fitting, shape reconstruction, and neural radiance field approximation demonstrate that HC-INR achieves up to 4 times higher reconstruction fidelity than strong INR baselines while using 30--60\% fewer parameters.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.18387" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.18387" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.18387" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods / Deep Learning, Advanced Architectures, Representation</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">21. Guaranteed Optimal Compositional Explanations for Neurons
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Biagio La Rosa, Leilani H. Gilpin</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A novel theoretical framework provides the first guaranteed optimal compositional explanations for deep neural networks, revealing that common beam search methods yield suboptimal results up to 40% of the time, especially with overlapping concepts. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">While neurons are the basic units of deep neural networks, it is still unclear what they learn and if their knowledge is aligned with that of humans. Compositional explanations aim to answer this question by describing the spatial alignment between neuron activations and concepts through logical rules. These logical descriptions are typically computed via a search over all possible concept combinations. Since computing the spatial alignment over the entire state space is computationally infeasible, the literature commonly adopts beam search to restrict the space. However, beam search cannot provide any theoretical guarantees of optimality, and it remains unclear how close current explanations are to the true optimum. In this theoretical paper, we address this gap by introducing the first framework for computing guaranteed optimal compositional explanations. Specifically, we propose: (i) a decomposition that identifies the factors influencing the spatial alignment, (ii) a heuristic to estimate the alignment at any stage of the search, and (iii) the first algorithm that can compute optimal compositional explanations within a feasible time. Using this framework, we analyze the differences between optimal and non-optimal explanations in the most popular settings for compositional explanations, the computer vision domain and Convolutional Neural Networks. In these settings, we demonstrate that 10-40 percent of explanations obtained with beam search are suboptimal when overlapping concepts are involved. Finally, we evaluate a beam-search variant guided by our proposed decomposition and heuristic, showing that it matches or improves runtime over prior methods while offering greater flexibility in hyperparameters and computational resources.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.20934" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.20934" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.20934" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods / Deep Learning, Advanced Architectures, Representation</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">22. Neural surrogates for designing gravitational wave detectors
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Carlos Ruiz-Gonzalez, Sören Arlt, Sebastian Lehner, Arturs Berzins, Yehonathan Drori, Rana X Adhikari, Johannes Brandstetter, Mario Krenn</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Utilizing neural surrogate models and an iterative training/verification loop, a new framework efficiently accelerates the inverse design of complex systems, such as gravitational wave detectors, achieving superior optimization results much faster than traditional CPU-based simulators. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Physics simulators are essential in science and engineering, enabling the analysis, control, and design of complex systems. In experimental sciences, they are increasingly used to automate experimental design, often via combinatorial search and optimization. However, as the setups grow more complex, the computational cost of traditional, CPU-based simulators becomes a major limitation. Here, we show how neural surrogate models can significantly reduce reliance on such slow simulators while preserving accuracy. Taking the design of interferometric gravitational wave detectors as a representative example, we train a neural network to surrogate the gravitational wave physics simulator Finesse, which was developed by the LIGO community. Despite that small changes in physical parameters can change the output by orders of magnitudes, the model rapidly predicts the quality and feasibility of candidate designs, allowing an efficient exploration of large design spaces. Our algorithm loops between training the surrogate, inverse designing new experiments, and verifying their properties with the slow simulator for further training. Assisted by auto-differentiation and GPU parallelism, our method proposes high-quality experiments much faster than direct optimization. Solutions that our algorithm finds within hours outperform designs that take five days for the optimizer to reach. Though shown in the context of gravitational wave detectors, our framework is broadly applicable to other domains where simulator bottlenecks hinder optimization and discovery.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.19364" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.19364" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.19364" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.LG</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">23. HVAdam: A Full-Dimension Adaptive Optimizer
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Yiheng Zhang, Shaowu Wu, Yuanzhuo Xu, Jiajun Wu, Shang Xu, Steve Drew, Xiaoguang Niu</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The Anon optimizer introduces continuously tunable adaptivity and an incremental delay update mechanism (IDU) to reliably bridge the performance gap between adaptive and non-adaptive methods, achieving superior results across image classification, diffusion, and language modeling. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Adaptive optimizers such as Adam have achieved great success in training large-scale models like large language models and diffusion models. However, they often generalize worse than non-adaptive methods, such as SGD on classical architectures like CNNs. We identify a key cause of this performance gap: adaptivity in pre-conditioners, which limits the optimizer&#39;s ability to adapt to diverse optimization landscapes. To address this, we propose Anon (Adaptivity Non-restricted Optimizer with Novel convergence technique), a novel optimizer with continuously tunable adaptivity , allowing it to interpolate between SGD-like and Adam-like behaviors and even extrapolate beyond both. To ensure convergence across the entire adaptivity spectrum, we introduce incremental delay update (IDU), a novel mechanism that is more flexible than AMSGrad&#39;s hard max-tracking strategy and enhances robustness to gradient noise. We theoretically establish convergence guarantees under both convex and non-convex settings. Empirically, Anon consistently outperforms state-of-the-art optimizers on representative image classification, diffusion, and language modeling tasks. These results demonstrate that adaptivity can serve as a valuable tunable design principle, and Anon provides the first unified and reliable framework capable of bridging the gap between classical and modern optimizers and surpassing their advantageous properties.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.20277" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.20277" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.20277" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.LG</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods / Deep Learning, Advanced Architectures, Representation</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">24. Terminal Velocity Matching
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Linqi Zhou, Mathias Parger, Ayaan Haque, Jiaming Song</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Terminal Velocity Matching (TVM) generalizes flow matching by regularizing the terminal time behavior, achieving state-of-the-art performance for high-fidelity one- and few-step generative modeling on large-scale image datasets like ImageNet. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We propose Terminal Velocity Matching (TVM), a generalization of flow matching that enables high-fidelity one- and few-step generative modeling. TVM models the transition between any two diffusion timesteps and regularizes its behavior at its terminal time rather than at the initial time. We prove that TVM provides an upper bound on the $2$-Wasserstein distance between data and model distributions when the model is Lipschitz continuous. However, since Diffusion Transformers lack this property, we introduce minimal architectural changes that achieve stable, single-stage training. To make TVM efficient in practice, we develop a fused attention kernel that supports backward passes on Jacobian-Vector Products, which scale well with transformer architectures. On ImageNet-256x256, TVM achieves 3.29 FID with a single function evaluation (NFE) and 1.99 FID with 4 NFEs. It similarly achieves 4.32 1-NFE FID and 2.94 4-NFE FID on ImageNet-512x512, representing state-of-the-art performance for one/few-step models from scratch.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.19797" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.19797" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.19797" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.LG</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods / Deep Learning, Advanced Architectures, Representation</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">25. Merging without Forgetting: Continual Fusion of Task-Specific Models via Optimal Transport
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">Zecheng Pan, Zhikang Chen, Ding Li, Min Zhang, Sen Cui, Hongshuo Jin, Luqi Tao, Yi Yang, Deheng Ye, Yu Zhang, et al.</span>
                                <span class="author-full" style="display: none;">Zecheng Pan, Zhikang Chen, Ding Li, Min Zhang, Sen Cui, Hongshuo Jin, Luqi Tao, Yi Yang, Deheng Ye, Yu Zhang, Tingting Zhu, Tianling Ren</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Optimal Transport-based Masked Fusion (OTMF) leverages optimal transport to align the semantic geometry of fine-tuned models by discovering common task vector masks, effectively mitigating distribution shift during merging and supporting efficient continual fusion. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Merging models fine-tuned for different tasks into a single unified model has become an increasingly important direction for building versatile, efficient multi-task systems. Existing approaches predominantly rely on parameter interpolation in weight space, which we show introduces significant distribution shift in the feature space and undermines task-specific knowledge. In this paper, we propose OTMF (Optimal Transport-based Masked Fusion), a novel model merging framework rooted in optimal transport theory to address the distribution shift that arises from naive parameter interpolation. Instead of directly aggregating features or weights, OTMF aligns the semantic geometry of task-specific models by discovering common masks applied to task vectors through optimal transport plans. These masks selectively extract transferable and task-agnostic components while preserving the unique structural identities of each task. To ensure scalability in real-world settings, OTMF further supports a continual fusion paradigm that incrementally integrates each new task vector without revisiting previous ones, maintaining a bounded memory footprint and enabling efficient fusion across a growing number of tasks. We conduct comprehensive experiments on multiple vision and language benchmarks, and results show that OTMF achieves state-of-the-art performance in terms of both accuracy and efficiency. These findings highlight the practical and theoretical value of our approach to model merging.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.19561" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.19561" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.19561" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.LG</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods / Deep Learning, Advanced Architectures, Representation</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">26. Test-Time Alignment of Text-to-Image Diffusion Models via Null-Text Embedding Optimisation
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Taehoon Kim, Henry Gouk, Timothy Hospedales</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Null-Text Test-Time Alignment (Null-TTA) aligns diffusion models by optimizing the unconditional embedding in classifier-free guidance, ensuring semantic coherence during inference and preventing reward hacking while achieving superior test-time performance. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Test-time alignment (TTA) aims to adapt models to specific rewards during inference. However, existing methods tend to either under-optimise or over-optimise (reward hack) the target reward function. We propose Null-Text Test-Time Alignment (Null-TTA), which aligns diffusion models by optimising the unconditional embedding in classifier-free guidance, rather than manipulating latent or noise variables. Due to the structured semantic nature of the text embedding space, this ensures alignment occurs on a semantically coherent manifold and prevents reward hacking (exploiting non-semantic noise patterns to improve the reward). Since the unconditional embedding in classifier-free guidance serves as the anchor for the model&#39;s generative distribution, Null-TTA directly steers model&#39;s generative distribution towards the target reward rather than just adjusting the samples, even without updating model parameters. Thanks to these desirable properties, we show that Null-TTA achieves state-of-the-art target test-time alignment while maintaining strong cross-reward generalisation. This establishes semantic-space optimisation as an effective and principled novel paradigm for TTA.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.20889" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.20889" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.20889" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.CV</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods / Deep Learning, Advanced Architectures, Representation</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">27. OVOD-Agent: A Markov-Bandit Framework for Proactive Visual Reasoning and Self-Evolving Detection
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Chujie Wang, Jianyu Lu, Zhiyuan Luo, Xi Chen, Chu He</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> OVOD-Agent reframes Open-Vocabulary Object Detection as a proactive visual reasoning task modeled by a Weakly Markovian Decision Process, utilizing a Bandit module and self-supervised reward optimization to significantly enhance generalization, particularly for rare categories. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Open-Vocabulary Object Detection (OVOD) aims to enable detectors to generalize across categories by leveraging semantic information. Although existing methods are pretrained on large vision-language datasets, their inference is still limited to fixed category names, creating a gap between multimodal training and unimodal inference. Previous work has shown that improving textual representation can significantly enhance OVOD performance, indicating that the textual space is still underexplored. To this end, we propose OVOD-Agent, which transforms passive category matching into proactive visual reasoning and self-evolving detection. Inspired by the Chain-of-Thought (CoT) paradigm, OVOD-Agent extends the textual optimization process into an interpretable Visual-CoT with explicit actions. OVOD&#39;s lightweight nature makes LLM-based management unsuitable; instead, we model visual context transitions as a Weakly Markovian Decision Process (w-MDP) over eight state spaces, which naturally represents the agent&#39;s state, memory, and interaction dynamics. A Bandit module generates exploration signals under limited supervision, helping the agent focus on uncertain regions and adapt its detection policy. We further integrate Markov transition matrices with Bandit trajectories for self-supervised Reward Model (RM) optimization, forming a closed loop from Bandit exploration to RM learning. Experiments on COCO and LVIS show that OVOD-Agent provides consistent improvements across OVOD backbones, particularly on rare categories, confirming the effectiveness of the proposed framework.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.21064" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.21064" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.21064" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.01</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods / Deep Learning, Advanced Architectures, Representation</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">28. Efficient Training for Human Video Generation with Entropy-Guided Prioritized Progressive Learning
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Changlin Li, Jiawei Zhang, Shuhao Liu, Sihao Lin, Zeyi Shi, Zhihui Li, Xiaojun Chang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Entropy-Guided Prioritized Progressive Learning (Ent-Prog) uses Conditional Entropy Inflation and an adaptive schedule to efficiently train human video diffusion models, achieving up to 2.2x speedup and 2.4x memory reduction without compromising generative quality. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Human video generation has advanced rapidly with the development of diffusion models, but the high computational cost and substantial memory consumption associated with training these models on high-resolution, multi-frame data pose significant challenges. In this paper, we propose Entropy-Guided Prioritized Progressive Learning (Ent-Prog), an efficient training framework tailored for diffusion models on human video generation. First, we introduce Conditional Entropy Inflation (CEI) to assess the importance of different model components on the target conditional generation task, enabling prioritized training of the most critical components. Second, we introduce an adaptive progressive schedule that adaptively increases computational complexity during training by measuring the convergence efficiency. Ent-Prog reduces both training time and GPU memory consumption while maintaining model performance. Extensive experiments across three datasets, demonstrate the effectiveness of Ent-Prog, achieving up to 2.2$\times$ training speedup and 2.4$\times$ GPU memory reduction without compromising generative performance.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.21136" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.21136" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.21136" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.CV</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods / Deep Learning, Advanced Architectures, Representation</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">29. Efficient Inference Using Large Language Models with Limited Human Data: Fine-Tuning then Rectification
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Lei Wang, Zikun Ye, Jinglong Zhao</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A novel framework optimally allocates labeled samples between LLM fine-tuning and rectification stages for social science applications, minimizing prediction error variance during fine-tuning to maximize the effectiveness of the downstream rectification process. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Driven by recent advances in artificial intelligence (AI), a growing body of work demonstrates the potential of using large language models (LLMs) to generate human-like responses in market research and social science applications. Two primary approaches can be applied to improve the performance of LLMs: fine-tuning, which aligns LLM predictions more closely with human responses, and rectification, which corrects biases in LLM outputs. In this paper, we develop a framework that combines fine-tuning and rectification, and optimally allocates limited labeled samples across the two stages. Unlike the conventional objective that minimizes the mean squared prediction errors, we propose to minimize the variance of the prediction errors as the fine-tuning objective, which is optimal for the downstream rectification stage. Building on this insight, we leverage empirical scaling laws to develop a data-driven method for optimally splitting samples between the fine-tuning and rectification stages. Empirical analysis validates our framework, demonstrating improved estimation and inference performance compared to using either fine-tuning or rectification alone.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.19486" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.19486" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.19486" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.LG</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods / Deep Learning, Advanced Architectures, Representation</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">30. ReLU-Based and DNN-Based Generalized Maximum Score Estimators
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Xiaohong Chen, Wayne Yuan Gao, Likang Wen</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The ReLU-based Maximum Score (RMS) estimator replaces indicator functions with Lipschitz ReLU compositions, facilitating gradient-based optimization of the maximum score criterion and generalizing the framework to multi-index single-crossing conditions with established convergence guarantees. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We propose a new formulation of the maximum score estimator that uses compositions of rectified linear unit (ReLU) functions, instead of indicator functions as in Manski (1975,1985), to encode the sign alignment restrictions. Since the ReLU function is Lipschitz, our new ReLU-based maximum score criterion function is substantially easier to optimize using standard gradient-based optimization pacakges. We also show that our ReLU-based maximum score (RMS) estimator can be generalized to an umbrella framework defined by multi-index single-crossing (MISC) conditions, while the original maximum score estimator cannot be applied. We establish the $n^{-s/(2s+1)}$ convergence rate and asymptotic normality for the RMS estimator under order-$s$ Holder smoothness. In addition, we propose an alternative estimator using a further reformulation of RMS as a special layer in a deep neural network (DNN) architecture, which allows the estimation procedure to be implemented via state-of-the-art software and hardware for DNN.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.19121" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.19121" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.19121" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">econ.EM</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods / Deep Learning, Advanced Architectures, Representation</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">31. Beyond the Monsters: A More Complete Census of Black Hole Activity at Cosmic Dawn
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">Madisyn Brooks, Jonathan R. Trump, Raymond C. Simons, Justin Cole, Anthony J. Taylor, Micaela B. Bagley, Steven L. Finkelstein, Kelcey Davis, Ricardio O. Amorín, Bren E. Backhaus, et al.</span>
                                <span class="author-full" style="display: none;">Madisyn Brooks, Jonathan R. Trump, Raymond C. Simons, Justin Cole, Anthony J. Taylor, Micaela B. Bagley, Steven L. Finkelstein, Kelcey Davis, Ricardio O. Amorín, Bren E. Backhaus, Nikko J. Cleri, Mauro Giavalisco, Norman A. Grogin, Michaela Hirschmann, Benne W. Holwerda, Marc Huertas-Company, Jeyhan S. Kartaltepe, Dale D. Kocevksi, Anton M. Koekemoer, Ray A. Lucas, Fabio Pacucci, Xin Wang</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Detailed stacking analysis of JWST spectroscopic data reveals that black holes in the early universe are generally consistent with light stellar remnant seeds and are only moderately over-massive relative to their host galaxies, suggesting individual AGN detections suffer from selection bias toward the upper envelope of the $M_{BH}-M_*$ relation. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">JWST has revealed an abundance of low-luminosity active galactic nuclei (AGN) at high redshifts ($z &gt; 3$), pushing the limits of black hole (BH) science in the early Universe. Results have claimed that these BHs are significantly more massive than expected from the BH mass-host galaxy stellar mass relation derived from the local Universe. We present a comprehensive census of the BH populations in the early Universe through a detailed stacking analysis of galaxy populations, binned by luminosity and redshift, using JWST spectroscopy from the CEERS, JADES, RUBIES, and GLASS extragalactic deep field surveys. Broad H$α$ detections in $31\%$ of the stacked spectra (5/16 bins) imply median BH masses of $10^{5.21} - 10^{6.13}~ \rm{M_{\odot}}$ and the stacked SEDs of these bins indicate median stellar masses of $10^{7.84} - 10^{8.56} ~\rm{M_{\odot}}$. This suggests that the median galaxy hosts a BH that is at most a factor of 10 times over-massive compared to its host galaxy and lies closer to the locally derived $M_{BH}-M_*$ relation. We investigate the seeding properties of the inferred BHs and find that they can be well-explained by a light stellar remnant seed undergoing moderate Eddington accretion. Our results indicate that individual detections of AGN are more likely to sample the upper envelope of the $M_{BH}-M_*$ distribution, while stacking on ``normal&#34; galaxies and searching for AGN signatures can overcome the selection bias of individual detections.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.19609" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.19609" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.19609" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Weak Lensing, Cosmological Constraints, Survey Systematics / Weak Lensing, Galaxy Clustering, Halo Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">32. From Passive Perception to Active Memory: A Weakly Supervised Image Manipulation Localization Framework Driven by Coarse-Grained Annotations
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Zhiqing Guo, Dongdong Xi, Songlin Li, Gaobo Yang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> BoxPromptIML, a novel weakly-supervised framework, balances annotation cost and localization performance by using coarse region prompts and knowledge distillation from a SAM-based teacher, achieving state-of-the-art accuracy and robustness in image manipulation localization. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Image manipulation localization (IML) faces a fundamental trade-off between minimizing annotation cost and achieving fine-grained localization accuracy. Existing fully-supervised IML methods depend heavily on dense pixel-level mask annotations, which limits scalability to large datasets or real-world deployment.In contrast, the majority of existing weakly-supervised IML approaches are based on image-level labels, which greatly reduce annotation effort but typically lack precise spatial localization. To address this dilemma, we propose BoxPromptIML, a novel weakly-supervised IML framework that effectively balances annotation cost and localization performance. Specifically, we propose a coarse region annotation strategy, which can generate relatively accurate manipulation masks at lower cost. To improve model efficiency and facilitate deployment, we further design an efficient lightweight student model, which learns to perform fine-grained localization through knowledge distillation from a fixed teacher model based on the Segment Anything Model (SAM). Moreover, inspired by the human subconscious memory mechanism, our feature fusion module employs a dual-guidance strategy that actively contextualizes recalled prototypical patterns with real-time observational cues derived from the input. Instead of passive feature extraction, this strategy enables a dynamic process of knowledge recollection, where long-term memory is adapted to the specific context of the current image, significantly enhancing localization accuracy and robustness. Extensive experiments across both in-distribution and out-of-distribution datasets show that BoxPromptIML outperforms or rivals fully-supervised models, while maintaining strong generalization, low annotation cost, and efficient deployment characteristics.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.20359" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.20359" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.20359" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.CV</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods / Deep Learning, Advanced Architectures, Representation</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">33. Towards Efficient VLMs: Information-Theoretic Driven Compression via Adaptive Structural Pruning
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Zhaoqi Xu, Yingying Zhang, Jian Li, Jianwei Guo, Qiannan Zhu, Hua Huang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> InfoPrune, an information-theoretic framework based on the Information Bottleneck principle, enables adaptive structural compression of Vision-Language Models by quantifying information loss using entropy-based effective rank and Kolmogorov–Smirnov distance, resulting in substantial efficiency gains. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Recent advances in vision-language models (VLMs) have shown remarkable performance across multimodal tasks, yet their ever-growing scale poses severe challenges for deployment and efficiency. Existing compression methods often rely on heuristic importance metrics or empirical pruning rules, lacking theoretical guarantees about information preservation. In this work, we propose InfoPrune, an information-theoretic framework for adaptive structural compression of VLMs. Grounded in the Information Bottleneck principle, we formulate pruning as a trade-off between retaining task-relevant semantics and discarding redundant dependencies. To quantify the contribution of each attention head, we introduce an entropy-based effective rank (eRank) and employ the Kolmogorov--Smirnov (KS) distance to measure the divergence between original and compressed structures. This yields a unified criterion that jointly considers structural sparsity and informational efficiency. Building on this foundation, we further design two complementary schemes: (1) a training-based head pruning guided by the proposed information loss objective, and (2) a training-free FFN compression via adaptive low-rank approximation. Extensive experiments on VQAv2, TextVQA, and GQA demonstrate that InfoPrune achieves up to 3.2x FLOP reduction and 1.8x acceleration with negligible performance degradation, establishing a theoretically grounded and practically effective step toward efficient multimodal large models.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.19518" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.19518" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.19518" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.CV</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods / Deep Learning, Advanced Architectures, Representation</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">34. TiCT: A Synthetically Pre-Trained Foundation Model for Time Series Classification
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Chin-Chia Michael Yeh, Uday Singh Saini, Junpeng Wang, Xin Dai, Xiran Fan, Jiarui Sun, Yujie Fan, Yan Zheng</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> TiCT, a transformer model pre-trained only on synthetic data, successfully performs competitive time-series classification using only in-context examples at inference time, leveraging a novel architecture designed for scalable bit-based label encoding and arbitrary class handling. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The ubiquity of time series data creates a strong demand for general-purpose foundation models, yet developing them for classification remains a significant challenge, largely due to the high cost of labeled data. Foundation models capable of in-context learning (ICL) offer a powerful solution, adapting to new tasks with minimal examples and reducing the need for extensive retraining. However, prior work on large-scale time series models has predominantly focused on forecasting, leaving a critical gap for versatile, fine-tuning-free classification. To address this, we introduce TiCT (Time-series in-Context Transformer), a transformer-based model pre-trained exclusively on synthetic data to perform in-context classification. We make two primary technical contributions: 1) a novel architecture featuring a scalable bit-based label encoding and a special output attention mechanism to handle an arbitrary number of classes; and 2) a synthetic pre-training framework that combines a Mixup-inspired process with data augmentation to foster generalization and noise invariance. Extensive evaluations on the UCR Archive show that TiCT achieves competitive performance against state-of-the-art supervised methods. Crucially, this is accomplished using only in-context examples at inference time, without updating a single model weight.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.19694" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.19694" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.19694" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.LG</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods / Deep Learning, Advanced Architectures, Representation</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">35. Object-Centric Vision Token Pruning for Vision Language Models
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Guangyuan Li, Rongzhen Zhao, Jinhong Deng, Yanbo Wang, Joni Pajarinen</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> High VLM inference efficiency is achieved by OC-VTP, a method that pre-trains a lightweight object-centric pruner to directly select the most representative vision tokens by minimizing reconstruction error, thereby preserving accuracy across various pruning ratios without VLM fine-tuning. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">In Vision Language Models (VLMs), vision tokens are quantity-heavy yet information-dispersed compared with language tokens, thus consume too much unnecessary computation. Pruning redundant vision tokens for high VLM inference efficiency has been continuously studied but all existing methods resort to indirect and non-guaranteed ways. We propose OC-VTP, a direct and guaranteed approach to select the most representative vision tokens for high-efficiency yet accuracy-preserving VLM inference. Our OC-VTP requires merely light-weight pre-training of a small object-centric vision token pruner, which can then be inserted into existing VLMs, without fine-tuning of any models on any datasets. It is gauranteed that the most representative vision tokens are kept by minimizing the error in reconstructing the original unpruned tokens from the selected ones. Across any vision pruning ratios, i.e., inference efficiency, our OC-VTP consistently helps mainstream VLMs to preserve the highest inference accuracy. Our pruning also demonstrates interesting interpretability. Our codes are available at https://github.com/GarryLarry010131/OC-VTP.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.20439" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.20439" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.20439" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.CV</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods / Deep Learning, Advanced Architectures, Representation</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">36. Masked Diffusion Models are Secretly Learned-Order Autoregressive Models
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Prateek Garg, Bhavya Kohli, Sunita Sarawagi</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Masked Diffusion Models can optimize their decoding order during training by utilizing multivariate noise schedules within the continuous-time variational objective, fundamentally establishing them as auto-regressive models with an inherent capacity for learning optimal token sequencing. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Masked Diffusion Models (MDMs) have emerged as one of the most promising paradigms for generative modeling over discrete domains. It is known that MDMs effectively train to decode tokens in a random order, and that this ordering has significant performance implications in practice. This observation raises a fundamental question: can we design a training framework that optimizes for a favorable decoding order? We answer this in the affirmative, showing that the continuous-time variational objective of MDMs, when equipped with multivariate noise schedules, can identify and optimize for a decoding order during training. We establish a direct correspondence between decoding order and the multivariate noise schedule and show that this setting breaks invariance of the MDM objective to the noise schedule. Furthermore, we prove that the MDM objective decomposes precisely into a weighted auto-regressive losses over these orders, which establishes them as auto-regressive models with learnable orders.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.19152" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.19152" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.19152" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.LG</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods / Deep Learning, Advanced Architectures, Representation</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">37. Merge and Bound: Direct Manipulations on Weights for Class Incremental Learning
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Taehoon Kim, Donghwan Jang, Bohyung Han</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The Merge-and-Bound (M&amp;B) training approach enhances Class Incremental Learning performance by mitigating catastrophic forgetting through parameter space optimization, utilizing both inter-task and intra-task weight merging alongside a bounded update strategy that preserves knowledge from previous tasks. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We present a novel training approach, named Merge-and-Bound (M&amp;B) for Class Incremental Learning (CIL), which directly manipulates model weights in the parameter space for optimization. Our algorithm involves two types of weight merging: inter-task weight merging and intra-task weight merging. Inter-task weight merging unifies previous models by averaging the weights of models from all previous stages. On the other hand, intra-task weight merging facilitates the learning of current task by combining the model parameters within current stage. For reliable weight merging, we also propose a bounded update technique that aims to optimize the target model with minimal cumulative updates and preserve knowledge from previous tasks; this strategy reveals that it is possible to effectively obtain new models near old ones, reducing catastrophic forgetting. M&amp;B is seamlessly integrated into existing CIL methods without modifying architecture components or revising learning objectives. We extensively evaluate our algorithm on standard CIL benchmarks and demonstrate superior performance compared to state-of-the-art methods.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.21490" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.21490" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.21490" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.CV</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods / Deep Learning, Advanced Architectures, Representation</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">38. Many Ways to be Right: Rashomon Sets for Concept-Based Neural Networks
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Shihan Feng, Cheng Zhang, Michael Xi, Ethan Hsu, Lesia Semenova, Chudi Zhong</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Rashomon Concept Bottleneck Models efficiently explore the diversity inherent in near-optimal solutions by training multiple accurate networks, which rely on distinct human-understandable concepts via lightweight adapters and a diversity-regularized objective, thereby revealing varied reasoning processes for identical predictions. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Modern neural networks rarely have a single way to be right. For many tasks, multiple models can achieve identical performance while relying on different features or reasoning patterns, a property known as the Rashomon Effect. However, uncovering this diversity in deep architectures is challenging as their continuous parameter spaces contain countless near-optimal solutions that are numerically distinct but often behaviorally similar. We introduce Rashomon Concept Bottleneck Models, a framework that learns multiple neural networks which are all accurate yet reason through distinct human-understandable concepts. By combining lightweight adapter modules with a diversity-regularized training objective, our method constructs a diverse set of deep concept-based models efficiently without retraining from scratch. The resulting networks provide fundamentally different reasoning processes for the same predictions, revealing how concept reliance and decision making vary across equally performing solutions. Our framework enables systematic exploration of data-driven reasoning diversity in deep models, offering a new mechanism for auditing, comparison, and alignment across equally accurate solutions.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.19636" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.19636" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.19636" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.LG</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods / Deep Learning, Advanced Architectures, Representation</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">39. How Learning Rate Decay Wastes Your Best Data in Curriculum-Based LLM Pretraining
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Kairong Luo, Zhenbo Sun, Haodong Wen, Xinyu Shi, Jiarui Cui, Chenyi Dang, Kaifeng Lyu, Wenguang Chen</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Curriculum-based pretraining for Large Language Models is significantly improved by mitigating the incompatibility between ascending data quality order and standard learning rate decay schedules, achieved through either moderate decay or replacing decay with model averaging. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Due to the scarcity of high-quality data, large language models (LLMs) are often trained on mixtures of data with varying quality levels, even after sophisticated data curation. A natural approach to better leverage high-quality data is curriculum-based pretraining, where the model is trained on data sorted in ascending order of quality as determined by a quality metric. However, prior studies have reported limited improvements from such curriculum-based pretraining strategies. This work identifies a critical factor constraining these methods: the incompatibility between the ascending data quality order and the decaying learning rate (LR) schedule. We find that while curriculum-based training substantially outperforms random shuffling when using a constant LR, its advantage diminishes under standard LR decay schedules. Our experiments show this incompatibility can be mitigated by two simple strategies: (1) employing a more moderate LR decay schedule, where the final LR is only moderately smaller than the peak LR, and (2) replacing LR decay with model averaging, i.e., computing a weighted average of the final few checkpoints. By combining these strategies, we improve the average score on a suite of standard benchmarks by 1.64% over random shuffling, without additional data refinement. Validated on 1.5B-parameter models trained over 30B tokens with various data-quality metrics, our findings call for a re-evaluation of curriculum-based LLM pretraining and underscore the potential of co-designing data curricula with optimization methods.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.18903" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.18903" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.18903" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.LG</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods / Deep Learning, Advanced Architectures, Representation</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">40. FastForward Pruning: Efficient LLM Pruning via Single-Step Reinforcement Learning
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Xin Yuan, Siqi Li, Jiateng Wei, Chengrui Zhu, Yanming Wu, Qingpeng Li, Jiajun Lv, Xiaoke Lan, Jun Chen, Yong Liu</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> FastForward Pruning introduces a decoupled, single-step Reinforcement Learning framework that efficiently determines optimal non-uniform layer-wise sparsity allocations for Large Language Models, achieving competitive performance at a fraction of the computational cost of prior search-based methods. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Pruning is an effective method for compressing Large Language Models, but finding an optimal, non-uniform layer-wise sparsity allocation remains a key challenge. While heuristic methods are fast but yield suboptimal performance, more powerful search-based approaches like Reinforcement Learning are often hindered by prohibitive computational costs on large-scale models. To overcome this efficiency barrier, we propose FastForward Pruning. Its core is a decoupled, single-step RL framework that separates policy optimization from the complex budget satisfaction problem. Such a decoupling is crucial for efficiently searching the vast policy space of LLMs. This curriculum-based strategy begins with low-cost, simple tasks and gradually increases in complexity, significantly reducing the search&#39;s computational overhead. Evaluated on the LLaMA, Mistral, and OPT model families, our framework discovers pruning policies that achieve superior performance over strong heuristic baselines. Crucially, when compared to other search-based algorithms, our method achieves competitive or superior results at a fraction of the computational cost, demonstrating a clear advantage in search efficiency.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.18977" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.18977" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.18977" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.LG</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods / Deep Learning, Advanced Architectures, Representation</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">41. Cosmological tensions in Proca-Nuevo theory
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Hsu-Wen Chiang, Claudia de Rham, Sebastian Garcia-Saenz, Xue Zhou</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The extended Proca-Nuevo vector-tensor theory provides a viable dark energy framework that significantly reduces the Hubble tension and is statistically favored over $\Lambda$CDM by current cosmological datasets, despite requiring mild tuning to manage the vector field&#39;s impact on matter perturbations. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We study the cosmological predictions of (extended) Proca-Nuevo theory. This vector-tensor theory enjoys stable homogeneous and isotropic solutions characterized by an effective dark energy fluid, with behavior that ranges from freezing quintessential to thawing phantom-like, serving as a motivated framework to scrutinize the cosmological tensions that affect the standard $Λ$CDM model. While the model we consider is sufficiently generic to encompass a large class of field theories, it distinguishes itself from scalar dark energy models (quintessential ones, kinetic ones and non-minimally coupled ones) by the presence of what would be classed as a vector degree of freedom which can be for instance inherited from more generic theories of gravity. We improve on previous work in several directions: we consider a general one-parameter class of background models; identify a so-called &#39;special&#39; model and analyze observational constraints taking also into account perturbations and making use of wide up-to-date catalogs of datasets including recently released ones. We find that the one-parameter Proca-Nuevo model is preferred over $Λ$CDM at $1.5σ$ when fitting CMB and BAO data, and at $2.4σ$ when further adding low-redshift data. The Hubble tension is alleviated, dropping from $5.8σ$ to $2.3σ$ (resp. $1.5σ$) between CMB with (and resp. without) BAO data and local measurements. On the other hand, we find that the vector field generically introduces a significant enhancement of the effective Newton constant, so that matching the observed matter power spectrum requires a mild amount of tuning to suppress the impact of perturbations. Since, at the background level, Proca-Nuevo is degenerate with other classes of theories, our results are also relevant to a wider range of set-ups including and beyond vector-tensor models.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.21071" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.21071" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.21071" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.02</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">hep-th</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">42. StarEstate: A Python Package for Galactic Population Synthesis
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Amedeo Romagnolo</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> StarEstate is an open-source Python package that accelerates galactic population synthesis modeling by using optimized statistical samplers and incorporating age-dependent dynamics to realistically assign stars to spiral arms based on stellar evolutionary tracks. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">I present StarEstate, an open-source Python package for producing rapid, statistically robust galactic population synthesis models. By utilizing optimized pre-calculated inverse-cumulative distribution function samplers, the tool generates synthetic populations from pre-generated grids of stellar tracks orders of magnitude faster than traditional numerical integration methods. A key morphological feature is the probabilistic assignment of stars to spiral arms based on age-dependent dynamical temperature, reproducing the observation that young tracers tightly confine to arms while older populations disperse. The software combines statistical generation with stellar physics by mapping synthetic populations to MESA or rapid SSE/BSE evolutionary tracks. Users can inspect specific evolutionary stages through automatic hierarchical classification, distinguishing evolutionary phases and spectral classes like Wolf-Rayet, O-type, or red supergiant stars across different metallicity environments. StarEstate&#39;s features allow the user to predict spatial distributions of diverse stellar objects, providing a flexible resource for interpreting galactic surveys.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.20735" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.20735" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.20735" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.IM</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">43. Searching Stochastic Gravitational Wave Background Landscape Across Frequency Bands
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Yunjia Bao, Tore Boybeyi, Vuk Mandic, Lian-Tao Wang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Analyzing the gravitational wave signature of hybrid topological defects formed during a two-step phase transition, multi-band GW observations are shown to be crucial for confirming or excluding this new physics scenario, which potentially explains the current pulsar timing array signal. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Gravitational wave (GW) astrophysics is entering a multi-band era with upcoming GW detectors, enabling detailed mapping of the stochastic GW background across vast frequencies. We highlight this potential via a new physics scenario: hybrid topological defects from a two-step phase transition separated by inflation. We develop a general pipeline to analyze experimental exclusions and apply it to this model. The model offers a possible explanation of the pulsar timing array signal at low frequencies, and future experiments (LISA/Cosmic Explorer/Einstein Telescope) will confirm or rule it out via the higher-frequency probes, showcasing the power of multi-band constraints.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.19590" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.19590" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.19590" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">gr-qc</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">44. Rethinking Garment Conditioning in Diffusion-based Virtual Try-On
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Kihyun Na, Jinyoung Choi, Injung Kim</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Re-CatVTON is introduced as an efficient single UNet architecture for Virtual Try-On that surpasses its predecessor and approaches the performance of computationally expensive Dual UNet models by employing tailored classifier-free guidance and direct garment latent injection. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Virtual Try-On (VTON) is the task of synthesizing an image of a person wearing a target garment, conditioned on a person image and a garment image. While diffusion-based VTON models featuring a Dual UNet architecture demonstrate superior fidelity compared to single UNet models, they incur substantial computational and memory overhead due to their heavy structure. In this study, through visualization analysis and theoretical analysis, we derived three hypotheses regarding the learning of context features to condition the denoising process. Based on these hypotheses, we developed Re-CatVTON, an efficient single UNet model that achieves high performance. We further enhance the model by introducing a modified classifier-free guidance strategy tailored for VTON&#39;s spatial concatenation conditioning, and by directly injecting the ground-truth garment latent derived from the clean garment latent to prevent the accumulation of prediction error. The proposed Re-CatVTON significantly improves performance compared to its predecessor (CatVTON) and requires less computation and memory than the high-performance Dual UNet model, Leffa. Our results demonstrate improved FID, KID, and LPIPS scores, with only a marginal decrease in SSIM, establishing a new efficiency-performance trade-off for single UNet VTON models.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.18775" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.18775" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.18775" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.CV</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods / Deep Learning, Advanced Architectures, Representation</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">45. MapReduce LoRA: Advancing the Pareto Front in Multi-Preference Optimization for Generative Models
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">Chieh-Yun Chen, Zhonghao Wang, Qi Chen, Zhifan Ye, Min Shi, Yue Zhao, Yinan Zhao, Hui Qu, Wei-An Lin, Yiru Shen, et al.</span>
                                <span class="author-full" style="display: none;">Chieh-Yun Chen, Zhonghao Wang, Qi Chen, Zhifan Ye, Min Shi, Yue Zhao, Yinan Zhao, Hui Qu, Wei-An Lin, Yiru Shen, Ajinkya Kale, Irfan Essa, Humphrey Shi</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A new multi-preference alignment framework utilizing MapReduce LoRA for expert merging and Reward-aware Token Embedding (RaTE) for flexible control successfully mitigates the alignment tax in RLHF, achieving state-of-the-art performance across diverse generative model modalities. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Reinforcement learning from human feedback (RLHF) with reward models has advanced alignment of generative models to human aesthetic and perceptual preferences. However, jointly optimizing multiple rewards often incurs an alignment tax, improving one dimension while degrading others. To address this, we introduce two complementary methods: MapReduce LoRA and Reward-aware Token Embedding (RaTE). MapReduce LoRA trains preference-specific LoRA experts in parallel and iteratively merges them to refine a shared base model; RaTE learns reward-specific token embeddings that compose at inference for flexible preference control. Experiments on Text-to-Image generation (Stable Diffusion 3.5 Medium and FLUX.1-dev) show improvements of 36.1%, 4.6%, and 55.7%, and 32.7%, 4.3%, and 67.1% on GenEval, PickScore, and OCR, respectively. On Text-to-Video generation (HunyuanVideo), visual and motion quality improve by 48.1% and 90.0%, respectively. On the language task, Helpful Assistant, with Llama-2 7B, helpful and harmless improve by 43.4% and 136.7%, respectively. Our framework sets a new state-of-the-art multi-preference alignment recipe across modalities.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.20629" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.20629" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.20629" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.01</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">cs.CV</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods / Deep Learning, Advanced Architectures, Representation</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">46. ROOT: Robust Orthogonalized Optimizer for Neural Network Training
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Wei He, Kai Han, Hang Zhou, Hanting Chen, Zhicheng Liu, Xinghao Chen, Yunhe Wang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The Robust Orthogonalized Optimizer (ROOT) improves the stability and convergence of large language model training by implementing a dimension-robust orthogonalization scheme with adaptive Newton iterations and a proximal optimization framework to effectively suppress gradient noise. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The optimization of large language models (LLMs) remains a critical challenge, particularly as model scaling exacerbates sensitivity to algorithmic imprecision and training instability. Recent advances in optimizers have improved convergence efficiency through momentum orthogonalization, but suffer from two key robustness limitations: dimensional fragility in orthogonalization precision and vulnerability to outlier-induced noise. To address these robustness challenges, we introduce ROOT, a Robust Orthogonalized Optimizer that enhances training stability through dual robustness mechanisms. First, we develop a dimension-robust orthogonalization scheme using adaptive Newton iterations with fine-grained coefficients tailored to specific matrix sizes, ensuring consistent precision across diverse architectural configurations. Second, we introduce an optimization-robust framework via proximal optimization that suppresses outlier noise while preserving meaningful gradient directions. Extensive experiments demonstrate that ROOT achieves significantly improved robustness, with faster convergence and superior final performance compared to both Muon and Adam-based optimizers, particularly in noisy and non-convex scenarios. Our work establishes a new paradigm for developing robust and precise optimizers capable of handling the complexities of modern large-scale model training. The code will be available at https://github.com/huawei-noah/noah-research/tree/master/ROOT.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.20626" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.20626" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.20626" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.LG</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods / Deep Learning, Advanced Architectures, Representation</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">47. Curvature Perturbations from Higgs Modulated Reheating
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Weiyi Deng, Chengcheng Han, Zhanhong Lei, Jin Min Yang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Curvature perturbations and local non-Gaussianity generated during Higgs modulated reheating are reliably calculated using the non-perturbative $\delta N$ formalism, revealing that a smaller Higgs self-coupling significantly increases the magnitude of the curvature perturbation. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">In this work we investigate curvature perturbations and non-Gaussianity arising from Higgs modulated reheating in the early Universe. We employ three different methods -- the period-averaging (PA) method, the exact method, and the non-perturbative $δN$ formalism -- to compute the power spectrum and bispectrum of curvature perturbations. Our results show that the non-perturbative $δN$ method provides a reliable estimate across a wide range of reheating time and Higgs field values, including regimes where the Higgs field oscillates significantly after inflation. We find that a smaller Higgs self-coupling ($λ$) leads to a larger curvature perturbation, with the non-Gaussianity predominantly taking a local shape. This highlights the importance of considering non-perturbative effects in calculating the curvature perturbation during Higgs modulated reheating, especially for smaller values of $λ$. Our findings offer valuable insights into the dynamics of reheating and the generation of primordial perturbations in the early Universe.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.18340" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.18340" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.18340" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">48. In medio stat virtus: enrichment history in poor galaxy clusters
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>G. Riva, S. Ghizzardi, S. Molendi, M. Balboni, I. Bartalucci, S. De Grandi, F. Gastaldello, L. Lovisari, M. Rossetti</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Accurate XMM-Newton measurements of three intermediate-mass galaxy clusters demonstrate that their iron abundance profiles are flat out to the outskirts, matching the profiles of massive clusters once soft X-ray background systematics are properly mitigated, providing new constraints on chemical enrichment in this transitional mass range. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The enrichment history of galaxy clusters and groups remains far from being fully understood. Recent measurements in massive clusters have revealed remarkably flat iron abundance profiles out to the outskirts, suggesting that similar enrichment processes have occurred for all systems. In contrast, abundance profiles in galaxy groups have sometimes been measured to decline with radius, challenging our understanding of the physical processes at these scales. In this paper, we present a pilot study aimed at accurately measuring the iron abundance profiles of MKW3s, A2589, and Hydra A, three poor clusters with total masses of $M_{500} \simeq 2.0-2.5 \times 10^{14}$ M$_\odot$, intermediate between the scales of galaxy groups and massive clusters. Using XMM-Newton to obtain nearly complete azimuthal coverage of the outer regions of these systems, we show that abundance measurements in the outskirts are more likely to be limited by systematics than by statistical errors. In particular, inaccurate modelling of the soft X-ray background can significantly bias metallicity estimates in regions where the cluster emission is faint. Once these systematics are properly accounted for, the abundance profiles of all three clusters appear to be flat at $Z \sim 0.3$ Z$_{\odot}$, in agreement with values observed in massive clusters. Using available stellar mass estimates, we also computed their iron yields, thereby beginning to probe a largely unexplored mass range. We find $Y_{Fe,500} = 2.68\pm0.34$, $2.54\pm0.64$, and $7.51\pm1.47$ Z$_{\odot}$ for MKW3s, A2589, and Hydra A, respectively, spanning the transition regime between galaxy groups and massive clusters. Future observations of systems with temperatures of $2-4$ keV will be essential to further populate this intermediate-mass regime and to draw firmer conclusions on the chemical enrichment history of galaxy systems across the full mass scale.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.19603" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.19603" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.19603" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Weak Lensing, Cosmological Constraints, Survey Systematics / Weak Lensing, Galaxy Clustering, Halo Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">49. Denoising gravitational wave with deep learning in the time-frequency domain
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Yi-De Lee, Hwei-Jang Yo</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A deep learning model incorporating the Griffin-Lim algorithm is proposed for gravitational wave denoising of binary black hole mergers, effectively restoring phase information from the amplitude spectrogram to achieve high accuracy in both phase and amplitude alignment, especially during the merger phase. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Gravitational wave denoising is an ongoing task for revealing the events of compact binary objects in the universe. Recently, with the aid of deep learning, gravitational waves have been efficiently and delicately extracted from the noisy data compared with the traditional match-filtering. While most of the relevant studies adopt the data in the time series only, the time-frequency data processing is also in progress due to its several advantages for the waveform denoising. Here, we target the gravitational waves events emitted by binary black hole (BBH) mergers, with their total mass larger than 30 solar masses. For denoising, we propose a deep learning model utilizing the Griffin-Lim algorithm, an existing numerical approach to restore the phase information from the related amplitude spectrogram. This design allows extra attention on the phase recovery by using a priorly denoised amplitude spectrogram. The denoising results fit well in both the amplitude and the phase alignments of the mock injected waveforms. We also apply our model to the real detected events and discover a nice consistency with the simulated template waveforms, especially the high accuracy around the merger stage. Our work suggests the possibility of a better methodological design for gravitational wave data analysis.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.20731" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.20731" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.20731" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">gr-qc</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">50. VADE: Variance-Aware Dynamic Sampling via Online Sample-Level Difficulty Estimation for Multimodal RL
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Zengjie Hu, Jiantao Qiu, Tianyi Bai, Haojin Yang, Binhang Yuan, Qi Jing, Conghui He, Wentao Zhang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> VADE, a Variance-Aware Dynamic sampling framework, resolves the gradient vanishing issue in group-based policy optimization by using online difficulty estimation and a Thompson sampler to dynamically select informative samples, thereby boosting performance and sample efficiency in multimodal reasoning tasks. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Group-based policy optimization methods like GRPO and GSPO have become standard for training multimodal models, leveraging group-wise rollouts and relative advantage estimation. However, they suffer from a critical \emph{gradient vanishing} problem when all responses within a group receive identical rewards, causing advantage estimates to collapse and training signals to diminish. Existing attempts to mitigate this issue fall into two paradigms: filtering-based and sampling-based methods. Filtering-based methods first generate rollouts broadly and then retroactively filter out uninformative groups, leading to substantial computational overhead. Sampling-based methods proactively select effective samples before rollout but rely on static criteria or prior dataset knowledge, lacking real-time adaptability. To address these issues, we propose \textbf{VADE}, a \textbf{V}ariance-\textbf{A}ware \textbf{D}ynamic sampling framework via online sample-level difficulty \textbf{E}stimation. Our framework integrates three key components: online sample-level difficulty estimation using Beta distributions, a Thompson sampler that maximizes information gain through the estimated correctness probability, and a two-scale prior decay mechanism that maintains robust estimation under policy evolution. This three components design enables VADE to dynamically select the most informative samples, thereby amplifying training signals while eliminating extra rollout costs. Extensive experiments on multimodal reasoning benchmarks show that VADE consistently outperforms strong baselines in both performance and sample efficiency, while achieving a dramatic reduction in computational overhead. More importantly, our framework can serves as a plug-and-play component to be seamlessly integrated into existing group-based RL algorithms. Code and models are available at https://VADE-RL.github.io.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2511.18902" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2511.18902" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2511.18902" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.01</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">cs.LG</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Statistical Sampling, Bayesian Methods / Deep Learning, Advanced Architectures, Representation</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
    </div>

    <footer class="footer">
        &copy; 2025 arXiv Daily · Powered by <a href="https://arxiv.org/" target="_blank">arXiv</a>
    </footer>
</body>
</html>