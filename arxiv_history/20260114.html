<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>arXiv Daily: 2026-01-14</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Roboto:400,700&display=swap" rel="stylesheet">
    <style>
        body { font-family: 'Roboto', Arial, sans-serif; background: #f8f9fa; transition: background 0.3s; }
        .arxiv-card { margin: 2em auto; max-width: 900px; box-shadow: 0 2px 8px rgba(0,0,0,0.08); border-radius: 16px; transition: box-shadow 0.3s, transform 0.3s; }
        .arxiv-card:hover { box-shadow: 0 4px 12px rgba(0,0,0,0.1); transform: translateY(-1px); }
        .arxiv-title { background: linear-gradient(90deg, #0d6efd 60%, #6610f2 100%); color: #fff; border-radius: 16px 16px 0 0; padding: 1.5em; font-size: 1.5em; font-weight: 700; letter-spacing: 0.5px;}
        .arxiv-meta { font-size: 1em; color: #555; margin-bottom: 1em; }
        .arxiv-abstract { background: #fff; padding: 1.5em; border-radius: 0 0 16px 16px; font-size: 1.1em; line-height: 1.7;}
        .arxiv-links a { margin-right: 1em; }
        .arxiv-scores { margin-top: 1em; font-size: 1em; }
        .navbar { background: #fff; box-shadow: 0 2px 8px rgba(0,0,0,0.04);}
        .footer { text-align: center; color: #888; padding: 2em 0 1em 0; font-size: 0.95em;}
        @media (prefers-color-scheme: dark) {
            body { background: #181a1b; color: #e4e6eb; }
            .arxiv-card { background: #23272b; box-shadow: 0 2px 8px rgba(0,0,0,0.28);}
            .arxiv-card:hover { box-shadow: 0 5px 15px rgba(0,0,0,0.25); transform: translateY(-1px); }
            .arxiv-title { background: linear-gradient(90deg, #375a7f 60%, #6f42c1 100%);}
            .arxiv-abstract { background: #23272b; color: #e4e6eb;}
            .navbar { background: #23272b; color: #e4e6eb;}
            .text-muted { color: #adb5bd !important; }
        }
        /* Improved abstract readability */
        .arxiv-abstract-text {
            font-size: 1.1em;
            line-height: 1.7;
        }
        p.big {
            line-height: 1.6;
            font-size: large;
        }
    </style>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'] ],
          processEscapes: true
        }
      });
    </script>
    <script>
    function toggleAuthors(element) {
        const fullList = element.querySelector('.author-full');
        const shortList = element.querySelector('.author-short');
        const toggleText = element.querySelector('.author-toggle');
        
        fullList.style.display = fullList.style.display === 'none' ? 'inline' : 'none';
        shortList.style.display = shortList.style.display === 'none' ? 'inline' : 'none';
        toggleText.textContent = fullList.style.display === 'none' ? ' (show all)' : ' (show less)';
    }
    </script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
</head>
<body>
    <nav class="navbar navbar-expand-lg mb-4">
        <div class="container">
            <a class="navbar-brand fw-bold text-primary" href="#">arXiv Daily</a>
            <span class="navbar-text">Modern arXiv Reader</span>
        </div>
    </nav>

    
    <div class="container py-4">
        <header class="mb-4"><h2 class="display-6 text-center">Analysis of Your Favorites</h2></header>
        
        <div class="row justify-content-center">
            <div class="col-lg-8 mb-4">
                <div class="card">
                    <div class="card-header fw-bold">Interest Word Cloud</div>
                    <div class="card-body text-center p-2">
                        <img src="analysis_results/word_cloud.png" class="img-fluid rounded" alt="Word Cloud of favorite paper topics">
                    </div>
                </div>
            </div>
        </div>
        
        
        <div class="row justify-content-center">
            <div class="col-lg-8 mb-4">
                <div class="card">
                    <div class="card-header fw-bold">Interest Clusters</div>
                    <div class="card-body text-center p-2">
                        <img src="analysis_results/daily_cluster_map.png" class="img-fluid rounded" alt="2D Cluster plot of favorite papers">
                    </div>
                </div>
            </div>
        </div>
        
    </div>
    

    <div class="container py-4">
        <header class="mb-4"><h1 class="display-5 text-center text-primary">arXiv: 2026-01-14</h1></header>

        
        <div class="row justify-content-center">
            <div class="col-lg-8 mb-4">
                <div class="card">
                    <div class="card-header fw-bold">Score Distribution of All Papers Found Today</div>
                    <div class="card-body text-center p-2">
                        <img src="analysis_results/score_distribution.png" class="img-fluid rounded" alt="Score distribution of all papers found today">
                    </div>
                </div>
            </div>
        </div>
        

        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">1. Euclid preparation. Calibrated intrinsic galaxy alignments in the Euclid Flagship simulation
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">Euclid Collaboration, K. Hoffmann, R. Paviot, B. Joachimi, N. Tessore, P. Tallada-Crespí, N. E. Chisari, E. J. Gonzalez, A. Loureiro, P. Fosalba, et al.</span>
                                <span class="author-full" style="display: none;">Euclid Collaboration, K. Hoffmann, R. Paviot, B. Joachimi, N. Tessore, P. Tallada-Crespí, N. E. Chisari, E. J. Gonzalez, A. Loureiro, P. Fosalba, J. Blazek, C. Laigle, Y. Dubois, C. Pichon, B. Altieri, S. Andreon, N. Auricchio, C. Baccigalupi, M. Baldi, S. Bardelli, F. Bernardeau, A. Biviano, E. Branchini, M. Brescia, S. Camera, G. Cañas-Herrera, V. Capobianco, C. Carbone, V. F. Cardone, J. Carretero, S. Casas, F. J. Castander, M. Castellano, G. Castignani, S. Cavuoti, K. C. Chambers, A. Cimatti, C. Colodro-Conde, G. Congedo, L. Conversi, Y. Copin, F. Courbin, H. M. Courtois, A. Da Silva, H. Degaudenzi, G. De Lucia, H. Dole, F. Dubath, C. A. J. Duncan, X. Dupac, S. Dusini, S. Escoffier, M. Farina, R. Farinelli, S. Farrens, S. Ferriol, F. Finelli, N. Fourmanoit, M. Frailis, E. Franceschi, M. Fumana, S. Galeotta, K. George, B. Gillis, C. Giocoli, J. Gracia-Carpio, A. Grazian, F. Grupp, S. V. H. Haugan, H. Hoekstra, W. Holmes, F. Hormuth, A. Hornstrup, K. Jahnke, M. Jhabvala, E. Keihänen, S. Kermiche, A. Kiessling, M. Kilbinger, B. Kubik, M. Kümmel, M. Kunz, H. Kurki-Suonio, A. M. C. Le Brun, S. Ligori, P. B. Lilje, V. Lindholm, I. Lloro, G. Mainetti, D. Maino, E. Maiorano, O. Mansutti, S. Marcin, O. Marggraf, M. Martinelli, N. Martinet, F. Marulli, R. J. Massey, E. Medinaceli, S. Mei, Y. Mellier, M. Meneghetti, E. Merlin, G. Meylan, A. Mora, M. Moresco, L. Moscardini, C. Neissner, S. -M. Niemi, C. Padilla, S. Paltani, F. Pasian, K. Pedersen, V. Pettorino, S. Pires, G. Polenta, M. Poncet, L. A. Popa, L. Pozzetti, F. Raison, R. Rebolo, A. Renzi, J. Rhodes, G. Riccio, E. Romelli, M. Roncarelli, R. Saglia, Z. Sakr, A. G. Sánchez, D. Sapone, B. Sartoris, P. Schneider, T. Schrabback, A. Secroun, E. Sefusatti, G. Seidel, S. Serrano, P. Simon, C. Sirignano, G. Sirri, A. Spurio Mancini, L. Stanco, J. Steinwagner, A. N. Taylor, I. Tereno, S. Toft, R. Toledo-Moreo, F. Torradeflot, I. Tutusaus, L. Valenziano, J. Valiviita, T. Vassallo, A. Veropalumbo, Y. Wang, J. Weller, G. Zamorani, F. M. Zerbi, E. Zucca, M. Ballardini, E. Bozzo, C. Burigana, R. Cabanac, M. Calabrese, A. Cappi, D. Di Ferdinando, J. A. Escartin Vigo, L. Gabarra, W. G. Hartley, S. Matthew, M. Maturi, N. Mauri, R. B. Metcalf, A. Pezzotta, M. Pöntinen, C. Porciani, I. Risso, V. Scottez, M. Sereno, M. Tenti, M. Viel, M. Wiesmann, Y. Akrami, S. Alvi, I. T. Andika, S. Anselmi, M. Archidiacono, F. Atrio-Barandela, D. Bertacca, M. Bethermin, A. Blanchard, L. Blot, M. Bonici, S. Borgani, M. L. Brown, S. Bruton, A. Calabro, B. Camacho Quevedo, F. Caro, C. S. Carvalho, T. Castro, F. Cogato, S. Conseil, A. R. Cooray, O. Cucciati, S. Davini, G. Desprez, A. Díaz-Sánchez, J. J. Diaz, S. Di Domizio, J. M. Diego, M. Y. Elkhashab, A. Enia, Y. Fang, A. G. Ferrari, A. Finoguenov, A. Fontana, A. Franco, K. Ganga, J. García-Bellido, T. Gasparetto, V. Gautard, R. Gavazzi, E. Gaztanaga, F. Giacomini, F. Gianotti, G. Gozaliasl, M. Guidi, C. M. Gutierrez, A. Hall, S. Hemmati, H. Hildebrandt, J. Hjorth, S. Joudaki, J. J. E. Kajava, Y. Kang, V. Kansal, D. Karagiannis, K. Kiiveri, J. Kim, C. C. Kirkpatrick, S. Kruk, J. Le Graet, L. Legrand, M. Lembo, F. Lepori, G. Leroy, G. F. Lesci, J. Lesgourgues, L. Leuzzi, T. I. Liaudat, J. Macias-Perez, G. Maggio, M. Magliocchetti, F. Mannucci, R. Maoli, C. J. A. P. Martins, L. Maurin, M. Miluzio, P. Monaco, A. Montoro, C. Moretti, G. Morgante, S. Nadathur, K. Naidoo, A. Navarro-Alsina, S. Nesseris, D. Paoletti, F. Passalacqua, K. Paterson, L. Patrizii, A. Pisani, D. Potter, S. Quai, M. Radovich, P. -F. Rocci, G. Rodighiero, S. Sacquegna, M. Sahlén, D. B. Sanders, E. Sarpa, J. Schaye, A. Schneider, M. Schultheis, D. Sciotti, E. Sellentin, L. C. Smith, J. G. Sorce, K. Tanidis, C. Tao, G. Testera, R. Teyssier, S. Tosi, A. Troja, M. Tucci, C. Valieri, A. Venhola, D. Vergani, F. Vernizzi, G. Verza, P. Vielzeuf, N. A. Walton</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A semi-analytic model of galaxy intrinsic alignments, calibrated against multi-survey data within the Euclid Flagship simulation, predicts that this cosmological contaminant will modify Euclid&#39;s tomographic weak lensing two-point statistics by up to $10\%$. (gemini fallback)</p>
                </div>
                <div class="arxiv-abstract-text">Intrinsic alignments of galaxies are potentially a major contaminant of cosmological analyses of weak gravitational lensing. We construct a semi-analytic model of galaxy ellipticities and alignments in the \Euclid Flagship simulation to predict this contamination in Euclid&#39;s weak lensing observations. Galaxy shapes and orientations are determined by the corresponding properties of the host haloes in the underlying $N$-body simulation, as well as the relative positions of galaxies within their halo. Alignment strengths are moderated via stochastic misalignments, separately for central and satellite galaxies and conditional on the galaxy&#39;s redshift, luminosity, and rest-frame colour. The resulting model is calibrated against galaxy ellipticity statistics from the COSMOS Survey, selected alignment measurements based on Sloan Digital Sky Survey samples, and galaxy orientations extracted from the Horizon-AGN hydrodynamic simulation at redshift $z=1$. The best-fit model has a total of 12 alignment parameters and generally reproduces the calibration data sets well within the $1σ$ statistical uncertainties of the observations and the \flagship simulation, with notable exceptions for the most luminous sub-samples on small physical scales. The statistical power of the calibration data and the volume of the single \flagship realisation are still too small to provide informative prior ranges for intrinsic alignment amplitudes in relevant galaxy samples. As a first application, we predict that \Euclid end-of-mission tomographic weak gravitational lensing two-point statistics are modified by up to order $10\,\%$ due to intrinsic alignments.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.07785" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.07785" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.07785" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 14.5</span>
                        <span class="badge bg-info text-dark">Author Score: 0.99</span>
                        <span class="badge bg-primary">Semantic Score: 0.96</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Weak Lensing, Galaxy Clustering, Cosmology</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">2. Euclid preparation. Testing analytic models of galaxy intrinsic alignments in the Euclid Flagship simulation
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">Euclid Collaboration, R. Paviot, B. Joachimi, K. Hoffmann, S. Codis, I. Tutusaus, D. Navarro-Gironés, J. Blazek, F. Hervas-Peters, B. Altieri, et al.</span>
                                <span class="author-full" style="display: none;">Euclid Collaboration, R. Paviot, B. Joachimi, K. Hoffmann, S. Codis, I. Tutusaus, D. Navarro-Gironés, J. Blazek, F. Hervas-Peters, B. Altieri, S. Andreon, N. Auricchio, C. Baccigalupi, M. Baldi, S. Bardelli, A. Biviano, E. Branchini, M. Brescia, S. Camera, G. Cañas-Herrera, V. Capobianco, C. Carbone, V. F. Cardone, J. Carretero, S. Casas, F. J. Castander, M. Castellano, G. Castignani, S. Cavuoti, K. C. Chambers, A. Cimatti, C. Colodro-Conde, G. Congedo, L. Conversi, Y. Copin, F. Courbin, H. M. Courtois, A. Da Silva, H. Degaudenzi, S. de la Torre, G. De Lucia, H. Dole, F. Dubath, C. A. J. Duncan, X. Dupac, S. Dusini, S. Escoffier, M. Farina, R. Farinelli, S. Farrens, S. Ferriol, F. Finelli, P. Fosalba, M. Frailis, E. Franceschi, S. Galeotta, K. George, B. Gillis, C. Giocoli, J. Gracia-Carpio, A. Grazian, F. Grupp, S. V. H. Haugan, H. Hoekstra, W. Holmes, F. Hormuth, A. Hornstrup, K. Jahnke, M. Jhabvala, E. Keihänen, S. Kermiche, A. Kiessling, M. Kilbinger, B. Kubik, M. Kümmel, M. Kunz, H. Kurki-Suonio, A. M. C. Le Brun, S. Ligori, P. B. Lilje, V. Lindholm, I. Lloro, G. Mainetti, D. Maino, E. Maiorano, O. Mansutti, S. Marcin, O. Marggraf, M. Martinelli, N. Martinet, F. Marulli, R. J. Massey, S. Maurogordato, E. Medinaceli, S. Mei, Y. Mellier, M. Meneghetti, E. Merlin, G. Meylan, A. Mora, M. Moresco, L. Moscardini, C. Neissner, S. -M. Niemi, C. Padilla, S. Paltani, F. Pasian, K. Pedersen, V. Pettorino, S. Pires, G. Polenta, M. Poncet, L. A. Popa, L. Pozzetti, F. Raison, R. Rebolo, A. Renzi, J. Rhodes, G. Riccio, E. Romelli, M. Roncarelli, R. Saglia, Z. Sakr, A. G. Sánchez, D. Sapone, B. Sartoris, P. Schneider, T. Schrabback, A. Secroun, E. Sefusatti, G. Seidel, S. Serrano, P. Simon, C. Sirignano, G. Sirri, A. Spurio Mancini, L. Stanco, J. Steinwagner, P. Tallada-Crespí, A. N. Taylor, I. Tereno, N. Tessore, S. Toft, R. Toledo-Moreo, F. Torradeflot, L. Valenziano, J. Valiviita, T. Vassallo, G. Verdoes Kleijn, A. Veropalumbo, Y. Wang, J. Weller, A. Zacchei, G. Zamorani, F. M. Zerbi, E. Zucca, E. Bozzo, C. Burigana, R. Cabanac, M. Calabrese, J. A. Escartin Vigo, L. Gabarra, W. G. Hartley, S. Matthew, M. Maturi, N. Mauri, R. B. Metcalf, A. Pezzotta, M. Pöntinen, C. Porciani, I. Risso, V. Scottez, M. Sereno, M. Tenti, M. Viel, M. Wiesmann, Y. Akrami, I. T. Andika, S. Anselmi, M. Archidiacono, F. Atrio-Barandela, D. Bertacca, M. Bethermin, A. Blanchard, L. Blot, H. Böhringer, M. Bonici, S. Borgani, M. L. Brown, S. Bruton, A. Calabro, B. Camacho Quevedo, F. Caro, C. S. Carvalho, T. Castro, F. Cogato, S. Conseil, A. R. Cooray, O. Cucciati, S. Davini, F. De Paolis, G. Desprez, A. Díaz-Sánchez, J. J. Diaz, S. Di Domizio, J. M. Diego, P. Dimauro, M. Y. Elkhashab, A. Enia, Y. Fang, A. G. Ferrari, A. Finoguenov, A. Fontana, A. Franco, K. Ganga, J. García-Bellido, T. Gasparetto, V. Gautard, R. Gavazzi, E. Gaztanaga, F. Giacomini, F. Gianotti, G. Gozaliasl, M. Guidi, C. M. Gutierrez, A. Hall, S. Hemmati, H. Hildebrandt, J. Hjorth, S. Joudaki, J. J. E. Kajava, Y. Kang, V. Kansal, D. Karagiannis, K. Kiiveri, J. Kim, C. C. Kirkpatrick, S. Kruk, J. Le Graet, L. Legrand, M. Lembo, F. Lepori, G. Leroy, G. F. Lesci, J. Lesgourgues, T. I. Liaudat, A. Loureiro, J. Macias-Perez, G. Maggio, M. Magliocchetti, F. Mannucci, R. Maoli, C. J. A. P. Martins, L. Maurin, M. Miluzio, P. Monaco, C. Moretti, G. Morgante, S. Nadathur, K. Naidoo, P. Natoli, A. Navarro-Alsina, S. Nesseris, L. Pagano, D. Paoletti, F. Passalacqua, K. Paterson, L. Patrizii, A. Pisani, D. Potter, S. Quai, M. Radovich, S. Sacquegna, M. Sahlén, D. B. Sanders, E. Sarpa, A. Schneider, M. Schultheis, D. Sciotti, E. Sellentin, L. C. Smith, J. G. Sorce, K. Tanidis, C. Tao, G. Testera, R. Teyssier, S. Tosi, A. Troja, M. Tucci, C. Valieri, A. Venhola, D. Vergani, F. Vernizzi, G. Verza, P. Vielzeuf, N. A. Walton</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Calibrating intrinsic alignment models (NLA and TATT) within the Euclid Flagship simulation confirms their accuracy down to small scales, but demonstrates that accurately predicting IA contamination for Euclid-like samples above $z=1.1$ necessitates replacing the standard redshift power-law with a luminosity-dependent evolution model. (gemini fallback)</p>
                </div>
                <div class="arxiv-abstract-text">We model intrinsic alignments (IA) in Euclid&#39;s Flagship simulation to investigate its impact on Euclid&#39;s weak lensing signal. Our IA implementation in the Flagship simulation takes into account photometric properties of galaxies as well as their dark matter host halos. We compare simulations against theory predictions, determining the parameters of two of the most widely used IA models: the Non Linear Alignment (NLA) and the Tidal Alignment and Tidal Torquing (TATT) models. We measure the amplitude of the simulated IA signal as a function of galaxy magnitude and colour in the redshift range $0.1&lt;z&lt;2.1$. We find that both NLA and TATT can accurately describe the IA signal in the simulation down to scales of $6$-$7 \,h^{-1}\,$Mpc. We measure alignment amplitudes for red galaxies comparable to those of the observations, with samples not used in the calibration procedure. For blue galaxies, our constraints are consistent with zero alignments in our first redshift bin $0.1 &lt; z &lt; 0.3$, but we detect a non-negligible signal at higher redshift, which is, however, consistent with the upper limits set by observational constraints. Additionally, several hydrodynamical simulations predict alignment for spiral galaxies, in agreement with our findings. Finally, the evolution of alignment with redshift is realistic and comparable to that determined in the observations. However, we find that the commonly adopted redshift power-law for IA fails to reproduce the simulation alignments above $z=1.1$. A significantly better agreement is obtained when a luminosity dependence is included, capturing the intrinsic luminosity evolution with redshift in magnitude-limited surveys. We conclude that the Flagship IA simulation is a useful tool for translating current IA constraints into predictions for IA contamination of Euclid-like samples.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.07784" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.07784" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.07784" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 14.5</span>
                        <span class="badge bg-info text-dark">Author Score: 0.99</span>
                        <span class="badge bg-primary">Semantic Score: 0.95</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Weak Lensing, Galaxy Clustering, Cosmology / Weak Lensing, Galaxy Clustering, Halo Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">3. Testing subhalo abundance matching with galaxy kinematics
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Fedir Boreiko, Tariq Yasin, Harry Desmond, Richard Stiskalek, Matt J. Jarvis</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Applying a Bayesian forward model to SPARC galaxy kinematics demonstrates that reconciling observed rotation velocities with $\Lambda$CDM requires either strong halo expansion inconsistent with clustering data, or an extreme selection effect favoring the lowest velocity-maximum halos. (gemini fallback)</p>
                </div>
                <div class="arxiv-abstract-text">The rotation velocities of disc galaxies trace dark matter halo structure, providing direct constraints on the galaxy--halo connection. We construct a Bayesian forward model to connect the dark matter halo population predicted by $Λ$CDM with an observed sample of disc galaxies (SPARC) through their maximum rotation velocities. Our approach combines a subhalo abundance matching scheme (accounting for assembly bias) with a parameterised halo response to galaxy formation. When assuming no correlation between selection in the SPARC survey and halo properties, reproducing the observed velocities requires strong halo expansion, low abundance matching scatter ($&lt;0.15$ dex at $1σ$) and a halo proxy that strongly suppresses the stellar masses in satellite haloes. This is in clear tension with independent clustering constraints. Allowing for SPARC-like galaxies to preferentially populate low $\Vmax$ haloes at fixed virial mass greatly improves the goodness-of-fit and resolves these tensions: the preferred halo response shifts to mild contraction, the abundance matching scatter increases to $\sint = 0.19^{+0.13}_{-0.11}$ dex and the proxy becomes consistent with clustering. However, the inferred selection threshold is extreme, implying that SPARC galaxies occupy the lowest ${\sim}16$ per cent of the $\Vmaxhalo$ distribution at fixed $\Mvir$. Moreover, even with selection, the inferred scatter remains in statistical disagreement with the low-mass clustering constraints, which are most representative of the SPARC galaxies in our sample. Our analysis highlights the advantage of augmenting clustering-based constraints on the galaxy--halo connection with kinematics and suggests a possible tension using current data.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.07799" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.07799" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.07799" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.5</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.95</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Weak Lensing, Galaxy Clustering, Cosmology / Weak Lensing, Galaxy Clustering, Halo Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">4. Cosmological back-reaction of baryons on dark matter in the CAMELS simulations
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">Matthew Gebhardt, Daniel Anglés-Alcázar, Shy Genel, Daisuke Nagai, Boon Kiat Oh, Isabel Medlock, Jonathan Mercedes-Feliz, Sagan Sutherland, Max E. Lee, Xavier Sims, et al.</span>
                                <span class="author-full" style="display: none;">Matthew Gebhardt, Daniel Anglés-Alcázar, Shy Genel, Daisuke Nagai, Boon Kiat Oh, Isabel Medlock, Jonathan Mercedes-Feliz, Sagan Sutherland, Max E. Lee, Xavier Sims, Christopher C. Lovell, David N. Spergel, Romeel Davé, Matthieu Schaller, Joop Schaye, Francisco Villaescusa-Navarro</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Baryonic processes, including radiative cooling and stellar/AGN feedback, profoundly reshape dark matter structure, leading to decreased halo virial masses, significant central density increases (up to 450% in some models), and strong modulation (up to 20%) of small-scale clustering, emphasizing the necessity of accounting for feedback implementation details when extracting cosmological parameters. (gemini fallback)</p>
                </div>
                <div class="arxiv-abstract-text">Baryonic processes such as radiative cooling and feedback from massive stars and active galactic nuclei (AGN) directly redistribute baryons in the Universe but also indirectly redistribute dark matter due to changes in the gravitational potential. In this work, we investigate this &#34;back-reaction&#34; of baryons on dark matter using thousands of cosmological hydrodynamic simulations from the Cosmology and Astrophysics with MachinE Learning Simulations (CAMELS) project, including parameter variations in the SIMBA, IllustrisTNG, ASTRID, and Swift-EAGLE galaxy formation models. Matching haloes to corresponding N-body (dark matter-only) simulations, we find that virial masses decrease owing to the ejection of baryons by feedback. Relative to N-body simulations, halo profiles show an increased dark matter density in the center (due to radiative cooling) and a decrease in density farther out (due to feedback), with both effects being strongest in SIMBA (&gt; 450% increase at r &lt; 0.01 Rvir). The clustering of dark matter strongly responds to changes in baryonic physics, with dark matter power spectra in some simulations from each model showing as much as 20% suppression or increase in power at k ~ 10 h/Mpc relative to N-body simulations. We find that the dark matter back-reaction depends intrinsically on cosmology (Omega_m and sigma_8) at fixed baryonic physics, and varies strongly with the details of the feedback implementation. These results emphasize the need for marginalizing over uncertainties in baryonic physics to extract cosmological information from weak lensing surveys as well as their potential to constrain feedback models in galaxy evolution.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.06258" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.06258" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.06258" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.05</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">5. Photometric Redshift Estimation Using Scaled Ensemble Learning
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Swagata Biswas, Shubhrangshu Ghosh, Avyarthana Ghosh, Yogesh Wadadekar, Abhishek Roy Choudhury, Arijit Mukherjee, Shailesh Deshpande, Arpan Pal</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A new scaled ensemble machine learning framework, integrating multiple learning algorithms with bagged optical photometric data, significantly enhances the precision and reliability of photometric redshift estimation for faint galaxies up to $z \sim 4$, successfully meeting or exceeding LSST performance benchmarks. (gemini fallback)</p>
                </div>
                <div class="arxiv-abstract-text">The development of the state-of-the-art telescopic systems capable of performing expansive sky surveys such as the Sloan Digital Sky Survey, Euclid, and the Rubin Observatory&#39;s Legacy Survey of Space and Time (LSST) has significantly advanced efforts to refine cosmological models. These advances offer deeper insight into persistent challenges in astrophysics and our understanding of the Universe&#39;s evolution. A critical component of this progress is the reliable estimation of photometric redshifts (Pz). To improve the precision and efficiency of such estimations, the application of machine learning (ML) techniques to large-scale astronomical datasets has become essential. This study presents a new ensemble-based ML framework aimed at predicting Pz for faint galaxies and higher redshift ranges, relying solely on optical (grizy) photometric data. The proposed architecture integrates several learning algorithms, including gradient boosting machine, extreme gradient boosting, k-nearest neighbors, and artificial neural networks, within a scaled ensemble structure. By using bagged input data, the ensemble approach delivers improved predictive performance compared to stand-alone models. The framework demonstrates consistent accuracy in estimating redshifts, maintaining strong performance up to z ~ 4. The model is validated using publicly available data from the Hyper Suprime-Cam Strategic Survey Program by the Subaru Telescope. Our results show marked improvements in the precision and reliability of Pz estimation. Furthermore, this approach closely adheres to-and in certain instances exceeds-the benchmarks specified in the LSST Science Requirements Document. Evaluation metrics include catastrophic outlier, bias, and rms.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.07292" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.07292" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.07292" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">6. Towards Infinite Length Extrapolation: A Unified Approach
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Nitin Vetcha</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Leveraging a unified framework that decomposes attention scores, Adaptive Positional Encoding (APE) introduces adaptive frequency modulation and a multi-term decay bias to achieve theoretically established, infinite-context extrapolation for large language models, demonstrated effectively on sequences reaching 32,000 words. (gemini fallback)</p>
                </div>
                <div class="arxiv-abstract-text">Large language models (LLMs) have revolutionized natural language processing, but their ability to process long sequences is fundamentally limited by the context window size during training. Existing length extrapolation methods often suffer from performance degradation or computational inefficiencies. We thereby use a unified framework that reinterprets positional encoding methods as a decomposition of the attention score into a multiplicative transformation and an additive bias. This perspective not only subsumes popular approaches such as relative position embeddings and attention-bias moderated approaches but also exposes their inherent limitations in handling long-range dependencies. To address these shortcomings, motivated by our framework, we introduce Adaptive Positional Encoding (APE), which leverages adaptive frequency modulation and an intricately designed decay bias that incorporates linear, logarithmic, and square-root terms. Our theoretical analysis establishes conditions for infinite-context extrapolation, ensuring that the softmax normalization remains well-defined over unbounded sequences while preserving long-distance correlations, entropy boundedness and gradient positional sensitivity. We substantiate our claims with an experimental case study on TinyStories dataset as well as a new synthetic dataset, \emph{Long Tiny Stories} featuring stories up to 32,000 words. Relevant code, dataset and model weights are available at https://anonymous.4open.science/r/Check-2DAD/.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.06113" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.06113" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.06113" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics / Advanced Architectures, Representation Learning, Probabilistic Modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">7. Position: Don&#39;t be Afraid of Over-Smoothing And Over-Squashing
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Niklas Kormann, Benjamin Doerr, Johannes F. Lutzeyer</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Instead, we posit that the distribution of relevant information over the graph frequently factorises and is often localised within a small k-hop neighbourhood, questioning the necessity of jointly observing entire receptive fields or engaging in an extensive search for long-range interactions. (sumy fallback)</p>
                </div>
                <div class="arxiv-abstract-text">Over-smoothing and over-squashing have been extensively studied in the literature on Graph Neural Networks (GNNs) over the past years. We challenge this prevailing focus in GNN research, arguing that these phenomena are less critical for practical applications than assumed. We suggest that performance decreases often stem from uninformative receptive fields rather than over-smoothing. We support this position with extensive experiments on several standard benchmark datasets, demonstrating that accuracy and over-smoothing are mostly uncorrelated and that optimal model depths remain small even with mitigation techniques, thus highlighting the negligible role of over-smoothing. Similarly, we challenge that over-squashing is always detrimental in practical applications. Instead, we posit that the distribution of relevant information over the graph frequently factorises and is often localised within a small k-hop neighbourhood, questioning the necessity of jointly observing entire receptive fields or engaging in an extensive search for long-range interactions. The results of our experiments show that architectural interventions designed to mitigate over-squashing fail to yield significant performance gains. This position paper advocates for a paradigm shift in theoretical research, urging a diligent analysis of learning tasks and datasets using statistics that measure the underlying distribution of label-relevant information to better understand their localisation and factorisation.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.07419" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.07419" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.07419" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">stat.ML</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics / Advanced Architectures, Representation Learning, Probabilistic Modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">8. Circuit Mechanisms for Spatial Relation Generation in Diffusion Transformers
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Binxu Wang, Jingxuan Fan, Xu Pan</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> We further show that, although the in-domain performance is similar for the two settings, their robustness to out-of-domain perturbations differs, potentially suggesting the difficulty of generating correct relations in real-world scenarios. (sumy fallback)</p>
                </div>
                <div class="arxiv-abstract-text">Diffusion Transformers (DiTs) have greatly advanced text-to-image generation, but models still struggle to generate the correct spatial relations between objects as specified in the text prompt. In this study, we adopt a mechanistic interpretability approach to investigate how a DiT can generate correct spatial relations between objects. We train, from scratch, DiTs of different sizes with different text encoders to learn to generate images containing two objects whose attributes and spatial relations are specified in the text prompt. We find that, although all the models can learn this task to near-perfect accuracy, the underlying mechanisms differ drastically depending on the choice of text encoder. When using random text embeddings, we find that the spatial-relation information is passed to image tokens through a two-stage circuit, involving two cross-attention heads that separately read the spatial relation and single-object attributes in the text prompt. When using a pretrained text encoder (T5), we find that the DiT uses a different circuit that leverages information fusion in the text tokens, reading spatial-relation and single-object information together from a single text token. We further show that, although the in-domain performance is similar for the two settings, their robustness to out-of-domain perturbations differs, potentially suggesting the difficulty of generating correct relations in real-world scenarios.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.06338" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.06338" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.06338" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics / Advanced Architectures, Representation Learning, Probabilistic Modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">9. Popcorn in the sky: Identifying primordial black holes in the gravitational-wave background
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Eleni Bagui, Sébastien Clesse, Federico De Lillo, Alexander C. Jenkins, Mairi Sakellariadou</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> We identify the dependence of the duty cycle on the signal frequency, duration and amplitude as a crucial metric for distinguishing PBHs from other sources in the GWB and constraining PBH models. (sumy fallback)</p>
                </div>
                <div class="arxiv-abstract-text">Primordial black holes (PBHs) are possible sources of a gravitational-wave background (GWB), detectable with the next observing runs of LIGO--Virgo--KAGRA. In case of a detection, it will be crucial to distinguish the possible sources of this GWB. One under-explored possibility is to exploit the duty cycle that quantifies the number of sources present in the time domain signal, which can be very different depending on the nature and population of the sources. We compute the duty cycle for a realistic population of PBH binaries, isolating the shot-noise, popcorn and continuous contributions to the GWB. We identify the dependence of the duty cycle on the signal frequency, duration and amplitude as a crucial metric for distinguishing PBHs from other sources in the GWB and constraining PBH models. Our work motivates the development of specific analysis tools to extract these observables, in order to unlock new cosmological insights with upcoming GW data.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.07774" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.07774" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.07774" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">10. The Impact of Anisotropic Covariance Structure on the Training Dynamics and Generalization Error of Linear Networks
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Taishi Watanabe, Ryo Karakida, Jun-nosuke Teramae</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The generalization error and learning trajectory of a two-layer linear network are fundamentally shaped by data anisotropy, exhibiting two distinct learning phases governed sequentially by input-output correlation and principal data directions, with performance improving when the spiked covariance structure aligns with the learning task. (gemini fallback)</p>
                </div>
                <div class="arxiv-abstract-text">The success of deep neural networks largely depends on the statistical structure of the training data. While learning dynamics and generalization on isotropic data are well-established, the impact of pronounced anisotropy on these crucial aspects is not yet fully understood. We examine the impact of data anisotropy, represented by a spiked covariance structure, a canonical yet tractable model, on the learning dynamics and generalization error of a two-layer linear network in a linear regression setting. Our analysis reveals that the learning dynamics proceed in two distinct phases, governed initially by the input-output correlation and subsequently by other principal directions of the data structure. Furthermore, we derive an analytical expression for the generalization error, quantifying how the alignment of the spike structure of the data with the learning task improves performance. Our findings offer deep theoretical insights into how data anisotropy shapes the learning trajectory and final performance, providing a foundation for understanding complex interactions in more advanced network architectures.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.06961" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.06961" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.06961" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">stat.ML</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics / Advanced Architectures, Representation Learning, Probabilistic Modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">11. More power on large scales
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Jeremy Mould</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Modeling primordial black holes as dark matter shows that their early clustering generates larger galaxy bulk flow velocities than standard $\Lambda$CDM, while their mass loss through Hawking radiation introduces a time-varying matter density that effectively reduces the Hubble tension. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The high value of the cosmic microwave dipole may be telling us that dark matter is macroscopic rather than a fundamental particle. The possible presence of a significant dark matter component in the form of primordial black holes suggests that dark halo formation simulations should be commenced well before redshift z = 100. Unlike standard CDM candidates, PBHs behave as dense, non-relativistic matter from their inception in the radiation-dominated era. This allows them to seed gravitational potential wells and begin clustering earlier. We find that starting N-body simulations at redshifts even before matter-radiation equality yield galaxy bulk flow velocities that are systematically larger than those predicted by standard LCDM models. The early, high-mass concentrations established by PBHs lead to a more rapid and efficient gravitational acceleration of surrounding baryonic and dark matter, generating larger peculiar velocities that remain coherent over scales of hundreds of Mpc. Furthermore, a sub-population of PBHs in the 10^-20 to 10^-17 solar mass range would lose a non-negligible fraction of their mass via Hawking radiation over cosmological timescales. This evaporation process converts matter into radiation, so a time-varying matter density parameter, Omega_m&#39;, is introduced, which behaves like a boosted radiation term in the Friedmann equation. This dynamic term acts to reduce the Hubble tension. A higher effective Omega_r in the early universe reduces the sound horizon at the epoch of recombination. PBH mass loss also influences fits to the equation of state parameter, w, at low redshift. The naive N-body modelling presented here suggests investigation with tried and tested cosmology codes should be carried out, by introducing mass losing PBHs and starting the evolution as early as practicable.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.07106" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.07106" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.07106" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Weak Lensing, Galaxy Clustering, Cosmology / Weak Lensing, Galaxy Clustering, Halo Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">12. Constraining Inflation Models with Spinning Voids
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Geonwoo Kang, Jounghun Lee</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Coherent rotation and redshift asymmetry observed in void galaxies provide a powerful, non-parametric diagnostic tool capable of independently constraining the running of the scalar spectral index, revealing a breakdown in cosmological model universality when this running deviates from zero. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We present a powerful new diagnostics by which the running of scalar spectral index of primordial density fluctuations can be tightly and independently constrained. This new diagnostics utilizes coherent rotation of void galaxies, which can be observed as redshift asymmetry in opposite sides dichotomized by the projected spin axes of hosting voids. Comparing the numerical results from the AbacusSummit of cosmological simulations, we derive a non-parametric model for the redshift asymmetry distribution of void galaxies, which turns out to be almost universally valid for a very broad range of cosmologies including dynamic dark energy models with time-dependent equation of states as well as the $Λ$CDM models with various initial conditions. We discover that the universality of this model breaks down only if the running of scalar spectral index deviates from zero, detecting a consistent trend that a more positive (negative) running yields a lower (higher) redshift asymmetry of voids than the model predictions. Given that non-standard inflations usually predict non-zero runnings of the spectral index and that the redshift asymmetry distribution of voids is a readily observable quantity, we conclude that this new diagnostics will pave another path toward understanding the true mechanism of inflation.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.06589" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.06589" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.06589" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">13. Cosmological Dynamics on a Novel $f(Q)$ Gravity Model with Recent DESI DR2 Observation
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>S. A. Kadam, D. Revanth Kumar, Santosh Kumar Yadav</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Observational constraints derived from combined cosmological datasets validate a modified symmetric teleparallel $f(Q)$ gravity model, confirming its transition from cosmic deceleration to late-time acceleration at $z_{tr} = 0.573$ and supporting a quintessence equation of state. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">In this article, we investigate the cosmological viability of a modified symmetric teleparallel gravity model within the $f(Q)$ framework. We derive observational constraints on the model parameters by performing a Markov Chain Monte Carlo analysis using a combined dataset consisting of cosmic chronometers, PantheonPlus SH0ES, and DESI BAO DR2. Our analysis yields the best-fit values for the model parameters $m=-0.386 \pm 0.090$ and $n=-1.055 \pm 0.047$, along with the cosmological parameters at present: $H_0 = 73.19 \pm 0.25$, $q_0 = -0.51 \pm 0.6$, and $ω_{0} = -0.73 \pm 0.3$, at 68\% CL. Furthermore, we examine the physical behavior of the model, focusing on the effective equation of state and deceleration parameter. Our findings indicate that the model experiences a transition from the early deceleration phase to the late-time cosmic acceleration, and the transition occurs at a redshift $z_{tr} = 0.573$. We also analyse the $om(z)$ diagnostic, which reflects a positive slope, supporting the behavior of the equation of state parameter in the quintessence region.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.06438" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.06438" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.06438" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">gr-qc</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">14. Characterizing turbulence in galaxy clusters: defining turbulent energies and assessing multi-scale versus fixed-scale filters
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Lorenzo Maria Perrone, Thomas Berlok, Ewald Puchwein, Christoph Pfrommer</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Applying GPU-accelerated real-space filtering to a simulated galaxy cluster merger successfully separates bulk motion from turbulence in the intracluster medium, demonstrating that the turbulent pressure fraction peaks briefly at 5% during core passage before settling to low levels consistent with XRISM observations. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Disentangling turbulence and bulk motions in the intracluster medium (ICM) of galaxy clusters is inherently ambiguous, as the plasma is continuously stirred by different processes on disparate scales. This poses a serious problem in the interpretation of both observations and numerical simulations. In this paper, we use filtering operators in real space to separate bulk motion from turbulence at different scales. We show how filters can be used to define consistent kinetic and magnetic energies for the bulk and turbulent component. We apply our GPU-accelerated filtering pipeline to a simulation of a major galaxy cluster merger, which is part of the PICO-Clusters suite of zoom-in cosmological simulations of massive clusters using the moving mesh code Arepo and the IllustrisTNG galaxy formation model. We find that during the merger the turbulent pressure fraction on physical scales $\lesssim$160 kpc reaches a maximum of 5%, before decreasing to 2% after $\sim$1.3 Gyr from the core passage. These low values are consistent with recent observations of clusters with XRISM, and suggest that unless a cluster was recently perturbed by a major merger, turbulence levels are low. We then re-examine the popular multiscale iterative filter method. In our tests, we find that its use can introduce artifacts, and that it does not reliably disentangle fluctuations living on widely separated length scales. Rather, we believe it is more fruitful to use fixed-scale filters and turbulent energies to compare between simulations and observations. This work significantly improves our understanding of turbulence generation by major mergers in galaxy clusters, which can be probed by XRISM and next-generation X-ray telescopes, allowing us to connect high-resolution cosmological simulations to observations.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.06250" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.06250" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.06250" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.01</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">15. Joint Optical-HI mock catalogs and prospects for upcoming HI surveys
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Sauraj Bharti, Jasjeet Singh Bagla</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A novel approach generates optical-HI joint mock catalogs for upcoming MeerKAT and ASKAP surveys, providing a powerful predictive benchmark for HI science and demonstrating that combining stacking and direct detections significantly tightens constraints on the HI mass function, especially at high redshift limits. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Atomic hydrogen (HI) regulates star formation as cold gas fuels star formation. It represents a key phase of matter in the baryon cycle involving accretion, feedback, outflows, and gas recycling. Redshifted $21$ cm line emission originating from galaxies serves as a key tracer for investigating HI gas and its dynamics in the interstellar medium (ISM) and circumgalactic medium (CGM), and enables the study of galaxy evolution. Nonetheless, direct detections of HI are currently limited to $z \leq 0.4$ due to the inherently weak $21$ cm emission line. Ongoing and upcoming large radio surveys aim to detect $21$ cm emission from galaxies up to $z \gtrsim 1$ with unprecedented sensitivity. In current work, we present a novel approach for creating optical-HI joint mock catalogs for upcoming SKA precursor surveys: MIGHTEE-HI and LADUMA with MeerKAT and WALLABY with ASKAP. Incorporation of optical properties along with HI in our mock catalogs makes these a powerful tool for making predictions for upcoming surveys and provides a benchmark for exploring the HI science (e.g., conditional HIMF and optical-to-HI scaling relations) expected from these surveys. As a case study, we show the use of the joint catalogs for predicting the expected outcome of stacking detection for average HI mass in galaxies that are below the threshold for direct detection. We show that combining stacking observations with the number of direct detections puts a strong constraint on the HI mass function, especially in the regime where the number of direct detections is small, as often happens near the farther edge of HI surveys. This intermediate step may be used to set priors for the full determination of the HI mass function.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.06815" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.06815" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.06815" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">16. Emulator-Based Inference of Cosmological Subgrid Models
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Nesar Ramachandra, Nicholas Frontiere, Michael Buehlmann, Kelly R. Moran, J. D. Emberson, Katrin Heitmann, Salman Habib</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> An inference framework employing high-fidelity emulators trained on large-scale cosmological hydrodynamics simulations (HACC) successfully calibrates baryonic physics models, identifying two distinct AGN kinetic feedback modes that optimize either the radial gas density profiles or the cluster gas fraction data. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The formation of structure in the Universe at large scales is dominated by gravity, with baryonic physics becoming significant at $\sim{\rm Mpc}$ scales. To capture the impact of baryonic physics, cosmological simulations must model gas dynamics and a host of relevant astrophysical processes. A recent extension of the Hardware/Hybrid Accelerated Cosmology Code (HACC) couples its gravity solver with a modern smoothed particle hydrodynamics method. This extension incorporates sub-resolution models for chemical enrichment, black hole and star formation, AGN kinetic and thermal feedback, supernova-driven feedback, galactic winds, and metal-line cooling. We present an inference framework based on high-fidelity emulators to aid in model calibration against observational targets, e.g., the galaxy stellar mass function, radial gas density profiles, and the cluster gas fraction. The emulators are trained on simulation suites comprising 64 boxes with side-length $128\,h^{-1}$Mpc and 16 boxes with side-length $256\,h^{-1}$Mpc with $2\times 512^3$ and $2\times 1024^3$ particles, respectively. Our analysis reveals two distinct AGN kinetic feedback modes -- a low-feedback mode yielding strong agreement with the observed radial gas density profiles of massive X-ray clusters, and a high-feedback mode providing a better fit to cluster gas fraction data, but systematically underestimating gas densities in inner regions.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.07306" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.07306" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.07306" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.01</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">17. Impact of a negative cosmological constant on the reconstruction of dark energy in light of DESI BAO data
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Hao Wang, Yun-Song Piao</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Reconstructions of the evolving dark energy equation of state $w(z)$ suggest a slight preference for a coexisting negative cosmological constant (NCC), which, while weakening constraints on $w(z)$, increases the consistency of the phantom divide $w=-1$ with the posterior distribution. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">An anti-de Sitter vacuum, corresponding to a negative cosmological constant (NCC), might coexist with one evolving positive dark energy component at low redshift and is hinted by the latest DESI observations. In this paper, we use two methods, \textit{redshift-binned} and \textit{Gaussian Process-based} reconstructions to investigate the effect of a NCC on the equation of state (EOS) $w(z)$ of evolving dark energy (DE) component. We find that a NCC is slightly preferred in both the two reconstructions by up to $\simeq1σ$. Although the degeneracy between the EOS of evolving DE component and NCC weakens the constraint on the reconstructed $w(z)$, this degeneracy leads to the phantom divide $w=-1$ more consistent with the 1$σ$ posterior of $w(z)$.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.06656" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.06656" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.06656" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">18. Exoplanet transit search at the detection limit: detection and false alarm vetting pipeline
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Jakob Robnik, Uroš Seljak, Jon M. Jenkins, Steve Bryson</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A novel Kepler planet detection pipeline improves completeness by enhancing defect removal and vetting using a Bayes factor test statistic, but it flags several previously identified Earth-like habitable zone candidates as false alarms, potentially altering estimates of $\eta_{\oplus}$. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">One of the primary mission goals of the Kepler space telescope was to detect Earth-like terrestrial planets in the habitable zone around Sun-like stars. These planets are at the detection limit, where the Kepler detection and vetting pipeline produced unreliable planet candidates. We present a novel pipeline that improves the removal of localized defects prior to the planet search, improves vetting at the level of individual transits and introduces a Bayes factor test statistic and an algorithm for extracting multiple candidates from a single detection run. We show with injections in the Kepler data that the introduced novelties improve pipeline&#39;s completeness at a fixed false alarm rate. We apply the pipeline to the stars with previously identified planet candidates and show that our pipeline successfully recovers the previously confirmed candidates, but flags a considerable portion of unconfirmed candidates as likely false alarms, especially in the long period, low signal-to-noise ratio regime. In particular, several known Earth-like candidates in the habitable zone, such as KOI 8063.01, 8107.01 and 8242.01, are identified as false alarms, which could have a significant impact on the estimates of $η_{\oplus}$, i.e., the occurrence of Earth-like planets in the habitable zone.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.07465" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.07465" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.07465" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.08</span>
                        <span class="badge bg-primary">Semantic Score: 0.89</span>
                        
                            <span class="badge bg-secondary">astro-ph.EP</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">19. Inference-Time Alignment for Diffusion Models via Doob&#39;s Matching
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Jinyuan Chang, Chenguang Duan, Yuling Jiao, Yi Xu, Jerry Zhijian Yang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Doob&#39;s matching provides a novel framework for inference-time alignment in diffusion models by formulating guidance as the gradient of a Doob&#39;s $h$-function logarithm, using gradient-penalized regression for consistent estimation and establishing non-asymptotic convergence guarantees for the generated distributions. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Inference-time alignment for diffusion models aims to adapt a pre-trained diffusion model toward a target distribution without retraining the base score network, thereby preserving the generative capacity of the base model while enforcing desired properties at the inference time. A central mechanism for achieving such alignment is guidance, which modifies the sampling dynamics through an additional drift term. In this work, we introduce Doob&#39;s matching, a novel framework for guidance estimation grounded in Doob&#39;s $h$-transform. Our approach formulates guidance as the gradient of logarithm of an underlying Doob&#39;s $h$-function and employs gradient-penalized regression to simultaneously estimate both the $h$-function and its gradient, resulting in a consistent estimator of the guidance. Theoretically, we establish non-asymptotic convergence rates for the estimated guidance. Moreover, we analyze the resulting controllable diffusion processes and prove non-asymptotic convergence guarantees for the generated distributions in the 2-Wasserstein distance.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.06514" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.06514" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.06514" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">stat.ML</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics / Advanced Architectures, Representation Learning, Probabilistic Modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">20. Cosmoglobe DR2. IV. Modelling starlight in DIRBE with Gaia and WISE
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">M. Galloway, E. Gjerløw, M. San, R. M. Sullivan, D. J. Watts, R. Aurvik, A. Basyrov, L. A. Bianchi, A. Bonato, M. Brilenkov, et al.</span>
                                <span class="author-full" style="display: none;">M. Galloway, E. Gjerløw, M. San, R. M. Sullivan, D. J. Watts, R. Aurvik, A. Basyrov, L. A. Bianchi, A. Bonato, M. Brilenkov, H. K. Eriksen, U. Fuskeland, K. A. Glasscock, L. T. Hergt, D. Herman, J. G. S. Lunde, A. I. Silva Martins, D. Sponseller, N. -O. Stutzer, H. Thommesen, V. Vikenes, I. K. Wehus, L. Zapelli</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A new starlight emission model for DIRBE data, integrating Gaia and WISE measurements for both bright and faint sources, accurately accounts for 91% of the observed flux density at 2.2 $\mu$m, significantly improving the precision of Cosmic Infrared Background and zodiacal light measurements at higher frequencies. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We present a model of starlight emission in the Diffuse Infrared Background Explorer (DIRBE) data between 1.25 and 25$\,μ$m based on \textit{Gaia} and WISE measurements. We include two classes of compact objects, namely bright stars with individual spectral energy densities (SEDs) measured by \textit{Gaia}, and a combined diffuse background of dim point source emission. Of the 424\ 829 bright sources that we fit, the number of stars with a flux density detected by WISE at Galactic latitudes $|b|&gt;20^{\circ}$ at more than $5\,σ$ is 94\,680, for an average of 1.36~stars per DIRBE beam area. For each star, we adopt physical parameters ($T_{\mathrm{eff}}$, $\log g$, and [M/H]) from \textit{Gaia}; use these to identify a best-fit effective SED with the PHOENIX stellar model library; convolve with the respective DIRBE bandpass; and fit an overall free amplitude per star within the Bayesian end-to-end \texttt{Cosmoglobe} DR2 framework. The contributions from faint sources are accounted for by coadding all 710\ 825\ 587 WISE sources not included as bright stars, and fit one single overall amplitude per DIRBE band. Based on this model we find that total star emission accounts for 91\,\% of the observed flux density at 2.2\,$μ$m; 54\,\% at 4.9$\,μ$m; and 1\,\% at 25\,$μ$m. As shown in companion papers, this new model is sufficiently accurate to support high-precision measurements of both the Cosmic Infrared Background monopole and zodiacal light emission in the three highest DIRBE frequencies.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.07831" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.07831" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.07831" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Weak Lensing, Galaxy Clustering, Cosmology / Weak Lensing, Galaxy Clustering, Halo Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">21. Tachyonic gravitational dark matter production after inflation
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Giorgio Laverda, Tomás Mendes, Javier Rubio</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A novel gravitational mechanism utilizing curvature-induced tachyonic instabilities in a scalar field coupled to spacetime invariants after inflation robustly reproduces the observed dark matter relic density across a wide parameter range. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We propose a novel gravitational mechanism for the non-thermal production of dark matter driven by curvature-induced tachyonic instabilities after inflation. Departing from the commonly studied non-minimal couplings to gravity, our framework considers a real spectator scalar field coupled quadratically to spacetime curvature invariants. We show that the rapid reorganization of spacetime curvature at the end of inflation can dynamically render the dark matter field tachyonic, triggering a short-lived phase of spontaneous symmetry breaking and explosive particle production. As a concrete and theoretically controlled example, we focus on the Gauss-Bonnet topological invariant. By combining analytical estimates with fully non-linear $3+1$ classical lattice simulations, we track the out-of-equilibrium evolution of the system and compute the resulting dark matter abundance. We find that this purely gravitational mechanism can robustly reproduce the observed dark matter relic density over a wide range of masses and inflationary scales, providing also a simple fitting function that enables a lattice-independent application of our results.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.07670" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.07670" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.07670" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">22. ARM: Role-Conditioned Neuron Transplantation for Training-Free Generalist LLM Agent Merging
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Zhuoka Feng, Kang Chen, Sihan Zhao, Kai Xiong, Yaoning Wang, Minshen Yu, Junjie Nian, Changyi Xiao, Yixin Cao, Yugang Jiang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Agent-Role Merging (ARM), an activation-guided neuron transplantation technique, effectively integrates specialized LLM agents into a single model, achieving superior cross-benchmark generalization across diverse interactive environments compared to prior merging methods. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Interactive large language model agents have advanced rapidly, but most remain specialized to a single environment and fail to adapt robustly to other environments. Model merging offers a training-free alternative by integrating multiple experts into a single model. In this paper, we propose Agent-Role Merging (ARM), an activation-guided, role-conditioned neuron transplantation method for model merging in LLM agents. ARM improves existing merging methods from static natural language tasks to multi-turn agent scenarios, and over the generalization ability across various interactive environments. This is achieved with a well designed 3-step framework: 1) constructing merged backbones, 2) selection based on its role-conditioned activation analysis, and 3) neuron transplantation for fine-grained refinements. Without gradient-based optimization, ARM improves cross-benchmark generalization while enjoying efficiency. Across diverse domains, the model obtained via ARM merging outperforms prior model merging methods and domain-specific expert models, while demonstrating strong out-of-domain generalization.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.07309" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.07309" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.07309" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics / Advanced Architectures, Representation Learning, Probabilistic Modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">23. Systematic Biases in Gravitational-Wave Parameter Estimation from Neglecting Orbital Eccentricity in Space-Based Detectors
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Jin-Zhao Yang, Jia-Hao Zhong, Tao Yang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Neglecting orbital eccentricity in quasi-circular waveform templates induces significant systematic biases in compact-binary parameter estimation for future space-based detectors, requiring the inclusion of eccentricity for accurate inference, especially for B-DECIGO where biases arise at eccentricities as low as $10^{-4}$. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Accurate modeling of gravitational-wave signals is essential for reliable inference of compact-binary source parameters, particularly for future space-based detectors operating in the milli- and deci-Hertz bands. In this work, we systematically investigate the parameter-estimation biases induced by neglecting orbital eccentricity when analyzing eccentric compact-binary coalescences with quasi-circular waveform templates. Focusing on the deci-Hertz detector B-DECIGO and the milli-Hertz detector LISA, we model eccentric inspiral signals using a frequency-domain waveform that incorporates eccentricity-induced higher harmonics and the time-dependent response of spaceborne detectors. We quantify systematic biases in the chirp mass, symmetric mass ratio, and luminosity distance using both Bayesian inference and the Fisher-Cutler-Vallisneri (FCV) formalism, and assess their significance relative to statistical uncertainties. By constructing mock gravitational-wave catalogs spanning stellar-mass and massive black-hole binaries, we identify critical initial eccentricities at which systematic errors become comparable to statistical errors. We find that for B-DECIGO, even very small eccentricities, $e_0\sim 10^{-4}-10^{-3}$ at 0.1 Hz, can lead to significant biases, whereas for LISA such effects typically arise at larger eccentricities, $e_0\sim 10^{-2}-10^{-1}$ at $10^{-4}$ Hz, due to the smaller number of in-band cycles. Comparisons between FCV predictions and full Bayesian analyses demonstrate good agreement within the regime where waveform mismatches remain small, especially when extrinsic parameters are pre-aligned to minimize mismatches. Our results highlight the necessity of incorporating eccentricity in waveform models for future space-based gravitational-wave observations.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.07739" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.07739" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.07739" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">gr-qc</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">24. Local EGOP for Continuous Index Learning
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Alex Kokot, Anand Hemmady, Vydhourie Thiyageswaran, Marina Meila</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Local EGOP learning is introduced as a recursive algorithm for continuous index learning that adapts kernels along noisy manifolds, achieving intrinsic dimensional learning rates by utilizing the Expected Gradient Outer Product (EGOP) to capture local function variability. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We introduce the setting of continuous index learning, in which a function of many variables varies only along a small number of directions at each point. For efficient estimation, it is beneficial for a learning algorithm to adapt, near each point $x$, to the subspace that captures the local variability of the function $f$. We pose this task as kernel adaptation along a manifold with noise, and introduce Local EGOP learning, a recursive algorithm that utilizes the Expected Gradient Outer Product (EGOP) quadratic form as both a metric and inverse-covariance of our target distribution. We prove that Local EGOP learning adapts to the regularity of the function of interest, showing that under a supervised noisy manifold hypothesis, intrinsic dimensional learning rates are achieved for arbitrarily high-dimensional noise. Empirically, we compare our algorithm to the feature learning capabilities of deep learning. Additionally, we demonstrate improved regression quality compared to two-layer neural networks in the continuous single-index setting.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.07061" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.07061" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.07061" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">stat.ML</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics / Advanced Architectures, Representation Learning, Probabilistic Modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">25. Learning to bin: differentiable and Bayesian optimization for multi-dimensional discriminants in high-energy physics
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Johannes Erdmann, Nitish Kumar Kasaraguppe, Florian Mausolf</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Optimizing bin boundaries for signal significance in multi-dimensional high-energy physics discriminants using Gaussian Mixture Models and differentiable or Bayesian optimization significantly enhances signal sensitivity compared to traditional equidistant or argmax classification methods. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Categorizing events using discriminant observables is central to many high-energy physics analyses. Yet, bin boundaries are often chosen by hand. A simple, popular choice is to apply argmax projections of multi-class scores and equidistant binning of one-dimensional discriminants. We propose a binning optimization for signal significance directly in multi-dimensional discriminants. We use a Gaussian Mixture Model (GMM) to define flexible bin boundary shapes for multi-class scores, while in one dimension (binary classification) we move bin boundaries directly. On this binning model, we study two optimization strategies: a differentiable and a Bayesian optimization approach. We study two toy setups: a binary classification and a three-class problem with two signals and backgrounds. In the one-dimensional case, both approaches achieve similar gains in signal sensitivity compared to equidistant binnings for a given number of bins. In the multi-dimensional case, the GMM-based binning defines sensitive categories as well, with the differentiable approach performing best. We show that, in particular for limited separability of the signal processes, our approach outperforms argmax classification even with optimized binning in the one-dimensional projections. Both methods are released as lightweight Python plugins intended for straightforward integration into existing analyses.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.07756" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.07756" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.07756" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">physics.data-an</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">26. A First Course in Sparse Optimization
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Jun Lu</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A comprehensive overview of sparse optimization details the mathematical foundations, models like LASSO and sparse signal recovery, and key algorithms such as basis pursuit and elastic net, serving as a rigorous resource for practitioners and researchers. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">This article aims to provide a comprehensive overview of sparse optimization, with a focus on both sparse signal recovery and sparse regularization techniques. We will begin by exploring the foundations of sparse optimization, delving into the mathematical tools and models that underpin sparse signal recovery and LASSO. We will then discuss key algorithms for both sparse recovery (e.g., basis pursuit, matching pursuit) and sparse regularization (e.g., LASSO, elastic net), along with their applications in real-world problems. Throughout the text, we balance intuitive explanations with rigorous mathematical formulations to provide a comprehensive resource for both newcomers and experts in the field. Our aim is twofold: to provide a self-contained entry point for students and researchers new to the field, and to offer a rigorous reference for practitioners seeking to apply sparse optimization in science and engineering.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.06173" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.06173" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.06173" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">math.HO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">27. Learning to Trust the Crowd: A Multi-Model Consensus Reasoning Engine for Large Language Models
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Pranav Kallem</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A Multi-Model Consensus Reasoning Engine leverages supervised meta-learning, including graph neural networks and semantic clustering features, to analyze heterogeneous LLM outputs, substantially improving macro-average accuracy and reducing hallucinations compared to individual models or majority voting. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Large language models (LLMs) achieve strong average performance yet remain unreliable at the instance level, with frequent hallucinations, brittle failures, and poorly calibrated confidence. We study reliability through the lens of multi-model consensus: given responses from several heterogeneous LLMs, can we learn which answer is most likely correct for a given query? We introduce a Multi-Model Consensus Reasoning Engine that treats the set of LLM outputs as input to a supervised meta-learner. The system maps natural language responses into structured features using semantic embeddings, pairwise similarity and clustering statistics, lexical and structural cues, reasoning-quality scores, confidence estimates, and model-specific priors, and then applies gradient-boosted trees, listwise ranking, and graph neural networks over similarity graphs of answers. Using three open-weight LLMs evaluated on compact, resource-constrained subsets of GSM8K, ARC-Challenge, HellaSwag, and TruthfulQA, our best graph-attention-based consensus model improves macro-average accuracy by 4.6 percentage points over the strongest single LLM and by 8.1 points over majority vote, while also yielding lower Brier scores and fewer TruthfulQA hallucinations. Ablation and feature-importance analyses show that semantic agreement and clustering features are most influential, with reasoning-quality and model-prior features providing complementary gains, suggesting supervised multi-model consensus is a practical route toward more reliable LLM behavior, even in a modest single-machine setup.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.07245" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.07245" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.07245" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics / Advanced Architectures, Representation Learning, Probabilistic Modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">28. Probing Dark Matter annihilation in the Galactic Centre with TRIDENT
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Yingwei Wang, Xinhui Chu, Andrew Cheek, Iwan Morton-Blake, Qichao Chang, Gwenael Giacinti, Samy Kaci, Xin Xiang, Donglian Xu, Fuyudi Zhang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The TRIDENT neutrino telescope is projected to probe dark matter annihilation rates below the thermal freeze-out benchmark, with cascade events providing superior sensitivity, although the previously overlooked Galactic neutrino background slightly degrades high-energy sensitivity. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We determine the future sensitivity of the TRIDENT neutrino telescope to dark matter annihilation in the Galactic Centre. By applying the full detector design we show that TRIDENT will probe annihilation rates down to $\langleσv\rangle\approx5\times10^{-27}\,{\rm cm}^3\,{\rm s}^{-1}$ for a $10\,{\rm TeV}$ dark matter, which is below the thermal freeze-out benchmark. The analysis is carried out with all-flavour neutrino interactions, where we demonstrate that cascade events, primarily due to $ν_{e,τ}$, show greater sensitivity to a dark matter signal compared to the more commonly studied track events. Furthermore, we highlight the impact of a previously overlooked background, Galactic neutrinos produced from interactions between hadronic cosmic rays and interstellar gas. We find dark matter sensitivities are more strongly degraded in the high energy region above $\sim 10\, {\rm TeV}$, with a maximal weakening of approximately a factor of $\sim 2$. This effect remains smaller than the uncertainty associated with the dark matter density profile but can nonetheless mimic a positive annihilation signal. We contextualize these results with a concrete particle model and show that TRIDENT will be able to probe the most interesting untested parts of parameter space.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.06817" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.06817" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.06817" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">hep-ph</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">29. ENTRA: Entropy-Based Redundancy Avoidance in Large Language Model Reasoning
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Ruichu Cai, Haopeng Du, Qingwen Lin, Yutong Chen, Zijian Li, Boyan Xu</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> ENTRA, an entropy-based reinforcement learning framework utilizing Bidirectional Importance Estimation, effectively suppresses redundant reasoning in Large Reasoning Models by rewarding conciseness, resulting in substantial reductions in output length without sacrificing performance. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Large Reasoning Models (LRMs) often suffer from overthinking, generating unnecessarily long reasoning chains even for simple tasks. This leads to substantial computational overhead with limited performance gain, primarily due to redundant verification and repetitive generation. While prior work typically constrains output length or optimizes correctness, such coarse supervision fails to guide models toward concise yet accurate inference. In this paper, we propose ENTRA, an entropy-based training framework that suppresses redundant reasoning while preserving performance. ENTRA first estimates the token-level importance using a lightweight Bidirectional Importance Estimation (BIE) method, which accounts for both prediction confidence and forward influence. It then computes a redundancy reward based on the entropy of low-importance tokens, normalized by its theoretical upper bound, and optimizes this reward via reinforcement learning. Experiments on mathematical reasoning benchmarks demonstrate that ENTRA reduces output length by 37% to 53% with no loss-and in some cases, gains-in accuracy. Our approach offers a principled and efficient solution to reduce overthinking in LRMs, and provides a generalizable path toward redundancy-aware reasoning optimization.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.07123" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.07123" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.07123" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics / Advanced Architectures, Representation Learning, Probabilistic Modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">30. Balance flux laws beyond general relativity
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>David Maibach, Jann Zosso</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Balance flux laws for asymptotic symmetries at null infinity are derived for diffeomorphism-invariant extensions of General Relativity, particularly Horndeski theories, using the covariant phase space formalism to provide non-perturbative constraints on gravitational strain in modified gravity. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Balance flux laws of asymptotic symmetries in general relativity provide fully non-perturbative constraint equations on gravitational strain. They have proven useful for constructing numerical gravitational waveforms and for characterizing gravitational memory. As the precision of current and future detectors continues to improve, such constraints become increasingly important for high-precision tests of gravity, including searches for deviations from general relativity. This motivates a systematic understanding of analogous balance laws in theories beyond general relativity. In this work, we investigate the existence and structure of flux laws at null infinity in diffeomorphism-invariant extensions of general relativity. Our analysis is based on the covariant phase space formalism and the definition of conserved quantities, as presented by Wald and Zoupas. For a particularly relevant class of Horndeski theories, we derive a general expression for the flux and formulate the corresponding balance equation via the associated non-conserved charges. We cross-check our general results by comparing them with previous studies of Brans-Dicke gravity. Furthermore, we demonstrate that the employed methods extend straightforwardly to a broader class of diffeomorphism-invariant theories. The null part of the resulting flux laws associated with null memory is compared with and validated against the alternative derivation based on the Isaacson approach to gravitational radiation. Beyond the specific results obtained, this work is intended to serve as a practical guide for computing balance laws in generic diffeomorphism-invariant theories of gravity and paves the way for an in-depth comparison between the Isaacson approach and the covariant phase space formalism.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.07091" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.07091" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.07091" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">gr-qc</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">31. CASCO: Cosmological and AStrophysical parameters from Cosmological simulations and Observations IV. Testing warm dark matter cosmologies with galaxy scaling relations: A joint simulation-observation study using DREAMS simulations
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">M. Silvestrini, C. Tortora, V. Busillo, Alyson M. Brooks, A. Farahi, A. M. Garcia, N. Kallivayalil, N. R. Napolitano, J. C. Rose, P. Torrey, et al.</span>
                                <span class="author-full" style="display: none;">M. Silvestrini, C. Tortora, V. Busillo, Alyson M. Brooks, A. Farahi, A. M. Garcia, N. Kallivayalil, N. R. Napolitano, J. C. Rose, P. Torrey, F. Villaescusa-Navarro, M. Vogelsberger</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Combining multi-resolution hydrodynamic simulations with observational galaxy catalogs effectively constrains cosmological and feedback parameters, revealing subtle warm dark matter trends at low stellar masses that suggest the stellar mass function is a viable complementary probe. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Small-scale discrepancies in the standard Lambda cold dark matter paradigm have motivated the exploration of alternative dark matter (DM) models, such as warm dark matter (WDM). We investigate the constraining power of galaxy scaling relations on cosmological, astrophysical, and WDM parameters through a joint analysis of hydrodynamic simulations and observational data. Our study is based on the DREAMS project and combines large-volume uniform-box simulations with high-resolution Milky Way zoom-in runs in a $Λ$WDM cosmology. To ensure consistency between the different simulation sets, we apply calibrations to account for resolution effects, allowing us to exploit the complementary strengths of the two suites. We compare simulated relations, including stellar size, DM mass and fraction within the stellar half-mass radius, and the total-to-stellar mass ratio, with two complementary galaxy samples: the SPARC catalog of nearby spirals and the LVDB catalog of dwarf galaxies in the Local Volume. Using a bootstrap-based fitting procedure, we show that key cosmological parameters ($Ω_m$, $σ_8$) and supernova feedback strength can be recovered with good accuracy, particularly from the uniform-box simulations. While the WDM particle mass remains unconstrained, the zoom-in simulations reveal subtle WDM-induced trends at low stellar masses in both the DM mass and total-to-stellar mass ratio. We also find that the galaxy stellar mass function exhibits a measurable dependence on the WDM particle mass below log10(M_*/Msun) &lt;~ 8, which appears separable from the impact of feedback, suggesting it as a promising complementary probe. Our results highlight the importance of combining multi-resolution simulations with diverse observational datasets to jointly constrain baryonic processes and DM properties.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.07543" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.07543" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.07543" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">32. Object-Centric World Models Meet Monte Carlo Tree Search
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Rodion Vakhitov, Leonid Ugadiarov, Aleksandr Panov</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The ObjectZero reinforcement learning algorithm utilizes Graph Neural Networks and object-centric representations to build a structured world model, enabling effective prediction of object dynamics and integration with Monte Carlo Tree Search planning in complex environments. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">In this paper, we introduce ObjectZero, a novel reinforcement learning (RL) algorithm that leverages the power of object-level representations to model dynamic environments more effectively. Unlike traditional approaches that process the world as a single undifferentiated input, our method employs Graph Neural Networks (GNNs) to capture intricate interactions among multiple objects. These objects, which can be manipulated and interact with each other, serve as the foundation for our model&#39;s understanding of the environment. We trained the algorithm in a complex setting teeming with diverse, interactive objects, demonstrating its ability to effectively learn and predict object dynamics. Our results highlight that a structured world model operating on object-centric representations can be successfully integrated into a model-based RL algorithm utilizing Monte Carlo Tree Search as a planning module.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.06604" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.06604" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.06604" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics / Advanced Architectures, Representation Learning, Probabilistic Modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">33. From RLHF to Direct Alignment: A Theoretical Unification of Preference Learning for Large Language Models
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Tarun Raheja, Nilay Pochhi</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A theoretical framework unifies the proliferation of LLM preference learning methods by categorizing them along three orthogonal axes—Preference Model, Regularization, and Data Distribution—thereby explaining failure modes and transforming the field into a theoretically grounded discipline. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Aligning large language models (LLMs) with human preferences has become essential for safe and beneficial AI deployment. While Reinforcement Learning from Human Feedback (RLHF) established the dominant paradigm, a proliferation of alternatives -- Direct Preference Optimization (DPO), Identity Preference Optimization (IPO), Kahneman-Tversky Optimization (KTO), Simple Preference Optimization (SimPO), and many others -- has left practitioners without clear guidance on method selection. This survey provides a \textit{theoretical unification} of preference learning methods, revealing that the apparent diversity reduces to principled choices along three orthogonal axes: \textbf{(I) Preference Model} (what likelihood model underlies the objective), \textbf{(II) Regularization Mechanism} (how deviation from reference policies is controlled), and \textbf{(III) Data Distribution} (online vs.\ offline learning and coverage requirements). We formalize each axis with precise definitions and theorems, establishing key results including the coverage separation between online and offline methods, scaling laws for reward overoptimization, and conditions under which direct alignment methods fail. Our analysis reveals that failure modes -- length hacking, mode collapse, likelihood displacement -- arise from specific, predictable combinations of design choices. We synthesize empirical findings across 50+ papers and provide a practitioner&#39;s decision guide for method selection. The framework transforms preference learning from an empirical art into a theoretically grounded discipline.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.06108" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.06108" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.06108" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics / Advanced Architectures, Representation Learning, Probabilistic Modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">34. Comment on arXiv:2511.21731v1: Identifying Quantum Structure in AI Language: Evidence for Evolutionary Convergence of Human and Artificial Cognition
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Krzysztof Sienicki</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A technical critique suggests that a prior manuscript&#39;s interpretation of CHSH/Bell calculations and Bose-Einstein fits to rank-frequency data likely overstates the implications regarding quantum entanglement in the standard Hilbert-space context. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">This note is a friendly technical check of arXiv:2511.21731v1. I highlight a few places where the manuscript&#39;s interpretation of (i) the reported CHSH/Bell-type calculations and (ii) Bose--Einstein (BE) fits to rank-frequency data seems to go beyond what the stated procedures can firmly support. I also point out one internal inconsistency in the &#34;energy-level spacing&#34; analogy. The aim is constructive: to keep the interesting empirical observations, while making clear what they do (and do not) imply about quantum entanglement in the usual Hilbert-space sense, especially when &#34;energy&#34; is defined by rank.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.06104" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.06104" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.06104" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">35. CAMELS Environments: The Impact of Local Neighbours on Galaxy Evolution across the SIMBA, IllustrisTNG, ASTRID, and Swift-EAGLE Simulations
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Xavier Sims, Daniel Anglés-Alcázar, Boon-Kiat Oh, Daisuke Nagai, Jonathan Mercedes-Feliz, Isabel Medlock, Yueying Ni, Christopher C. Lovell, Francisco Villaescusa-Navarro</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Environmental effects significantly influence galaxy evolution, particularly suppressing satellite star formation, but the specific response of central galaxies and halo baryon fractions depends critically on the chosen galaxy formation model and can vary dramatically with galaxy mass and cosmic epoch. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Internal feedback from massive stars and active galactic nuclei (AGN) play a key role in galaxy evolution, but external environmental effects can also strongly influence galaxies. We investigate the impact of environment on galaxy evolution, and its dependence on baryonic physics implementation, using Cosmology and Astrophysics with MachinE Learning Simulations (CAMELS) spanning a wide range of stellar and AGN feedback implementations in the SIMBA, IllustrisTNG, ASTRID, and Swift-EAGLE galaxy formation models. We show that satellite galaxies are significantly affected by the environment in all simulation models, with their gas fraction and star formation rate (SFR) suppressed in overdense regions compared to similar mass satellites in underdense environments at $z=0$. Central galaxies are less sensitive to environment but tend to show lower gas fraction and SFR in overdense regions at low stellar mass, transitioning to higher gas fraction and SFR for massive galaxies in higher-density environments. Halo baryon fraction ($f_{\rm B}$) and circumgalactic medium mass fraction ($f_{\rm CGM}$) at $z=0$ show clear environmental effects. In SIMBA, low-mass haloes in overdense regions have systematically lower $f_{\rm B}$ and $f_{\rm CGM}$ at fixed halo mass, while Swift-EAGLE haloes in overdense regions have systematically higher $f_{\rm B}$ and $f_{\rm CGM}$ across the full halo mass range, and IllustrisTNG and ASTRID show opposite trends at the low and high mass ends. Environmental effects can flip at higher redshift, with SFR and $f_{\rm B}$ increasing with local density in low-mass haloes before quenching at an increasing overdensity threshold. Our results demonstrate that the impact of environment on galaxy evolution depends significantly on galaxy formation model, and higher-density environments can either suppress or enhance star formation depending on galaxy mass and cosmic epoch.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.06290" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.06290" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.06290" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.04</span>
                        <span class="badge bg-primary">Semantic Score: 0.90</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">36. Dr. Zero: Self-Evolving Search Agents without Training Data
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Zhenrui Yue, Kartikeya Upasani, Xianjun Yang, Suyu Ge, Shaoliang Nie, Yuning Mao, Zhe Liu, Dong Wang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The Dr. Zero framework enables data-free self-evolution for search agents by employing a proposer-solver feedback loop that establishes an automated curriculum, enhanced by hop-grouped relative policy optimization to significantly improve training efficiency and performance. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">As high-quality data becomes increasingly difficult to obtain, data-free self-evolution has emerged as a promising paradigm. This approach allows large language models (LLMs) to autonomously generate and solve complex problems, thereby improving their reasoning capabilities. However, multi-turn search agents struggle in data-free self-evolution due to the limited question diversity and the substantial compute required for multi-step reasoning and tool using. In this work, we introduce Dr. Zero, a framework enabling search agents to effectively self-evolve without any training data. In particular, we design a self-evolution feedback loop where a proposer generates diverse questions to train a solver initialized from the same base model. As the solver evolves, it incentivizes the proposer to produce increasingly difficult yet solvable tasks, thus establishing an automated curriculum to refine both agents. To enhance training efficiency, we also introduce hop-grouped relative policy optimization (HRPO). This method clusters structurally similar questions to construct group-level baselines, effectively minimizing the sampling overhead in evaluating each query&#39;s individual difficulty and solvability. Consequently, HRPO significantly reduces the compute requirements for solver training without compromising performance or stability. Extensive experiment results demonstrate that the data-free Dr. Zero matches or surpasses fully supervised search agents, proving that complex reasoning and search capabilities can emerge solely through self-evolution.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.07055" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.07055" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.07055" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics / Advanced Architectures, Representation Learning, Probabilistic Modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">37. Student Guides Teacher: Weak-to-Strong Inference via Spectral Orthogonal Exploration
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Dayu Wang, Jiaye Yang, Weikang Li, Jiahui Liang, Yang Li</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Spectral Orthogonal Exploration (SOE) overcomes &#34;Reasoning Collapse&#34; in large language models by using a weak auxiliary agent to orthogonally probe the model&#39;s Null Space, thereby facilitating semantic exploration and achieving substantial gains in complex mathematical proving accuracy and efficiency. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">While Large Language Models (LLMs) demonstrate near-human capabilities, they often suffer from &#34;Reasoning Collapse&#34; in complex mathematical proving and long-horizon planning. Models tend to degenerate into low-rank Bias Manifold, where stochastic sampling merely produces lexical variations of erroneous logic rather than semantic exploration. This geometric collapse renders the model &#34;blind&#34; to high-value solutions that lie within its Null Space. To address this, we propose Spectral Orthogonal Exploration (SOE), a geometric framework operating on a counter-intuitive &#34;Student Guides Teacher&#34; paradigm. Specifically, we utilize a weak auxiliary agent not for imitation, but as an orthogonal probe. By explicitly navigating the Teacher&#39;s Null Space, SOE serves as a geometric bridge, effectively ejecting the model from local optima to explore diverse, high-value solution spaces. Experiments on mathematical benchmarks demonstrate that, relative to baseline methods, our approach improves average accuracy by 62.4% and increases average sampling efficiency by 113.7%, indicating a promising path toward overcoming performance plateaus in advanced reasoning tasks.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.06160" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.06160" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.06160" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics / Advanced Architectures, Representation Learning, Probabilistic Modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">38. Consolidation or Adaptation? PRISM: Disentangling SFT and RL Data via Gradient Concentration
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">Yang Zhao, Yangou Ouyang, Xiao Ding, Hepeng Wang, Bibo Cai, Kai Xiong, Jinglong Gao, Zhouhao Sun, Li Du, Bing Qin, et al.</span>
                                <span class="author-full" style="display: none;">Yang Zhao, Yangou Ouyang, Xiao Ding, Hepeng Wang, Bibo Cai, Kai Xiong, Jinglong Gao, Zhouhao Sun, Li Du, Bing Qin, Ting Liu</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The PRISM framework optimizes hybrid LLM agent training by using gradient spatial geometry to diagnose data conflict, routing high-conflict samples to Reinforcement Learning for structural adaptation and low-conflict samples to Supervised Fine-Tuning for efficient consolidation. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">While Hybrid Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL) has become the standard paradigm for training LLM agents, effective mechanisms for data allocation between these stages remain largely underexplored. Current data arbitration strategies often rely on surface-level heuristics that fail to diagnose intrinsic learning needs. Since SFT targets pattern consolidation through imitation while RL drives structural adaptation via exploration, misaligning data with these functional roles causes severe optimization interference. We propose PRISM, a dynamics-aware framework grounded in Schema Theory that arbitrates data based on its degree of cognitive conflict with the model&#39;s existing knowledge. By analyzing the spatial geometric structure of gradients, PRISM identifies data triggering high spatial concentration as high-conflict signals that require RL for structural restructuring. In contrast, data yielding diffuse updates is routed to SFT for efficient consolidation. Extensive experiments on WebShop and ALFWorld demonstrate that PRISM achieves a Pareto improvement, outperforming state-of-the-art hybrid methods while reducing computational costs by up to 3.22$\times$. Our findings suggest that disentangling data based on internal optimization regimes is crucial for scalable and robust agent alignment.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.07224" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.07224" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.07224" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics / Advanced Architectures, Representation Learning, Probabilistic Modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">39. Multi-environment Invariance Learning with Missing Data
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Yiran Jia</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A novel estimator derived for invariance learning objectives maintains strong non-asymptotic guarantees on variable selection and prediction error convergence rates, proving effective for domain generalization even when outcome data is partially missing and imputed with reasonable bias. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Learning models that can handle distribution shifts is a key challenge in domain generalization. Invariance learning, an approach that focuses on identifying features invariant across environments, improves model generalization by capturing stable relationships, which may represent causal effects when the data distribution is encoded within a structural equation model (SEM) and satisfies modularity conditions. This has led to a growing body of work that builds on invariance learning, leveraging the inherent heterogeneity across environments to develop methods that provide causal explanations while enhancing robust prediction. However, in many practical scenarios, obtaining complete outcome data from each environment is challenging due to the high cost or complexity of data collection. This limitation in available data hinders the development of models that fully leverage environmental heterogeneity, making it crucial to address missing outcomes to improve both causal insights and robust prediction. In this work, we derive an estimator from the invariance objective under missing outcomes. We establish non-asymptotic guarantees on variable selection property and $\ell_2$ error convergence rates, which are influenced by the proportion of missing data and the quality of imputation models across environments. We evaluate the performance of the new estimator through extensive simulations and demonstrate its application using the UCI Bike Sharing dataset to predict the count of bike rentals. The results show that despite relying on a biased imputation model, the estimator is efficient and achieves lower prediction error, provided the bias is within a reasonable range.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.07247" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.07247" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.07247" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">stat.ML</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics / Advanced Architectures, Representation Learning, Probabilistic Modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">40. Knowledge Distillation for LLM-Based Human Activity Recognition in Homes
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Julien Cumin, Oussama Er-Rahmany, Xi Chen</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Knowledge distillation effectively transfers high-performance Human Activity Recognition capabilities from large language models to significantly smaller models, achieving near-equivalent recognition performance with drastically reduced parameter counts. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Human Activity Recognition (HAR) is a central problem for context-aware applications, especially for smart homes and assisted living. A few very recent studies have shown that Large Language Models (LLMs) can be used for HAR at home, reaching high performance and addressing key challenges. In this paper, we provide new experimental results regarding the use of LLMs for HAR, on two state-of-the-art datasets. More specifically, we show how recognition performance evolves depending on the size of the LLM used. Moreover, we experiment on the use of knowledge distillation techniques to fine-tune smaller LLMs with HAR reasoning examples generated by larger LLMs. We show that such fine-tuned models can perform almost as well as the largest LLMs, while having 50 times less parameters.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.07469" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.07469" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.07469" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.01</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics / Advanced Architectures, Representation Learning, Probabilistic Modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">41. Limits of vacuum-template subtraction for LISA massive black hole binary sources in realistic environments
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Lorenz Zwick</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Imperfect subtraction of massive black hole binary signals in LISA data, due to gravitational wave dephasing caused by gas accretion, leaves a quantifiable residual signal whose SNR depends critically on the population&#39;s Eddington ratio and merger rate. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We investigate the impact of gravitational wave (GW) dephasing due to gas accretion on the subtraction of massive black hole (MBH) binary signals over 4 yr of LISA data in the context of the global-fit. Based on state of the art predictions for the population of merging MBHs, we show that imperfect subtraction with vacuum waveform templates leaves a GW residual with an SNR of $3.2^{+5.4}_{-1.9}\times \sqrt{f_{\rm Edd} \langle \dot n \rangle/(20\, {\rm yr}^{-1})}$, where $f_{\rm Edd}$ is the typical Eddington ratio and $\langle \dot n \rangle$ the mean merger rate of LISA MBH binaries. We characterize the dependence of the residual on key population hyper-parameters, provide a simple fitting function and discuss detection and mitigation strategies.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.06684" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.06684" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.06684" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">gr-qc</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">42. Star formation quenching precedes morphological transformation in COSMOS-WEB&#39;s richest galaxy groups
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">Z. Ghaffari, G. Gozaliasl, A. Biviano, G. Toni, S. Taamoli, M. Maturi, L. Moscardini, A. Zacchei, F. Gentile, M. Haas, et al.</span>
                                <span class="author-full" style="display: none;">Z. Ghaffari, G. Gozaliasl, A. Biviano, G. Toni, S. Taamoli, M. Maturi, L. Moscardini, A. Zacchei, F. Gentile, M. Haas, H. Akins, R. C. Arango-Toro, Y. Cheng, C. Casey, M. Franco, S. Harish, H. Hatamnia, O. Ilbert, J. Kartaltepe, A. H. Khostovan, A. M. Koekemoer, D. Liu, G. A. Mamon, H. J. McCracken, J. McKinney, J. Rhodes, B. Robertson, M. Shuntov, L. Yang</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Studying rich galaxy groups in COSMOS-Web reveals that mass-dependent quenching rapidly transforms massive galaxies into spheroidal early-types, while environmental processes mildly suppress star formation in lower-mass systems, suggesting distinct quenching timescales and mechanisms across the mass spectrum. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We analyzed the 25 richest galaxy groups in COSMOS-Web at z = 0.18-3.65, identified via the AMICO algorithm. These groups contain 20-30 galaxies with high (&gt;75%) membership probability. Our study reveals both passive-density and active-density relations: late-type galaxies (LTGs) prefer higher central overdensities than early-type galaxies (ETGs) across all groups, and many massive LTGs exhibit colors typical of quiescent galaxies. We identify red sequences (RS) in 5 groups, prominently established at z 10^10.5 M_sun) undergo rapid quenching over ~1 Gyr, becoming predominantly spheroidal ETGs. This indicates morphological transformation accelerates in massive systems during peak cosmic star formation. Intermediate-mass galaxies (10^9 &lt; M_star/M_sun &lt; 10^10.5) show mild quenching, while low-mass galaxies (M_star &lt; 10^9 M_sun) remain largely star-forming; here, environmental processes suppress star formation without destroying disks, suggesting group quenching operates on longer timescales than mass quenching. Overall, mass-dependent quenching dominates the high-mass end, while environment shapes lower-mass systems. The HLAGN fraction for both groups and field increases with redshift, peaking at z ~ 2, with groups consistently showing higher fractions. We suggest AGN feedback partially drives rapid quenching in high-mass galaxies, while mergers may trigger AGN activity.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.06297" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.06297" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.06297" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.07</span>
                        <span class="badge bg-primary">Semantic Score: 0.88</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">43. Evaluating the efficacy of a data cube treatment procedure for kinematic analyses: application to NGC 3115 and NGC 4699
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>R. B. Menezes, L. D. B. Sonoda, Patrícia da Silva, A. T. Monteiro, T. V. Ricci, R. G. Bravo, D. D. V. Gueter, V. C. Parro</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Applying a data cube treatment methodology involving Butterworth filtering and Richardson-Lucy deconvolution to IFU observations substantially improves the precision of dynamical modeling, reducing the uncertainty in derived supermassive black hole masses by up to 45%. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Data cubes have been increasingly used in astronomy. These data sets, however, are usually affected by instrumental effects and high-frequency noise. In this work, we evaluate the efficacy of a data cube treatment methodology, previously proposed by our research group, for analyses focused on the stellar and gas kinematics. To do that, we used data cubes of the central regions of the galaxies NGC 3115 and NGC 4699, obtained with the Integral Field Unit of the Gemini Multi-Object Spectrograph. For each galaxy, we analysed three data cubes: non-treated, filtered (with the Butterworth spatial filtering) and filtered and deconvolved (with the Richardson-Lucy deconvolution). For each data cube, we performed a dynamical modelling, using Jeans Anisotropic Models, to obtain, among other parameters, the masses of the central supermassive black holes. Both for NGC 3115 and NGC 4699, the values of the parameters provided by the dynamical modelling from the non-treated, filtered and filtered and deconvolved data cubes were compatible, at the 1-$σ$ level. However, the use of the Butterworth spatial filtering decreased the uncertainty of the parameters. The additional use of the Richardson-Lucy deconvolution decreased even more the uncertainty of the parameters. The complete data treatment procedure resulted in decreases of 41% and 45% in the uncertainties of the supermassive black hole masses in NGC 3115 and NGC 4699, respectively. These results indicate that our treatment procedure not only does not compromise analyses of data cubes focused on the stellar or gas kinematics, but actually improves the quality of the results.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.06718" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.06718" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.06718" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">44. Galaxy Mergers in UNIONS -- II: Predicting Timescales in the Post-Merger Regime
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Leonardo Ferreira, Sara L. Ellison, David R. Patton, Shoshannah Byrne-Mamahit, Scott Wilkinson, Robert W. Bickley</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Leveraging machine learning trained on realism-enhanced mock observations, the MUlti-Model Merger Identifier (	extsc{Mummi}) framework successfully predicts post-merger timescales with over 70% accuracy, providing a robust method to link galaxy interaction duration to evolutionary processes in the UNIONS survey. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Galaxy mergers are critical events that influence galaxy evolution by driving processes such as enhanced star formation, quenching, and active galactic nucleus (AGN) activity. However, constraining the timescales over which these processes occur in the post-merger phase has remained a significant challenge. This study extends the MUlti-Model Merger Identifier (\textsc{Mummi}) framework to predict post-merger timescales ($T_{PM}$) for galaxies, leveraging machine learning models trained on realism-enhanced mock observations derived from the IllustrisTNG simulations. By classifying post-merger galaxies into four temporal bins spanning 0 to 1.76 Gyr after coalescence, \textsc{Mummi} achieves time classification accuracies exceeding 70 per cent. We apply this framework to the Ultraviolet Near Infrared Optical Northern Survey (UNIONS), yielding a catalog of 8,716 post-merger galaxies with $T_{PM}$ predictions and stellar masses $\log(M_*/M_\odot) \geq 10$ at redshifts 0.03 &lt; z &lt; 0.3. These results provide a robust methodology to connect galaxy interaction timescales with physical processes, enabling detailed studies of galaxy evolution in the post-merger regime.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.07604" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.07604" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.07604" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">45. A New Consistency Test for the $Λ$CDM Model using Radial and Transverse BAO Measurements
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Xing-Han A. Zhao, Zheng Cai</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A calibration-free consistency test for flat $\Lambda$CDM, utilizing ratios of BAO distance measurements to derive a redshift-independent effective matter density parameter, confirms the internal consistency of the model based on constraints from DESI data releases. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We present a calibration-free consistency test of spatially flat $Λ$CDM based on baryon acoustic oscillation (BAO) distance measurements. The method forms ratios of BAO distances including the Hubble distance, the comoving angular diameter distance, and the volume-averaged distance, so that the sound horizon scale cancels, and then maps each observed ratio to an effective flat-$Λ$CDM matter density parameter, $Ω_{\rm M}^Λ$, defined as the value of $Ω_{\rm M}$ that reproduces the measured ratio within $Λ$CDM. Flat $Λ$CDM predicts that $Ω_{\rm M}^Λ$ should be independent of redshift and of the particular ratio used. For ratios involving the integrated distances, we associate them with well-defined effective line-of-sight redshift intervals based on the integral mean value theorem. We apply the test to BAO measurements from the Dark Energy Spectroscopic Instrument (DESI) Data Release~1 and Data Release~2, propagating the full published BAO covariance matrices into all derived ratios and $Ω_{\rm M}^Λ$ constraints. Within current uncertainties, the inferred $Ω_{\rm M}^Λ$ values are broadly consistent with a redshift-independent constant, providing an internal consistency check of flat $Λ$CDM that can be strengthened straightforwardly as BAO measurements improve.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.07075" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.07075" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.07075" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">46. New $H(z)$ measurement at Redshift = 0.12 with DESI Data Release 1
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Ze-fan Wang, Lei Lei, Yi-zhong Fan</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Analyzing the stellar ages and star-formation histories of thousands of massive, passively evolving DESI galaxies via full-spectrum fitting yields a new, cosmology-independent measurement of the Hubble parameter $H(z=0.12)=71.33 \pm 4.20~{\rm km~s^{-1}~Mpc^{-1}}$. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The Hubble parameter ($H(z)$) is a function of the redshift and a reliable measurement is very important to understand the expansion history of the Universe. In this work, we perform full-spectrum fitting using BAGPIPES on more than four thousand massive, passively evolving galaxies released by the DESI collaboration to estimate their cosmological-independent stellar ages and star-formation histories, and derive a new measurement of $H(z=0.12)=71.33 \pm 4.20~{\rm km~s^{-1}~Mpc^{-1}}$, which is well consistent with those derived in other ways.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.07345" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.07345" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.07345" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">47. Temperature-Dependent CPT Violation: Constraints from Big Bang Nucleosynthesis
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Gabriela Barenboim, Anne-Katherine Burns</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Analyzing Big Bang Nucleosynthesis observables under temperature-dependent CPT violation, parameterized by electron-positron mass asymmetries, yields the most stringent constraints on this early-universe regime, requiring the scaling factor $\alpha$ to be approximately $10^{-6}$ GeV$^{-1}$ or higher. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">In this study, we explore temperature-dependent CPT violation during Big Bang Nucleosynthesis (BBN) through electron-positron mass asymmetries parametrized by $b_0(T) = αT^2$. The $T^2$ scaling naturally evades stringent laboratory bounds at zero temperature while allowing for significant CPT violation at MeV scales in the early universe \cite{ParticleDataGroup:2024cfk}. Using a modified version of the BBN code \faGithub \href{https://github.com/vallima/PRyMordial}{\,\texttt{PRyMordial}} with dynamically-solved chemical potentials and appropriate finite-mass corrections, we constrain electron-positron mass differences from observed abundances of Helium-4, Deuterium, and $N_{\rm eff}$. We find that $α$ must be greater than or approximately equal to $10^{-6}$ GeV$^{-1}$ for keV-scale mass differences at BBN. All three observables show no simultaneous $1σ$ overlap, though pairwise combinations allow for constrained regions of parameter space. We present three toy models demonstrating how $b_0(T) \propto T^2$ arises from field-theoretic mechanisms, including temperature-driven phase transitions. These results provide the most stringent constraints on early-universe CPT violation in this regime, probing parameter space inaccessible to laboratory experiments.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.06259" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.06259" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.06259" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">hep-ph</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">48. Puzzle it Out: Local-to-Global World Model for Offline Multi-Agent Reinforcement Learning
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Sijia li, Xinran Li, Shibo Chen, Jun Zhang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The local-to-global (LOGO) world model enhances offline Multi-Agent Reinforcement Learning generalization by accurately inferring complex global dynamics from local predictions and employing uncertainty-aware sampling to reliably augment the dataset with synthetic transitions, establishing a new state-of-the-art baseline. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Offline multi-agent reinforcement learning (MARL) aims to solve cooperative decision-making problems in multi-agent systems using pre-collected datasets. Existing offline MARL methods primarily constrain training within the dataset distribution, resulting in overly conservative policies that struggle to generalize beyond the support of the data. While model-based approaches offer a promising solution by expanding the original dataset with synthetic data generated from a learned world model, the high dimensionality, non-stationarity, and complexity of multi-agent systems make it challenging to accurately estimate the transitions and reward functions in offline MARL. Given the difficulty of directly modeling joint dynamics, we propose a local-to-global (LOGO) world model, a novel framework that leverages local predictions-which are easier to estimate-to infer global state dynamics, thus improving prediction accuracy while implicitly capturing agent-wise dependencies. Using the trained world model, we generate synthetic data to augment the original dataset, expanding the effective state-action space. To ensure reliable policy learning, we further introduce an uncertainty-aware sampling mechanism that adaptively weights synthetic data by prediction uncertainty, reducing approximation error propagation to policies. In contrast to conventional ensemble-based methods, our approach requires only an additional encoder for uncertainty estimation, significantly reducing computational overhead while maintaining accuracy. Extensive experiments across 8 scenarios against 8 baselines demonstrate that our method surpasses state-of-the-art baselines on standard offline MARL benchmarks, establishing a new model-based baseline for generalizable offline multi-agent learning.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.07463" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.07463" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.07463" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.01</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics / Advanced Architectures, Representation Learning, Probabilistic Modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">49. Group Pattern Selection Optimization: Let LRMs Pick the Right Pattern for Reasoning
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Hanbin Wang, Jingwei Song, Jinpeng Li, Fei Mi, Lifeng Shang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The Group Pattern Selection Optimization (GPSO) reinforcement learning framework enhances Large Reasoning Models by enabling them to internalize the mapping from problem characteristics to the most effective reasoning pattern, utilizing multi-pattern rollouts and verifier-guided selection to achieve substantial performance improvements on reasoning benchmarks. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Large reasoning models (LRMs) exhibit diverse high-level reasoning patterns (e.g., direct solution, reflection-and-verification, and exploring multiple solutions), yet prevailing training recipes implicitly bias models toward a limited set of dominant patterns. Through a systematic analysis, we identify substantial accuracy variance across these patterns on mathematics and science benchmarks, revealing that a model&#39;s default reasoning pattern is often sub-optimal for a given problem. To address this, we introduce Group Pattern Selection Optimization (GPSO), a reinforcement learning framework that extends GRPO by incorporating multi-pattern rollouts, verifier-guided optimal pattern selection per problem, and attention masking during optimization to prevent the leakage of explicit pattern suffixes into the learned policy. By exploring a portfolio of diverse reasoning strategies and optimizing the policy on the most effective ones, GPSO enables the model to internalize the mapping from problem characteristics to optimal reasoning patterns. Extensive experiments demonstrate that GPSO delivers consistent and substantial performance gains across various model backbones and benchmarks, effectively mitigating pattern sub-optimality and fostering more robust, adaptable reasoning. All data and codes are available at https://github.com/wanghanbinpanda/GPSO.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.07238" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.07238" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.07238" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics / Advanced Architectures, Representation Learning, Probabilistic Modeling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">50. Atmospheric Mass-Squared Splitting at Sub-Percent Precision as a $CPT$ Symmetry Probe
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>T. V. Ngoc, S. Cao, P. T. Quyen</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Combining data from JUNO, DUNE, and Hyper-Kamiokande will improve the sensitivity to CPT violation in the neutrino sector by 60%, achieving a precision of $2\times 10^{-5}~\text{eV}^2$ on the discrepancy between neutrino and antineutrino atmospheric mass-squared splittings. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">In this paper, we present an improved test of $CPT$ symmetry in the neutrino sector by analyzing the atmospheric mass-squared splittings, $Δm^2_{31}$ and $Δ\overline{m}^2_{31}$, using on-going JUNO and future DUNE and Hyper-Kamiokande experiments. Our study focuses on the discrepancy $δ_{ν\overlineν}(Δm^2_{31}) = Δm^2_{31} - Δ\overline{m}^2_{31}$, achieving unprecedented precision by exploiting the high statistics and reduced systematic uncertainties of these facilities. The combined analysis yields a sensitivity to $CPT$ violation at the level of $2\times 10^{-5}~\text{eV}^2$ at $3σ$ confidence level, representing a $60\%$ improvement over the joint T2K-NO$ν$A-JUNO analysis. These results highlight the crucial role of multi-experiment synergies in testing fundamental symmetries of nature.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.07269" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.07269" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.07269" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">hep-ph</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Bayesian Inference, Cosmological Statistics</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
    </div>

    <footer class="footer">
        &copy; 2026 arXiv Daily · Powered by <a href="https://arxiv.org/" target="_blank">arXiv</a>
    </footer>
</body>
</html>