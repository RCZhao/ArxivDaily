<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>arXiv Daily: 2026-02-05</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Roboto:400,700&display=swap" rel="stylesheet">
    <style>
        body { font-family: 'Roboto', Arial, sans-serif; background: #f8f9fa; transition: background 0.3s; }
        .arxiv-card { margin: 2em auto; max-width: 900px; box-shadow: 0 2px 8px rgba(0,0,0,0.08); border-radius: 16px; transition: box-shadow 0.3s, transform 0.3s; }
        .arxiv-card:hover { box-shadow: 0 4px 12px rgba(0,0,0,0.1); transform: translateY(-1px); }
        .arxiv-title { background: linear-gradient(90deg, #0d6efd 60%, #6610f2 100%); color: #fff; border-radius: 16px 16px 0 0; padding: 1.5em; font-size: 1.5em; font-weight: 700; letter-spacing: 0.5px;}
        .arxiv-meta { font-size: 1em; color: #555; margin-bottom: 1em; }
        .arxiv-abstract { background: #fff; padding: 1.5em; border-radius: 0 0 16px 16px; font-size: 1.1em; line-height: 1.7;}
        .arxiv-links a { margin-right: 1em; }
        .arxiv-scores { margin-top: 1em; font-size: 1em; }
        .navbar { background: #fff; box-shadow: 0 2px 8px rgba(0,0,0,0.04);}
        .footer { text-align: center; color: #888; padding: 2em 0 1em 0; font-size: 0.95em;}
        @media (prefers-color-scheme: dark) {
            body { background: #181a1b; color: #e4e6eb; }
            .arxiv-card { background: #23272b; box-shadow: 0 2px 8px rgba(0,0,0,0.28);}
            .arxiv-card:hover { box-shadow: 0 5px 15px rgba(0,0,0,0.25); transform: translateY(-1px); }
            .arxiv-title { background: linear-gradient(90deg, #375a7f 60%, #6f42c1 100%);}
            .arxiv-abstract { background: #23272b; color: #e4e6eb;}
            .navbar { background: #23272b; color: #e4e6eb;}
            .text-muted { color: #adb5bd !important; }
        }
        /* Improved abstract readability */
        .arxiv-abstract-text {
            font-size: 1.1em;
            line-height: 1.7;
        }
        p.big {
            line-height: 1.6;
            font-size: large;
        }
    </style>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'] ],
          processEscapes: true
        }
      });
    </script>
    <script>
    function toggleAuthors(element) {
        const fullList = element.querySelector('.author-full');
        const shortList = element.querySelector('.author-short');
        const toggleText = element.querySelector('.author-toggle');
        
        fullList.style.display = fullList.style.display === 'none' ? 'inline' : 'none';
        shortList.style.display = shortList.style.display === 'none' ? 'inline' : 'none';
        toggleText.textContent = fullList.style.display === 'none' ? ' (show all)' : ' (show less)';
    }
    </script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
</head>
<body>
    <nav class="navbar navbar-expand-lg mb-4">
        <div class="container">
            <a class="navbar-brand fw-bold text-primary" href="#">arXiv Daily</a>
            <span class="navbar-text">Modern arXiv Reader</span>
        </div>
    </nav>

    
    <div class="container py-4">
        <header class="mb-4"><h2 class="display-6 text-center">Analysis of Your Favorites</h2></header>
        
        <div class="row justify-content-center">
            <div class="col-lg-8 mb-4">
                <div class="card">
                    <div class="card-header fw-bold">Interest Word Cloud</div>
                    <div class="card-body text-center p-2">
                        <img src="analysis_results/word_cloud.png" class="img-fluid rounded" alt="Word Cloud of favorite paper topics">
                    </div>
                </div>
            </div>
        </div>
        
        
        <div class="row justify-content-center">
            <div class="col-lg-8 mb-4">
                <div class="card">
                    <div class="card-header fw-bold">Interest Clusters</div>
                    <div class="card-body text-center p-2">
                        <img src="analysis_results/daily_cluster_map.png" class="img-fluid rounded" alt="2D Cluster plot of favorite papers">
                    </div>
                </div>
            </div>
        </div>
        
    </div>
    

    <div class="container py-4">
        <header class="mb-4"><h1 class="display-5 text-center text-primary">arXiv: 2026-02-05</h1></header>

        
        <div class="row justify-content-center">
            <div class="col-lg-8 mb-4">
                <div class="card">
                    <div class="card-header fw-bold">Score Distribution of All Papers Found Today</div>
                    <div class="card-body text-center p-2">
                        <img src="analysis_results/score_distribution.png" class="img-fluid rounded" alt="Score distribution of all papers found today">
                    </div>
                </div>
            </div>
        </div>
        

        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">1. Emulating galaxy and peculiar velocity clustering on non-linear scales
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">T. Dumerchat, J. Bautista, C. Ravoux, J. Aguilar, S. Ahlen, S. BenZvi, D. Bianchi, D. Brooks, T. Claybaugh, A. de la Macorra, et al.</span>
                                <span class="author-full" style="display: none;">T. Dumerchat, J. Bautista, C. Ravoux, J. Aguilar, S. Ahlen, S. BenZvi, D. Bianchi, D. Brooks, T. Claybaugh, A. de la Macorra, P. Doel, S. Ferraro, J. E. Forero-Romero, E. Gaztañaga, S. Gontcho A Gontcho, G. Gutierrez, C. Hahn, C. Howlett, M. Ishak, R. Joyce, D. Kirkby, A. Kremin, C. Lamman, M. Landriau, L. Le Guillou, M. Manera, R. Miquel, S. Nadathur, W. J. Percival, F. Prada, I. Pérez-Ràfols, G. Rossi, E. Sanchez, D. Schlegel, M. Schubnell, J. Silber, D. Sprayberry, G. Tarlé, B. A. Weaver, H. Zou</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Cross-correlating galaxy clustering and peculiar velocities on non-linear scales, using HOD and simulation emulators, yields substantially tighter cosmological constraints on parameters like $f\sigma_8$ and $w_0$, despite systematic biases introduced by realistic velocity measurement uncertainties. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We explore the potential of cross-correlating galaxies and peculiar velocities on non-linear scales to enhance cosmological constraints. Leveraging the \textsc{AbacusSummit} simulation suite and the halo occupation distribution (HOD) formalism, we train emulator models to describe the non-linear clustering of galaxies and velocities in redshift space. Our analysis demonstrates that combining galaxy and peculiar velocity clustering, provides tighter constraints on both HOD and cosmological parameters, particularly on $σ_8$ and $w_0$. We further apply our models to realistic mock catalogues, reproducing the expected density and peculiar velocity errors of type-Ia supernovae and Tully-Fisher/fundamental plane measurements for the combined ZTF and DESI measurements. While systematic biases arise in the HOD parameters, the cosmological constraints remain unbiased, yielding $3.8\%$ precision measurement on $fσ_8$ compared to $4.7\%$ using galaxy clustering alone. We demonstrate that, while combining tracers with realistic velocity measurements still yields improvement, the gains are diminished, highlighting the need for further efforts to reduce velocity measurement uncertainties and correct observational systematics on small scales.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.03382" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.03382" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.03382" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 10.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.17</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">2. Degeneracies and modelling choices in double-plane time-delay cosmography
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Daniel Johnson, Pierre Fleury, Martin Millon</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A generalized mass-sheet degeneracy framework for double-plane gravitational lensing explicitly incorporates line-of-sight effects and scaling factor uncertainty, allowing for robust measurements of the Hubble constant ($H_0$) by leveraging the unfolding relation to simplify the time-delay function. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Double-plane gravitational lensing is a rare but increasingly observed phenomenon in which the light from a distant source is lensed by two foreground objects at different redshifts. Such systems can be used to provide simultaneous constraints on the Hubble constant $H_0$ and the dark-energy equation of state, independent of and complementary to other probes. However, just as for single-plane gravitational lenses, the precision of these constraints is limited by the so-called mass-sheet degeneracy (MSD) -- a fundamental limit to the knowledge of the mass profiles of lens galaxies and the line of sight that can be obtained from imaging constraints alone. In this work, we show explicitly how contributions from the line of sight appear in double-plane systems. Because these contributions modify angular diameter distances, we argue that cosmological priors should not be used to simply fix the ``cosmological scaling factor&#39;&#39;, a ratio of angular diameter distances which is key to the modelling of double-plane lenses. Motivated by this fact, we generalise the double-plane MSD to account for this uncertainty in the scaling factor. While this complicates the time-delay function, we show that, using the ``unfolding relation&#39;&#39;, a geometric relation between distances which holds even in the presence of line-of-sight corrections, the uncertainty in the Hubble constant reduces to the familiar mass-sheet transformation of the first lens plane, and a line-of-sight contribution between the observer and the second lens plane. Our main message is therefore a prescription for reducing the degrees of freedom within double-plane models, while still safely accounting for the MSD in measurements of $H_0$.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.02697" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.02697" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.02697" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.5</span>
                        <span class="badge bg-info text-dark">Author Score: 0.01</span>
                        <span class="badge bg-primary">Semantic Score: 0.95</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Weak Lensing, Galaxy Clustering, Cosmology</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">3. Cosmological phase transitions: from particle physics to gravitational waves, semi-analytically
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>S. Pascoli, S. Rosauro-Alcaraz, M. Zandi</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> To efficiently connect particle physics models to cosmological predictions, a semi-analytical method is proposed for calculating the gravitational wave spectrum generated by supercooled first-order phase transitions, bypassing computationally demanding full simulations. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Motivated by the recent evidence of a stochastic gravitational wave background found by pulsar timing array experiments, we focus on one of the prime cosmological explanations, i.e. a supercooled first order phase transition. If confirmed, it would offer a unique opportunity to probe early Universe dynamics and the related physics beyond the Standard Model of particles and interactions. However, the prediction of the gravitational wave spectrum from a given particle physics scenario requires theoretically and computationally demanding methods. While several tools have been put forward to reduce uncertainties and automatize these computations, we study here the possibility to perform the full pipeline of computations semi-analytically in the $4D$ theory, thus avoiding computationally intensive simulations. Our approach yields accurate results that can be used in phenomenological studies and allow for an efficient exploration of the connection between the particle physics models and their cosmological predictions.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.02829" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.02829" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.02829" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.5</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.95</span>
                        
                            <span class="badge bg-secondary">hep-ph</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">4. Constraining cosmological simulations with peculiar velocities: a forward-modeling approach
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Aurélien Valade, Noam Libeskind, Daniel Pomarède, Richard Stiskalek, Yehuda Hoffman, Stefan Gottlöber, R. Brent Tully</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The Hamlet-PM method uses field-level forward modeling of peculiar velocities to constrain initial conditions for cosmological simulations, producing evolved numerical universes that accurately reproduce the Local Universe environment and provide dynamically constrained mass estimates for galaxy clusters. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Numerical simulations are a key tool to decipher the dynamics of gravitation. Yet, they fail to spatially reproduce the Universe we observe, limiting comparison between observations and simulations to a statistical level. This is highly problematic for rare, faint or well studied nearby objects that are observed in a single environment. The computational cost of recovering this environment in random simulations is prohibitive. We present Hamlet-PM, a method that enables the constraining of initial conditions for cosmological simulations so as to produce evolved numerical universes that can be directly compared to observations of the Local Universe: constrained simulations. Our method implements the field-level forward modeling of the early-time density field from sparse and noisy measurements of late-time peculiar velocities. The dynamics are integrated with a particle-mesh gravity solver, thus probing the mildly non-linear regime. The code is applied to the Cosmicflows-4 compilation of peculiar velocities up to z &lt; 0.05 (160 Mpc/h). The constrained ICs a re-simulated with a high precision N-body code. A series of one hundred dark-matter only cosmological constrained simulations with a resolution of 512^3 particles in a 500^3 [Mpc/h]3 box is presented. Special attention is given to twelve prominent nearby galaxy clusters, whose simulated counterparts are matched on criteria of mass and separation. We provide a mass estimate constrained by the dynamical environment for each cluster. Field-level forward modeling of the initial conditions produces highly constrained cosmological simulations. Currently, this method already overtakes in quality the pipeline in use in the peculiar-velocity community, although systematic biases still need to be addressed. Furthermore, improving the model is easy thanks to the inherent flexibility of the Bayesian approach.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.03699" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.03699" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.03699" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.01</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">5. Probing The Dark Matter Halo of High-redshift Quasar from Wide-Field Clustering Analysis
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Hao Meng, Huanian Zhang, Guangping Ye</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Wide-field clustering analysis of high-redshift quasar candidates reveals a dark matter halo mass of approximately $10^{12.2} M_{\odot}$, suggesting a more complex and possibly non-monotonic evolutionary path for quasar host halos than previously observed at similar redshifts. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">High-redshift quasars have been an excellent tracer to study the astrophysics and cosmology at early Universe. Using 216,949 high-redshift quasar candidates ($5.0 \leq z &lt; 6.3$) selected via machine learning from the Legacy Survey Data Release 9 and the Wide-field Infrared Survey Explorer, we perform wide-field clustering analysis to investigate the large-scale environment of those high-redshift quasars. We construct the projected auto correlation function of those high-redshift quasars that is weighted by its predicted probability of being a true high-redshift quasar, from which we derive the bias parameter and the typical dark matter halo mass of those quasars. The dark matter halo mass of quasars estimated from the projected auto correlation function is $\log(M_h/M_{\odot})=12.2 ^{+0.2}_{-0.7}$ ($11.9^{+0.3}_{-0.7}$), with the bias parameter $b$ of $12.34 ^{+4.26}_{-4.37}$ ($11.52^{+4.02}_{-4.14}$) for the redshift interval of $5.0 \leq z &lt;5.7$ ($5.7 \leq z &lt;6.3$). Our results, combined with other measurements of dark matter halo masses for quasars or active galactic nucleus which obtain a lower dark matter halo mass of $\sim 10^{11.5}$ M$_\odot$ at similar redshift, suggest a more complex, and possibly non-monotonic evolution of quasar hosting dark matter halo. Moreover, we estimate the duty cycle of those quasars, which is $0.008^{+0.135}_{-0.007}$ ($0.003+^{+0.047}_{-0.003}$) for the redshift interval of $5.0 \leq z &lt;5.7$ ($5.7 \leq z &lt;6.3$).</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.02778" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.02778" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.02778" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Weak Lensing, Galaxy Clustering, Cosmology / Galaxy Clustering, Weak Lensing, Halo Model</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">6. Structuring Value Representations via Geometric Coherence in Markov Decision Processes
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Zuyuan Zhang, Zeyu Fang, Tian Lan</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> GCR-RL (Geometric Coherence Regularized Reinforcement Learning) leverages order theory to stabilize and accelerate reinforcement learning by enforcing geometric coherence through the iterative refinement of partially ordered sets (posets) underpinning learned value functions. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Geometric properties can be leveraged to stabilize and speed reinforcement learning. Existing examples include encoding symmetry structure, geometry-aware data augmentation, and enforcing structural restrictions. In this paper, we take a novel view of RL through the lens of order theory and recast value function estimates into learning a desired poset (partially ordered set). We propose \emph{GCR-RL} (Geometric Coherence Regularized Reinforcement Learning) that computes a sequence of super-poset refinements -- by refining posets in previous steps and learning additional order relationships from temporal difference signals -- thus ensuring geometric coherence across the sequence of posets underpinning the learned value functions. Two novel algorithms by Q-learning and by actor--critic are developed to efficiently realize these super-poset refinements. Their theoretical properties and convergence rates are analyzed. We empirically evaluate GCR-RL in a range of tasks and demonstrate significant improvements in sample efficiency and stable performance over strong baselines.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.02978" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.02978" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.02978" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling / Neural Architectures, Representation Learning, Generative Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">7. Evidence for a 3.0$σ$ Deviation in Gravitational Light Deflection from General Relativity at Cosmological Scales with KiDS-Legacy and CMB Lensing
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Guo-Hong Du, Tian-Nuo Li, Tonghua Liu, Jing-Fei Zhang, Xin Zhang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Stringent cosmological tests of General Relativity using combined weak lensing, CMB, BAO, and supernova data show consistency with GR for matter clustering ($\mu_0$) but reveal a 3.0$\sigma$ deviation in gravitational light deflection ($\Sigma_0$), highlighting the importance of synergistic high-precision datasets. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">General Relativity (GR) faces challenges from cosmic acceleration and observational tensions, necessitating stringent tests at cosmological scales. In this work, we probe GR deviations via a $μ$-$Σ$ modified gravity parameterization, integrating KiDS-Legacy weak lensing (1347 deg$^2$, $z\leq 2.0$), joint CMB data (Planck/ACT/SPT), DESI DR2 BAO, and DES-Dovekie supernovae. KiDS-Legacy significantly improves constraint precision: $μ_0$ (matter clustering) by $\sim 43\%$ and $Σ_0$ (gravitational light deflection) by $\sim 60\%$ relative to CMB alone. In the $Λ$CDM background, $μ_0 = 0.21\pm 0.21$ is consistent with GR, while $Σ_0 = 0.149\pm 0.051$ deviates from GR at the 3.0$σ$ level -- attributed to large-scale CMB lensing from ACT/SPT. This precise separation of GR-consistent matter clustering and deviant light deflection provides key observational clues for new physics or data systematics. Our work underscores the critical role of synergizing high-precision CMB and WL data in advancing GR tests.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.03110" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.03110" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.03110" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling / Cluster 2</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">8. Line-Intensity Mapping
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Tzu-Ching Chang, Adam Lidz</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Line-Intensity Mapping (LIM) serves as a critical, complementary technique for mapping three-dimensional large-scale structure and probing the high-redshift universe, offering unique insights into galaxy formation, cosmology, and the Epoch of Reionization. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Line-Intensity Mapping (LIM) has emerged as a powerful technique for studying large-scale structure and the high-redshift universe, enabling three-dimensional maps of line emission across vast cosmological volumes. In this review, we summarize the LIM framework, its key scientific goals, and its future prospects. We describe the landscape of emission line tracers, theoretical modeling approaches, anticipated signals, and data-analysis methodologies. We also discuss experimental challenges, particularly those posed by astrophysical foregrounds, and review possible mitigation strategies. Further, we highlight a range of cross-correlation science cases, linking LIM with other cosmological surveys. Finally, we summarize current and upcoming experiments and early results, including recent first detections, while outlining the outlook for future discoveries. Specifically, LIM may offer new insights into galaxy formation and evolution and cosmology, while revealing the Epoch of Reionization, Cosmic Dawn, and possibly the Cosmic Dark Ages. LIM enables cosmological measurements that complement other probes and provide unique access to the high-redshift universe, potentially shedding light on dark matter, dark energy, and cosmic inflation.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.03011" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.03011" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.03011" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">9. Seeing Wiggles without Seeing Wiggles: BAO Recovery in 21 cm Intensity Mapping with Deep Learning
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Kaifeng Yu, Xin Wang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Deep learning successfully reconstructs large-scale features, including Baryon Acoustic Oscillations (BAO), in 21 cm intensity mapping fields by leveraging non-linear mode coupling from short-wavelength data, offering a method to recover cosmological information lost during foreground avoidance. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The 21 cm intensity mapping provides a promising probe of the large-scale structure. Astrophysical foregrounds, as the main source of contamination to the cosmological 21 cm signal, persist in a wedge-like region of Fourier space due to the inherent chromaticity in radio interferometric observations. The foreground avoidance strategy focuses on utilizing data from relatively clean regions with minimal foreground leakage, at the cost of losing large-scale information. Non-linear structure formation, however, couples Fourier modes across scales, leaving imprints of the missing large-scale modes in the remaining data. In this work, we employ a deep learning approach to test whether large-scale features of the 21 cm brightness temperature fields, particularly the baryon acoustic oscillations (BAO), can be recovered at the field level using only short-wavelength modes that are beyond the linear scales. To explicitly assess the dependence on the training cosmology, we train the network exclusively on de-wiggled simulations, providing a controlled test of whether the reconstruction arises from physical non-linear mode coupling rather than implicit encoding of BAO features. In the ideal noise-free case, the amplitude and phase of the lost modes can be restored with high fidelity. With instrumental noise included, the reconstructed amplitude becomes biased, while the phase information remains robust. The trained network also exhibits reasonable robustness to variations in the underlying cosmological model. Together, these results suggest that mode restoration offers a complementary approach for extracting cosmological information from future 21 cm intensity mapping analyses.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.03313" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.03313" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.03313" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">10. STAR: Similarity-guided Teacher-Assisted Refinement for Super-Tiny Function Calling Models
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Jiliang Ni, Jiachen Pu, Zhongyi Yang, Jingfeng Luo, Conggang Hu</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The STAR framework, which employs Constrained Knowledge Distillation and Similarity-guided Reinforcement Learning, efficiently transfers complex function-calling capabilities from large language models to significantly smaller models, achieving state-of-the-art performance and high sample efficiency. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The proliferation of Large Language Models (LLMs) in function calling is pivotal for creating advanced AI agents, yet their large scale hinders widespread adoption, necessitating transferring their capabilities into smaller ones. However, existing paradigms are often plagued by overfitting, training instability, ineffective binary rewards for multi-solution tasks, and the difficulty of synergizing techniques. We introduce STAR: Similarity-guided Teacher-Assisted Refinement, a novel holistic framework that effectively transfers LLMs&#39; capabilities to super-tiny models. STAR consists of two core technical innovations: (1) Constrained Knowledge Distillation (CKD), a training objective that augments top-k forward KL divergence to suppress confidently incorrect predictions, ensuring training stability while preserving exploration capacity for downstream RL. STAR holistically synergizes these strategies within a cohesive training curriculum, enabling super-tiny models to achieve exceptional performance on complex function calling tasks; (2) Similarity-guided RL (Sim-RL), a RL mechanism that introduces a fine-grained, similarity-based reward. This provides a robust, continuous, and rich signal for better policy optimization by evaluating the similarity between generated outputs and the ground truth. Extensive experiments on challenging and renowned benchmarks demonstrate the effectiveness of our method. Our STAR models establish SOTA in their size classes, significantly outperforming baselines. Remarkably, our 0.6B STAR model achieves the best performance among all open models under 1B, surpassing even several well-known open models at a larger scale. STAR demonstrates a training framework that distills capabilities of LLMs into super-tiny models, paving the way for powerful, accessible, and efficient AI agents.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.03022" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.03022" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.03022" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling / Neural Architectures, Representation Learning, Generative Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">11. Probing beyond the Standard Model with gravitational waves from phase transitions
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Chiara Caprini</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Stochastic gravitational wave backgrounds originating from first-order phase transitions in beyond-Standard-Model scenarios are detectable by LISA, offering constraints complementary to particle colliders, even though parameter degeneracies complicate the underlying model reconstruction. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">This review article is based on a seminar presented at the Higgs pairs workshop 2025. Stochastic gravitational wave backgrounds can serve as probe of the diverse phenomenology encountered in beyond-Standard-Model scenarios featuring phase transitions in the early Universe. Focussing on gravitational wave production from first-order phase transitions, we present the main results of a recent analysis by the LISA Cosmology Working Group concerning the detectability of such signals with LISA. Strong degeneracies, both among the parameters controlling the phase transition and between these and the parameters of the beyond-Standard-Model scenario underlying the phase transition, complicate the reconstruction of the model from a potential signal. Nonetheless, once a specific scenario is assumed, LISA observations can supply constraints possibly complementary to those obtainable from present and future particle colliders.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.02861" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.02861" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.02861" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">12. Improving the Linearized Laplace Approximation via Quadratic Approximations
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Pedro Jiménez, Luis A. Ortega, Pablo Morales-Álvarez, Daniel Hernández-Lobato</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The Quadratic Laplace Approximation (QLA) enhances Bayesian uncertainty quantification in deep neural networks by efficiently approximating the second-order factors of the Laplace log-posterior with rank-one factors, yielding more accurate uncertainty estimates than the Linearized Laplace Approximation (LLA) with minimal computational increase. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Deep neural networks (DNNs) often produce overconfident out-of-distribution predictions, motivating Bayesian uncertainty quantification. The Linearized Laplace Approximation (LLA) achieves this by linearizing the DNN and applying Laplace inference to the resulting model. Importantly, the linear model is also used for prediction. We argue this linearization in the posterior may degrade fidelity to the true Laplace approximation. To alleviate this problem, without increasing significantly the computational cost, we propose the Quadratic Laplace Approximation (QLA). QLA approximates each second order factor in the approximate Laplace log-posterior using a rank-one factor obtained via efficient power iterations. QLA is expected to yield a posterior precision closer to that of the full Laplace without forming the full Hessian, which is typically intractable. For prediction, QLA also uses the linearized model. Empirically, QLA yields modest yet consistent uncertainty estimation improvements over LLA on five regression datasets.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.03394" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.03394" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.03394" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">stat.ML</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling / Neural Architectures, Representation Learning, Generative Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">13. Modern Machine Learning and Particle Physics Phenomenology at the LHC
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Maria Ubiali</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Machine learning is fundamentally transforming the theoretical prediction pipeline in particle physics phenomenology at the Large Hadron Collider, with applications spanning scattering amplitude computation, phase space integration, and parameter extraction, while emphasizing the importance of uncertainty quantification and symmetry incorporation. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Modern machine learning is driving a paradigm shift in particle physics phenomenology at the Large Hadron Collider. This short review examines the transformative role of machine learning across the entire theoretical prediction pipeline, from parton-level calculations to full simulations. We discuss applications to scattering amplitude computations, phase space integration, Parton Distribution Function determination, and parameter extraction. Some critical frontiers for the field including uncertainty quantification, the role of symmetries, and interpretability are highlighted.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.03728" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.03728" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.03728" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">hep-ph</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">14. Dynamic Mix Precision Routing for Efficient Multi-step LLM Interaction
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Yuanzhe Li, Jianing Deng, Jingtong Hu, Tianlong Chen, Song Wang, Huanrui Yang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A dynamic mix-precision routing framework, trained using KL-divergence and Group-Relative Policy Optimization, adaptively selects between high- and low-precision quantized large language models at each step of long-horizon decision-making, significantly improving the accuracy-cost trade-off. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Large language models (LLM) achieve strong performance in long-horizon decision-making tasks through multi-step interaction and reasoning at test time. While practitioners commonly believe a higher task success rate necessitates the use of a larger and stronger LLM model, multi-step interaction with a large LLM incurs prohibitive inference cost. To address this problem, we explore the use of low-precision quantized LLM in the long-horizon decision-making process. Based on the observation of diverse sensitivities among interaction steps, we propose a dynamic mix-precision routing framework that adaptively selects between high-precision and low-precision LLMs at each decision step. The router is trained via a two-stage pipeline, consisting of KL-divergence-based supervised learning that identifies precision-sensitive steps, followed by Group-Relative Policy Optimization (GRPO) to further improve task success rates. Experiments on ALFWorld demonstrate that our approach achieves a great improvement on accuracy-cost trade-off over single-precision baselines and heuristic routing methods.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.02711" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.02711" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.02711" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling / Neural Architectures, Representation Learning, Generative Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">15. Near-Universal Multiplicative Updates for Nonnegative Einsum Factorization
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>John Hood, Aaron Schein</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> NNEinFact is an efficient, user-friendly, einsum-based multiplicative update algorithm that allows researchers to fit arbitrary nonnegative tensor factorizations specified by a string, achieving faster convergence and superior predictive performance compared to standard and gradient-based methods. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Despite the ubiquity of multiway data across scientific domains, there are few user-friendly tools that fit tailored nonnegative tensor factorizations. Researchers may use gradient-based automatic differentiation (which often struggles in nonnegative settings), choose between a limited set of methods with mature implementations, or implement their own model from scratch. As an alternative, we introduce NNEinFact, an einsum-based multiplicative update algorithm that fits any nonnegative tensor factorization expressible as a tensor contraction by minimizing one of many user-specified loss functions (including the $(α,β)$-divergence). To use NNEinFact, the researcher simply specifies their model with a string. NNEinFact converges to a local minimum of the loss, supports missing data, and fits to tensors with hundreds of millions of entries in seconds. Empirically, NNEinFact fits custom models which outperform standard ones in heldout prediction tasks on real-world tensor data by over $37\%$ and attains less than half the test loss of gradient-based methods while converging up to 90 times faster.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.02759" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.02759" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.02759" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">stat.ML</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling / Neural Architectures, Representation Learning, Generative Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">16. NeutrinoOsc3Flavor: CP Phase Dependence in Three-Flavor Neutrino Oscillations: A Numerical Study in Vacuum and Matter
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Baktiar Wasir Farooq, Bipin Singh Koranga, Ansh Prasad, Imran Khan</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> NeutrinoOsc3Flavor is a lightweight, transparent, and minimal-dependency computational framework designed for pedagogical use and verification of exact three-flavor neutrino oscillation studies in vacuum and constant density matter, relying on numerical diagonalization and analytical consistency checks. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We present NeutrinoOsc3Flavor, a lightweight and fully transparent computational framework for exact three flavor neutrino oscillation studies in vacuum and constant density matter. The code numerically solves the Schrodinger evolution equation in the flavor basis using explicit construction and diagonalization of the effective Hamiltonian within the PMNS formalism, including full CP Violating phase dependence. In contrast to large scale oscillation toolkits optimized for experimental simulations, NeutrinoOsc3Flavor is designed as a minimal dependency reference implementation, emphasizing analytical traceability, equation level accessibility, and cross platform portability. The framework relies solely on NumPy for numerical linear algebra and runs natively on both Linux and Windows systems without external compilation or specialized libraries. As an internal consistency and validation feature, we implement an independent analytical determination of the matter modified Hamiltonian eigenvalues using the Cardano method and demonstrate excellent agreement with numerical diagonalization. CP Phase dependence is used as a sensitive diagnostic of numerical stability and correctness of the evolution operator in both vacuum and matter. NeutrinoOsc3Flavor is intended as a verification oriented and pedagogical computational tool, suitable for theoretical cross-checks, educational use, and benchmarking of more complex neutrino oscillation software, rather than as a replacement for full experimental simulation frameworks. Here, we consider the DUNE experiments baseline length in the python implementation but in general we can implement any value of baseline length.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.02578" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.02578" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.02578" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">hep-ph</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">17. Enhancing Foundation VLM Robustness to Missing Modality: Scalable Diffusion for Bi-directional Feature Restoration
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Wei Dai, Haoyu Wang, Honghao Chang, Lijun He, Fan Li, Jian Sun, Haixia Bi</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A general missing modality restoration strategy for Vision Language Models utilizes an enhanced diffusion model with Dynamic Modality Gating and Cross-Modal Mutual Learning to effectively restore semantically consistent features, significantly improving VLM reliability and generalization in incomplete input scenarios. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Vision Language Models (VLMs) typically assume complete modality input during inference. However, their effectiveness drops sharply when certain modalities are unavailable or incomplete. Current research primarily faces two dilemmas: Prompt-based methods struggle to restore missing yet indispensable features and impair generalization of VLMs. Imputation-based approaches, lacking effective guidance, are prone to generating semantically irrelevant noise. Restoring precise semantics while sustaining VLM generalization remains challenging. Therefore, we propose a general missing modality restoration strategy in this paper. We introduce an enhanced diffusion model as a pluggable mid-stage training module to effectively restore missing features. Our strategy introduces two key innovations: (I) Dynamic Modality Gating, which adaptively leverages conditional features to steer the generation of semantically consistent features; (II) Cross-Modal Mutual Learning mechanism, which bridges the semantic spaces of dual encoders to achieve bidirectional alignment. Zero-shot evaluations across benchmark datasets demonstrate that our approach outperforms existing baseline methods. Extensive experiments and ablation studies confirm our model as a robust and scalable extension for VLMs in missing modality scenarios, ensuring reliability across diverse missing rates and environments. Our code and models will be publicly available.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.03151" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.03151" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.03151" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling / Neural Architectures, Representation Learning, Generative Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">18. Exact Bachian singularity in quadratic gravity
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Simon Knoska, David Kofron, Robert Svarc</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A fully explicit static spherically symmetric solution is derived for specifically coupled quadratic gravity parameters, revealing the global geometric structure—a central singularity surrounded by a black hole or cosmological horizon—and serving as a robust benchmark for evaluating approximation methods. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">For specifically coupled values of the quadratic gravity parameters, we present a fully explicit static spherically symmetric solution. It contains the central singularity surrounded by the black-hole or the cosmological horizon for the negative or positive cosmological parameter, respectively. This spacetime, thus, belongs to the already analyzed classes of solutions expressed in terms of the Frobenius expansions, continuous fractions, or numerical simulations; however, it has not been explicitly identified before. The purpose of the presented highly-constrained somehow unphysical model is to reveal a global geometric picture that may occur in spherical spacetimes within quadratic gravity, which is typically hidden in more general approximative solutions. At the same time, it can serve as a solid benchmark for evaluating the accuracy of the methods employed to obtain such solutions.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.02840" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.02840" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.02840" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">gr-qc</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">19. Non-Singular Bouncing cosmology from Phantom Scalar-Gauss-Bonnet Coupling: Reconstruction with Observational Insights
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Khandro K. Chokyi, Surajit Chattopadhyay</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Non-singular bounce cosmology, modeled by a phantom scalar field coupled to the Gauss-Bonnet term, demonstrates observational viability confirmed by cosmological data, with bulk viscosity playing a crucial role in stabilizing post-bounce dynamics and ensuring a smooth, positive squared speed of sound. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We examine non-singular bounce cosmology within the framework of a phantom scalar field coupled to the Gauss-Bonnet term in both non-viscous and bulk-viscous cases. Using the scale factor ansatz $α(t)=\left(\fracαη+t^2\right)^{\frac{1}{2 η}}$, we reconstruct the scalar field potential $V(t)$, and observe a smooth potential well centered at the bounce point. The resulting energy density, pressure, and equation-of-state parameter show NEC violation necessary for successful bounce, while viscosity controls post-bounce dynamics with a positive and smooth squared speed of sound. In contrast, for the non-viscous model, sharp divergences occur just at the bounce and continues to be negative in the expanding phase, which in turn emphasises the stabilising role of dissipative effects. The energy condition analysis indicates a temporary NEC and SEC violation in the viscous scenario, whereas its persistent violation within the non-viscous model suggests a continuous accelerated expansion. Observational viability is found through Bayesian MCMC fitting in regards to the Pantheon+ supernova data, with best-fit parameters providing a reduced chi-squared of $χ_{red}^2 =0.995$ while the inflation observables derived from the reconstructed potential place our model predictions inside $68\%$ CL Planck 2018 confidence contours. Our findings suggest that bounce cosmologies could offer a physically reasonable and observationally acceptable alternative or pre-inflationary scenario, while highlighting the role that viscosity could play for a stable and smooth cosmological evolution.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.02608" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.02608" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.02608" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">20. Fast Sampling for Flows and Diffusions with Lazy and Point Mass Stochastic Interpolants
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Gabriel Damsholt, Jes Frellsen, Susanne Ditlevsen</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Extending the stochastic interpolant framework allows for conversion between arbitrary schedules and diffusion coefficients, enabling the identification of &#34;lazy schedule families&#34; that minimize drift and facilitating the generation of high-quality images in fewer steps using pretrained flow models without requiring retraining. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Stochastic interpolants unify flows and diffusions, popular generative modeling frameworks. A primary hyperparameter in these methods is the interpolation schedule that determines how to bridge a standard Gaussian base measure to an arbitrary target measure. We prove how to convert a sample path of a stochastic differential equation (SDE) with arbitrary diffusion coefficient under any schedule into the unique sample path under another arbitrary schedule and diffusion coefficient. We then extend the stochastic interpolant framework to admit a larger class of point mass schedules in which the Gaussian base measure collapses to a point mass measure. Under the assumption of Gaussian data, we identify lazy schedule families that make the drift identically zero and show that with deterministic sampling one gets a variance-preserving schedule commonly used in diffusion models, whereas with statistically optimal SDE sampling one gets our point mass schedule. Finally, to demonstrate the usefulness of our theoretical results on realistic highly non-Gaussian data, we apply our lazy schedule conversion to a state-of-the-art pretrained flow model and show that this allows for generating images in fewer steps without retraining the model.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.03789" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.03789" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.03789" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">stat.ML</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling / Neural Architectures, Representation Learning, Generative Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">21. Rethinking Test-Time Training: Tilting The Latent Distribution For Few-Shot Source-Free Adaptation
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Tahir Qasim Syed, Behraj Khan</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A novel training-free inference method uses KL-optimal exponential tilting over latent embeddings to adapt frozen foundation models for few-shot classification, achieving competitive performance under strictly constrained deployment settings. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Often, constraints arise in deployment settings where even lightweight parameter updates e.g. parameter-efficient fine-tuning could induce model shift or tuning instability. We study test-time adaptation of foundation models for few-shot classification under a completely frozen-model regime, where additionally, no upstream data are accessible. We propose arguably the first training-free inference method that adapts predictions to the new task by performing a change of measure over the latent embedding distribution induced by the encoder. Using task-similarity scores derived from a small labeled support set, exponential tilting reweights latent distributions in a KL-optimal manner without modifying model parameters. Empirically, the method consistently competes with parameter-update-based methods across multiple benchmarks and shot regimes, while operating under strictly and universally stronger constraints. These results demonstrate the viability of inference-level distributional correction for test-time adaptation even with a fully-frozen model pipeline.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.02633" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.02633" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.02633" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">stat.ML</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling / Neural Architectures, Representation Learning, Generative Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">22. Convolutional Neural Networks for classifying galaxy mergers: Can faint tidal features aid in classifying mergers?
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Yeonkyung Lee, Hyunmi Song, Jihye Shin, Sungryong Hong, Jaehyun Lee, Kyungwon Chun</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A convolutional neural network trained on Illustris TNG50 mock data achieved 67–70% accuracy in distinguishing galaxy mergers from non-mergers in LSST-like deep images, demonstrating that faint tidal features are crucial indicators for classification. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Identifying mergers from observational data has been a crucial aspect of studying galaxy evolution and formation. Tidal features, typically fainter than 26 ${\rm mag\,arcsec^{-2}}$, exhibit a diverse range of appearances depending on the merger characteristics and are expected to be investigated in greater detail with the Rubin Observatory Large Synoptic Survey Telescope (LSST), which will reveal the low surface brightness universe with unprecedented precision. Our goal is to assess the feasibility of developing a convolutional neural network (CNN) that can distinguish between mergers and non-mergers based on LSST-like deep images. To this end, we used Illustris TNG50, one of the highest-resolution cosmological hydrodynamic simulations to date, allowing us to generate LSST-like mock images with a depth $\sim$ 29 ${\rm mag\,arcsec^{-2}}$ for low-redshift ($z=0.16$) galaxies, with labeling based on their merger status as ground truth. We focused on 151 Milky Way-like galaxies in field environments, comprising 81 non-mergers and 70 mergers. After applying data augmentation and hyperparameter tuning, a CNN model was developed with an accuracy of 65--67\%. Through additional image processing, the model was further optimized, achieving an accuracy of 67--70\% when trained on images containing only faint features. This represents an improvement of $\sim$ 5\% compared to training on images with bright features only. This suggests that faint tidal features can serve as effective indicators for distinguishing between mergers and non-mergers. The future direction for further improvement based on this study is also discussed.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.03312" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.03312" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.03312" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">23. Distilling LLM Reasoning into Graph of Concept Predictors
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Ziyang Yu, Liang Zhao</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The Graph of Concept Predictors (GCP) framework enhances active distillation of Large Language Models by mirroring the teacher&#39;s reasoning process as a directed acyclic graph, improving sample efficiency and interpretability through targeted uncertainty sampling and sub-module retraining. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Deploying Large Language Models (LLMs) for discriminative workloads is often limited by inference latency, compute, and API costs at scale. Active distillation reduces these costs by querying an LLM oracle to train compact discriminative students, but most pipelines distill only final labels, discarding intermediate reasoning signals and offering limited diagnostics of what reasoning is missing and where errors arise. We propose Graph of Concept Predictors (GCP), a reasoning-aware active distillation framework that externalizes the teacher&#39;s decision process as a directed acyclic graph and mirrors it with modular concept predictors in the student. GCP enhances sample efficiency through a graph-aware acquisition strategy that targets uncertainty and disagreement at critical reasoning nodes. Additionally, it improves training stability and efficiency by performing targeted sub-module retraining, which attributes downstream loss to specific concept predictors and updates only the most influential modules. Experiments on eight NLP classification benchmarks demonstrate that GCP enhances performance under limited annotation budgets while yielding more interpretable and controllable training dynamics. Code is available at: https://github.com/Ziyang-Yu/GCP.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.03006" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.03006" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.03006" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling / Neural Architectures, Representation Learning, Generative Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">24. Generator-based Graph Generation via Heat Diffusion
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Anthony Stephenson, Ian Gallagher, Christopher Nemeth</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A novel graph generative framework adapts Generator Matching by defining a continuous-time diffusion via the graph Laplacian, allowing a neural network to learn the generator and simulate a time-reversed process for effective graph structure sampling. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Graph generative modelling has become an essential task due to the wide range of applications in chemistry, biology, social networks, and knowledge representation. In this work, we propose a novel framework for generating graphs by adapting the Generator Matching (arXiv:2410.20587) paradigm to graph-structured data. We leverage the graph Laplacian and its associated heat kernel to define a continous-time diffusion on each graph. The Laplacian serves as the infinitesimal generator of this diffusion, and its heat kernel provides a family of conditional perturbations of the initial graph. A neural network is trained to match this generator by minimising a Bregman divergence between the true generator and a learnable surrogate. Once trained, the surrogate generator is used to simulate a time-reversed diffusion process to sample new graph structures. Our framework unifies and generalises existing diffusion-based graph generative models, injecting domain-specific inductive bias via the Laplacian, while retaining the flexibility of neural approximators. Experimental studies demonstrate that our approach captures structural properties of real and synthetic graphs effectively.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.03612" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.03612" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.03612" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">stat.ML</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling / Neural Architectures, Representation Learning, Generative Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">25. Training-Free Self-Correction for Multimodal Masked Diffusion Models
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Yidong Ouyang, Panwen Hu, Zhengyan Wan, Zhe Wang, Liyan Xie, Dmitriy Bespalov, Ying Nian Wu, Guang Cheng, Hongyuan Zha, Qiang Sun</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A training-free self-correction framework leverages the inherent inductive biases of pre-trained masked diffusion models to mitigate error accumulation, significantly enhancing generation quality and reducing sampling steps in text-to-image and multimodal tasks. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Masked diffusion models have emerged as a powerful framework for text and multimodal generation. However, their sampling procedure updates multiple tokens simultaneously and treats generated tokens as immutable, which may lead to error accumulation when early mistakes cannot be revised. In this work, we revisit existing self-correction methods and identify limitations stemming from additional training requirements or reliance on misaligned likelihood estimates. We propose a training-free self-correction framework that exploits the inductive biases of pre-trained masked diffusion models. Without modifying model parameters or introducing auxiliary evaluators, our method significantly improves generation quality on text-to-image generation and multimodal understanding tasks with reduced sampling steps. Moreover, the proposed framework generalizes across different masked diffusion architectures, highlighting its robustness and practical applicability. Code can be found in https://github.com/huge123/FreeCorrection.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.02927" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.02927" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.02927" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">stat.ML</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling / Neural Architectures, Representation Learning, Generative Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">26. Search for Faint Lone Double-Peaked H$α$ Lines as IMBH Signatures in the MUSE Deep Field
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Jyoti Yadav, Jorge Sánchez Almeida, Casiana Muñoz Tuñón, João Calhau</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Reanalysis of the MUSE Extremely Deep Field data using an automated detection algorithm failed to recover the previously reported population of double-peaked Hα sources interpreted as wandering intermediate-mass black holes, resulting in a null detection that informs future systematic searches.</p>
                </div>
                <div class="arxiv-abstract-text">Double-peaked H$α$ emission profiles can serve as potential signatures of accreting intermediate-mass black holes (IMBHs), particularly those residing outside galactic nuclei. Such features are expected to arise from rotating disk-like structures around black holes and can be used to identify elusive IMBH candidates. \citet{Almeida2022ApJ...934..100S} reported a sample of such double-peaked H$α$ sources in the MUSE-Wide survey, interpreting them as potential signatures of wandering IMBHs after systematically excluding alternative explanations. Their method relied on constructing H$α$ maps around central galaxies and visually identifying compact emission clumps in the surrounding halo regions. In this work, we revisit the analysis using the deeper MUSE Extremely Deep Field (MXDF) data and an automated detection algorithm tailored to identify such features. However, we do not recover any candidate population in MXDF, resulting in a null detection. This outcome is nevertheless informative, as it (1) highlights the inherent challenges in detecting IMBHs, and (2) demonstrates the potential of automated approaches for future systematic searches, even though it did not yield a positive outcome in this case.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.02705" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.02705" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.02705" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">27. Optimal neural network approximation of smooth compositional functions on sets with low intrinsic dimension
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Thomas Nagler, Sophie Langer</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Deep ReLU networks achieve minimax-optimal uniform approximation rates for smooth functions on low Minkowski dimension sets and exhibit improved convergence rates for empirical risk minimization by adapting to compositional structure and intrinsic dimensionality. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We study approximation and statistical learning properties of deep ReLU networks under structural assumptions that mitigate the curse of dimensionality. We prove minimax-optimal uniform approximation rates for $s$-Hölder smooth functions defined on sets with low Minkowski dimension using fully connected networks with flexible width and depth, improving existing results by logarithmic factors even in classical full-dimensional settings. A key technical ingredient is a new memorization result for deep ReLU networks that enables efficient point fitting with dense architectures. We further introduce a class of compositional models in which each component function is smooth and acts on a domain of low intrinsic dimension. This framework unifies two common assumptions in the statistical learning literature, structural constraints on the target function and low dimensionality of the covariates, within a single model. We show that deep networks can approximate such functions at rates determined by the most difficult function in the composition. As an application, we derive improved convergence rates for empirical risk minimization in nonparametric regression that adapt to smoothness, compositional structure, and intrinsic dimensionality.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.03539" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.03539" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.03539" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">math.ST</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling / Neural Architectures, Representation Learning, Generative Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">28. Novel exact black hole solution in Dehnen $\left(1,4,\frac32\right)$ halo thermodynamics, photon circular motion and eikonal quasinormal modes
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>David Senjaya, Thanaporn Chuensuksan, Supakchai Ponglertsakul</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A novel exact black hole solution embedded in the Dehnen dark matter halo demonstrates that the halo stabilizes the black hole, induces thermodynamic phase transitions, and modifies null geodesics, resulting in observable changes to the black hole shadow radius. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Dehnen $(1,4,\frac32)$ dark matter halo has been proven to be a valuable model for describing the surface brightness distributions of elliptical galaxies, yet its implications for black hole spacetimes remain largely unexplored. In this work, we construct a novel exact black hole solution embedded in this Dehnen halo and investigate its physical consequences. The influence of the halo on black hole thermodynamics is analyzed through the mass function, entropy, Hawking temperature, heat capacity, and Gibbs free energy, allowing us to assess both local and global thermodynamic stability of the black hole-dark matter system. Our results show that the presence of a Dehnen-type halo not only stabilizes the otherwise thermodynamically unstable Schwarzschild black hole but also induces phase transitions. In addition, we study null geodesics to examine photon motion, the shadow radius and the optical appearance of the system. The dark matter halo modifies the effective potential, leading to observable changes in the photon sphere and the apparent size of the shadow. We also explore the instability of circular null geodesics and its relation to quasinormal modes in an eikonal limit. These findings highlight the significant role of realistic dark matter distributions in shaping both the thermodynamic behavior and the observable signatures of black holes, providing further insight into the interplay between dark matter halos and central black holes in galaxies.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.03349" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.03349" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.03349" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">gr-qc</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">29. ExoDNN: Boosting exoplanet detection with artificial intelligence. Application to Gaia Data Release 3
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>A. Abreu, J. Lillo-Box, A. M. Perez-Garcia, J. Sahlmann, J. H. J. de Bruijne, C. Cifuentes</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Combining Gaia DR3 astrometric fit quality statistics with a deep neural network (ExoDNN) generated a list of 7414 candidate stars hosting unresolved companions, enhancing the statistical census of substellar objects in poorly constrained orbital regimes. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We combine Gaia Data Release 3 and artificial intelligence to enhance the current statistics of substellar companions, particularly within regions of the orbital period vs. mass parameter space that remain poorly constrained by the radial velocity and transit detection methods. Using supervised learning, we train a deep neural network to recognise the characteristic distribution of the fit quality statistics corresponding to a Gaia DR3 astrometric solution for a non single star. We generate a deep learning model, ExoDNN, which predicts the probability of a DR3 source to host unresolved companions based on those fit quality statistics. Applying the predictive capability of ExoDNN to a volume limited sample of F,G,K and M stars from Gaia DR3, we have produced a list of 7414 candidate stars hosting companions. The stellar properties of these candidates, such as their mass and metallicity, are similar to those of the Gaia DR3 non single star sample. We also identify synergies with future observatories, such as PLATO, and we propose a follow up strategy with the intention of investigating the most promising candidates among those samples.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.02910" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.02910" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.02910" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">astro-ph.EP</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">30. Thurston geometries and parameter constraints from SNIa data
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Tanay Gupta, Anshul Verma, Sukanta Panda, Pavan K. Aluri</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Extending the standard cosmological model to anisotropic Thurston geometries, constrained by Pantheon+ and SH0ES Type Ia supernova data, reveals mild evidence for large-scale cosmic isotropy violation. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Following the numerous evidence for large-scale cosmic isotropy violation with the advent of the `precision cosmology&#39; era, we explore the possible advantages of extending the flat $Λ$CDM model to more general models in order to constrain anisotropies in the universe, otherwise absent in the standard model based on FLRW spacetime. Such extensions are offered by the topologically unique Thurston geometries, which are homogeneous but anisotropic spacetime models. In this work, we attempt to distinguish Thurston geometries from one another by introducing anisotropies via different scale factors in different directions, thereby introducing additional model parameters such as shear, eccentricity, curvature, and a preferred axis. We used the latest compilation of Pantheon+ \&amp; SH0ES Type Ia supernova data for deriving model constraints, and found mild evidence of large-scale isotropy violation.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.02936" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.02936" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.02936" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">gr-qc</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">31. Observational signatures of charged Bardeen black holes in perfect fluid dark matter with a cloud of strings
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Faizuddin Ahmed, Ahmad Al-Badawi, İzzet Sakallı</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A charged Bardeen black hole model incorporating perfect fluid dark matter and a cloud of strings reveals that these two components distinctly influence observables like the black hole shadow, QPOs, and scalar field perturbations, suggesting a pathway for independent observational constraints. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We construct a charged Bardeen black hole (BH) surrounded by perfect fluid dark matter (PFDM) and coupled to a cloud of strings (CS). The metric function combines the magnetic monopole charge from nonlinear electrodynamics, the PFDM logarithmic correction, and the CS parameter that renders the spacetime asymptotically non-flat. We analyze the horizon structure, identifying parameter ranges yielding non-extremal BHs, extremal configurations, and naked singularities. The null geodesics, photon sphere radius, and shadow are computed, revealing that both CS and PFDM enlarge the shadow. For neutral particle dynamics, we derive the specific energy, angular momentum, and innermost stable circular orbit location. Quasiperiodic oscillations (QPOs) are examined through the azimuthal, radial, and vertical epicyclic frequencies, where notably the azimuthal frequency is independent of the CS parameter. Scalar field perturbations governed by the Klein-Gordon equation yield an effective potential whose peak decreases with both parameters, yet the transmission and reflection probabilities respond oppositely to CS and PFDM variations. The greybody factor bounds are obtained using semi-analytical methods. Our results demonstrate that the distinct effects of $α$ and $β$ on various observables could allow independent constraints on these parameters through shadow measurements, QPO timing, and gravitational wave ringdown observations.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.02586" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.02586" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.02586" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">gr-qc</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">32. Probing the Charged Hayward Black Hole in Dark Matter and String Cloud Environments through Shadow, Geodesics, and Quasinormal Spectrum
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Faizuddin Ahmed, Ahmad Al-Badawi, İzzet Sakallı</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A charged Bardeen black hole model incorporating perfect fluid dark matter and a cloud of strings reveals that these two components distinctly influence observables like the black hole shadow, QPOs, and scalar field perturbations, suggesting a pathway for independent observational constraints. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We construct a charged Bardeen black hole (BH) surrounded by perfect fluid dark matter (PFDM) and coupled to a cloud of strings (CS). The metric function combines the magnetic monopole charge from nonlinear electrodynamics, the PFDM logarithmic correction, and the CS parameter that renders the spacetime asymptotically non-flat. We analyze the horizon structure, identifying parameter ranges yielding non-extremal BHs, extremal configurations, and naked singularities. The null geodesics, photon sphere radius, and shadow are computed, revealing that both CS and PFDM enlarge the shadow. For neutral particle dynamics, we derive the specific energy, angular momentum, and innermost stable circular orbit location. Quasiperiodic oscillations (QPOs) are examined through the azimuthal, radial, and vertical epicyclic frequencies, where notably the azimuthal frequency is independent of the CS parameter. Scalar field perturbations governed by the Klein-Gordon equation yield an effective potential whose peak decreases with both parameters, yet the transmission and reflection probabilities respond oppositely to CS and PFDM variations. The greybody factor bounds are obtained using semi-analytical methods. Our results demonstrate that the distinct effects of $α$ and $β$ on various observables could allow independent constraints on these parameters through shadow measurements, QPO timing, and gravitational wave ringdown observations.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.02621" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.02621" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.02621" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">gr-qc</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">33. Generalized Neutrino Interactions: constraints and parametrizations
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>L. J. Flore, O. G. Miranda, G. Sanchez Garcia</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Analyzing Generalized Neutrino Interactions, bounds derived from COHERENT CEvNS measurements are found to be more restrictive for scalar interactions, while deep-inelastic scattering provides stronger constraints on tensor interactions, demonstrating the complementarity of low- and high-energy experiments. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Generalized neutrino interactions (GNI) are emerging as a convenient framework for describing effective scalar, vector, and tensor interactions. Such interactions arise naturally from extensions of the Standard Model that aim to explain neutrino properties and their mass origin. In this paper, we carefully study the two more common parametrizations for GNI and how to relate them. This allows us to compare bounds obtained from CEvNS and deep-inelastic scattering under the same footing. In addition, we present the current bounds from CEvNS measurements by COHERENT and compare them to those obtained from deep inelastic scattering on the same level. Our results focus on neutrino-quark interactions, and illustrate the complementarity between experiments working at different scales for GNI, showing that scalar interactions are better constrained by low-energy experiments like COHERENT, while tensor interactions are robustly constrained from deep inelastic scattering.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.02688" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.02688" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.02688" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">hep-ph</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">34. CRL-VLA: Continual Vision-Language-Action Learning
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Qixin Zeng, Shuo Zhang, Hongyin Zhang, Renjie Wang, Han Zhao, Libang Zhao, Runze Li, Donglin Wang, Chao Huang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The CRL-VLA framework resolves the stability-plasticity dilemma in continual reinforcement learning for Vision-Language-Action models by employing asymmetric advantage regulation and a dual-critic architecture with Goal-Conditioned Value Formulation, leading to improved skill retention and adaptation in robotic manipulation tasks. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Lifelong learning is critical for embodied agents in open-world environments, where reinforcement learning fine-tuning has emerged as an important paradigm to enable Vision-Language-Action (VLA) models to master dexterous manipulation through environmental interaction. Thus, Continual Reinforcement Learning (CRL) is a promising pathway for deploying VLA models in lifelong robotic scenarios, yet balancing stability (retaining old skills) and plasticity (learning new ones) remains a formidable challenge for existing methods. We introduce CRL-VLA, a framework for continual post-training of VLA models with rigorous theoretical bounds. We derive a unified performance bound linking the stability-plasticity trade-off to goal-conditioned advantage magnitude, scaled by policy divergence. CRL-VLA resolves this dilemma via asymmetric regulation: constraining advantage magnitudes on prior tasks while enabling controlled growth on new tasks. This is realized through a simple but effective dual-critic architecture with novel Goal-Conditioned Value Formulation (GCVF), where a frozen critic anchors semantic consistency and a trainable estimator drives adaptation. Experiments on the LIBERO benchmark demonstrate that CRL-VLA effectively harmonizes these conflicting objectives, outperforming baselines in both anti-forgetting and forward adaptation.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.03445" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.03445" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.03445" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling / Neural Architectures, Representation Learning, Generative Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">35. Plug-In Classification of Drift Functions in Diffusion Processes Using Neural Networks
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Yuzhen Zhao, Jiarong Fan, Yating Liu</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A neural network-based plug-in classifier is proposed for supervised multiclass classification of multidimensional diffusion processes, achieving faster convergence rates and superior performance by explicitly estimating class-specific drift functions and leveraging the underlying diffusion model structure. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We study a supervised multiclass classification problem for diffusion processes, where each class is characterized by a distinct drift function and trajectories are observed at discrete times. Extending the one-dimensional multiclass framework of Denis et al. (2024) to multidimensional diffusions, we propose a neural network-based plug-in classifier that estimates the drift functions for each class from independent sample paths and assigns labels based on a Bayes-type decision rule. Under standard regularity assumptions, we establish convergence rates for the excess misclassification risk, explicitly capturing the effects of drift estimation error and time discretization. Numerical experiments demonstrate that the proposed method achieves faster convergence and improved classification performance compared to Denis et al. (2024) in the one-dimensional setting, remains effective in higher dimensions when the underlying drift functions admit a compositional structure, and consistently outperforms direct neural network classifiers trained end-to-end on trajectories without exploiting the diffusion model structure.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.02791" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.02791" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.02791" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">stat.ML</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling / Neural Architectures, Representation Learning, Generative Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">36. JWST imaging of the Pleiades: anisotropy of turbulence in the cold neutral medium
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">G. Vigoureux, N. Flagey, F. Boulanger, A. Noriega-Crespo, V. Guillet, A. J. Alvarez-Castro, N. deJesus-Rivera, E. Allys, J. M. Delouis, E. Falgarone, et al.</span>
                                <span class="author-full" style="display: none;">G. Vigoureux, N. Flagey, F. Boulanger, A. Noriega-Crespo, V. Guillet, A. J. Alvarez-Castro, N. deJesus-Rivera, E. Allys, J. M. Delouis, E. Falgarone, B. Godard, P. Guillard, F. Levrier, P. Lesaffre, A. Marcowith, M. A. Miville-Deschênes, G. Pineau des Forêts</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> High-resolution JWST observations of PAH emission in the Pleiades nebula reveal highly anisotropic, break-free power spectra consistent with power-law indices of -3.5 and -3, suggesting that the turbulent energy cascade in the cold neutral medium is anisotropic and potentially driven by the cluster stars. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Interstellar medium studies rely on magnetohydrodynamic (MHD) turbulence as a framework for interpretation. In this context, the statistical characterization of interstellar observations is of prime importance. We open a new perspective on diffuse interstellar matter by analyzing James Webb Space Telescope (JWST) observations of the Pleiades nebula with NIRCam. These observations are remarkable in that they provide a microscope view at the cold neutral medium (CNM) with a spatial resolution of 0.2 mpc (40 au). A two-dimensional Fourier analysis is used to characterize the structure of PAH emission in regions near and far from the Pleiades star Merope. To produce maps of the interstellar emission, stars and galaxies are filtered out. The final step in the data cleaning involves subtracting a component, in Fourier space, which we infer to be a residual of the near-infrared cosmic background. The PAH emission power spectra are highly anisotropic. They are well fitted with a break-free power-law, suggesting that we do not observe a specific scale for energy dissipation. Power-law indices are -3.5 near Merope and -3 in the more distant field. The magnetic field orientation, as derived from the Planck dust polarization data, aligns with the PAH anisotropy. The power anisotropy is constant across scales. These findings are discussed in relation to interstellar turbulence that may be driven by the Pleiades stars. The JWST observations of the Pleiades offer a new viewpoint for comparing observations and theoretical models, as they examine physical scales at which turbulence in the CNM is subsonic and decoupled from the thermal instability. The observations may indicate that the turbulent energy cascade in the CNM is anisotropic.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.03672" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.03672" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.03672" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Weak Lensing, Galaxy Clustering, Cosmology / Galaxy Clustering, Weak Lensing, Halo Model</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">37. Accordion-Thinking: Self-Regulated Step Summaries for Efficient and Readable LLM Reasoning
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Zhicheng Yang, Zhijiang Guo, Yinya Huang, Yongxin Wang, Wenlei Shi, Yiwei Wang, Xiaodan Liang, Jing Tang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Accordion-Thinking enables Large Language Models to self-regulate reasoning granularity through dynamic summarization, allowing for efficient context compression that maintains solution quality while significantly reducing token overhead and increasing inference throughput. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Scaling test-time compute via long Chain-ofThought unlocks remarkable gains in reasoning capabilities, yet it faces practical limits due to the linear growth of KV cache and quadratic attention complexity. In this paper, we introduce Accordion-Thinking, an end-to-end framework where LLMs learn to self-regulate the granularity of the reasoning steps through dynamic summarization. This mechanism enables a Fold inference mode, where the model periodically summarizes its thought process and discards former thoughts to reduce dependency on historical tokens. We apply reinforcement learning to incentivize this capability further, uncovering a critical insight: the accuracy gap between the highly efficient Fold mode and the exhaustive Unfold mode progressively narrows and eventually vanishes over the course of training. This phenomenon demonstrates that the model learns to encode essential reasoning information into compact summaries, achieving effective compression of the reasoning context. Our Accordion-Thinker demonstrates that with learned self-compression, LLMs can tackle complex reasoning tasks with minimal dependency token overhead without compromising solution quality, and it achieves a 3x throughput while maintaining accuracy on a 48GB GPU memory configuration, while the structured step summaries provide a human-readable account of the reasoning process.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.03249" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.03249" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.03249" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling / Neural Architectures, Representation Learning, Generative Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">38. UAT-LITE: Inference-Time Uncertainty-Aware Attention for Pretrained Transformers
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Elias Hossain, Shubhashis Roy Dipta, Subash Neupane, Rajib Rana, Ravid Shwartz-Ziv, Ivan Garibay, Niloofar Yousefi</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> UAT-LITE enhances the calibration and robustness of pretrained transformer classifiers by employing Monte Carlo dropout during inference to estimate token-level epistemic uncertainty, which is then used to modulate self-attention without requiring changes to the training process or model weights. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Neural NLP models are often miscalibrated, assigning high confidence to incorrect predictions, which undermines selective prediction and high-stakes deployment. Post-hoc calibration methods adjust output probabilities but leave internal computation unchanged, while ensemble and Bayesian approaches improve uncertainty at substantial training or storage cost. We propose UAT-LITE, an inference-time framework that makes self-attention uncertainty-aware using approximate Bayesian inference via Monte Carlo dropout in pretrained transformer classifiers. Token-level epistemic uncertainty is estimated from stochastic forward passes and used to modulate self-attention during contextualization, without modifying pretrained weights or training objectives. We additionally introduce a layerwise variance decomposition to diagnose how predictive uncertainty accumulates across transformer depth. Across the SQuAD 2.0 answerability, MNLI, and SST-2, UAT-LITE reduces Expected Calibration Error by approximately 20% on average relative to a fine-tuned BERT-base baseline while preserving task accuracy, and improves selective prediction and robustness under distribution shift.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.02952" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.02952" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.02952" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling / Neural Architectures, Representation Learning, Generative Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">39. Building Interpretable Models for Moral Decision-Making
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Mayank Goel, Aritra Das, Paras Chopra</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A small, custom transformer model trained on structured moral dilemma scenarios achieves 77% accuracy and, through interpretability analysis, reveals that moral reasoning biases localize to specific computational stages within the network architecture. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We build a custom transformer model to study how neural networks make moral decisions on trolley-style dilemmas. The model processes structured scenarios using embeddings that encode who is affected, how many people, and which outcome they belong to. Our 2-layer architecture achieves 77% accuracy on Moral Machine data while remaining small enough for detailed analysis. We use different interpretability techniques to uncover how moral reasoning distributes across the network, demonstrating that biases localize to distinct computational stages among other findings.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.03351" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.03351" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.03351" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling / Neural Architectures, Representation Learning, Generative Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">40. Search-R2: Enhancing Search-Integrated Reasoning via Actor-Refiner Collaboration
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Bowei He, Minda Hu, Zenan Xu, Hongru Wang, Licheng Zong, Yankai Chen, Chen Ma, Xue Liu, Pluto Zhou, Irwin King</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Search-R2, an Actor-Refiner collaboration framework, improves search-integrated reasoning in language agents by using a Meta-Refiner to selectively repair flawed steps and employing a hybrid reward system that combines outcome correctness with a dense process reward quantifying retrieved evidence density. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Search-integrated reasoning enables language agents to transcend static parametric knowledge by actively querying external sources. However, training these agents via reinforcement learning is hindered by the multi-scale credit assignment problem: existing methods typically rely on sparse, trajectory-level rewards that fail to distinguish between high-quality reasoning and fortuitous guesses, leading to redundant or misleading search behaviors. To address this, we propose Search-R2, a novel Actor-Refiner collaboration framework that enhances reasoning through targeted intervention, with both components jointly optimized during training. Our approach decomposes the generation process into an Actor, which produces initial reasoning trajectories, and a Meta-Refiner, which selectively diagnoses and repairs flawed steps via a &#39;cut-and-regenerate&#39; mechanism. To provide fine-grained supervision, we introduce a hybrid reward design that couples outcome correctness with a dense process reward quantifying the information density of retrieved evidence. Theoretically, we formalize the Actor-Refiner interaction as a smoothed mixture policy, proving that selective correction yields strict performance gains over strong baselines. Extensive experiments across various general and multi-hop QA datasets demonstrate that Search-R2 consistently outperforms strong RAG and RL-based baselines across model scales, achieving superior reasoning accuracy with minimal overhead.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.03647" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.03647" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.03647" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling / Neural Architectures, Representation Learning, Generative Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">41. Generative Engine Optimization: A VLM and Agent Framework for Pinterest Acquisition Growth
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Faye Zhang, Qianyu Cheng, Jasmine Wan, Vishwakarma Singh, Jinfeng Rao, Kofi Boakye</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> By fine-tuning Vision-Language Models to predict user search intent and aggregating visual assets into semantically coherent Collection Pages, the Pinterest GEO framework achieved 20% organic traffic growth, successfully adapting the platform for the generative search paradigm. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Large Language Models are fundamentally reshaping content discovery through AI-native search systems such as ChatGPT, Gemini, and Claude. Unlike traditional search engines that match keywords to documents, these systems infer user intent, synthesize multimodal evidence, and generate contextual answers directly on the search page, introducing a paradigm shift from Search Engine Optimization (SEO) to Generative Engine Optimization (GEO). For visual content platforms hosting billions of assets, this poses an acute challenge: individual images lack the semantic depth and authority signals that generative search prioritizes, risking disintermediation as user needs are satisfied in-place without site visits. We present Pinterest GEO, a production-scale framework that pioneers reverse search design: rather than generating generic image captions describing what content is, we fine-tune Vision-Language Models (VLMs) to predict what users would actually search for, augmented this with AI agents that mine real-time internet trends to capture emerging search demand. These VLM-generated queries then drive construction of semantically coherent Collection Pages via multimodal embeddings, creating indexable aggregations optimized for generative retrieval. Finally, we employ hybrid VLM and two-tower ANN architectures to build authority-aware interlinking structures that propagate signals across billions of visual assets. Deployed at scale across billions of images and tens of millions of collections, GEO delivers 20\% organic traffic growth contributing to multi-million monthly active user (MAU) growth, demonstrating a principled pathway for visual platforms to thrive in the generative search era.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.02961" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.02961" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.02961" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling / Neural Architectures, Representation Learning, Generative Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">42. When Routing Collapses: On the Degenerate Convergence of LLM Routers
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Guannan Lai, Han-Jia Ye</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Addressing the &#34;routing collapse&#34; failure mode where LLM routers default to expensive models, the proposed EquiRouter mitigates cost inefficiency by directly learning model rankings instead of scalar performance scores, achieving a 17% cost reduction at high performance levels. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">LLM routing aims to achieve a favorable quality--cost trade-off by dynamically assigning easy queries to smaller models and harder queries to stronger ones. However, across both unimodal and multimodal settings, we uncover a pervasive yet underexplored failure mode in existing routers: as the user&#39;s cost budget increases, routers systematically default to the most capable and most expensive model even when cheaper models already suffice. As a result, current routers under-utilize small models, wasting computation and monetary cost and undermining the core promise of routing; we term this phenomenon routing collapse. We attribute routing collapse to an objective--decision mismatch: many routers are trained to predict scalar performance scores, whereas routing decisions ultimately depend on discrete comparisons among candidate models. Consequently, small prediction errors can flip relative orderings and trigger suboptimal selections. To bridge this gap, we propose EquiRouter, a decision-aware router that directly learns model rankings, restoring the role of smaller models and mitigating routing collapse. On RouterBench, EquiRouter reduces cost by about 17\% at GPT-4-level performance compared to the strongest prior router. Our code is available at https://github.com/AIGNLAI/EquiRouter.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.03478" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.03478" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.03478" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling / Neural Architectures, Representation Learning, Generative Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">43. Dynamical hair growth in black hole binaries in Einstein-scalar-Gauss-Bonnet gravity
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Lodovico Capuano, Llibert Aresté Saló, Daniela D. Doneva, Stoytcho S. Yazadjiev, Enrico Barausse</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Binary black holes governed by Einstein-scalar-Gauss-Bonnet gravity can dynamically acquire scalar charges during inspiral, a phenomenon termed &#34;dynamical scalarization&#34; that may be observable in nearly equal-mass mergers using future gravitational-wave detectors. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Within the framework of scalar-tensor theories of gravity, certain models can evade classical black hole no-hair theorems. A well-known example is Einstein-scalar-Gauss-Bonnet gravity, where black holes carrying a scalar charge can exist. We find that, within this theory, binary black holes initially described by General Relativity can acquire scalar charges once they reach a critical orbital separation (&#34;dynamical scalarization&#34;). We develop a simple semi-analytic model, based on the adiabatic conservation of the total Wald entropy, to estimate the scalar charge evolution during the binary inspiral. We also run fully nonlinear numerical-relativity simulations for different configurations, finding consistent results. The gravitational-wave phase difference between Einstein-scalar-Gauss-Bonnet and General Relativity waveforms, which we use to assess detectability, is also computed. We find that dynamical scalarization might be observable in nearly equal-mass binary black hole mergers with third-generation ground-based gravitational-wave detectors, in a narrow range of the dimensional coupling of the theory.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.02650" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.02650" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.02650" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">gr-qc</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">44. Score-based diffusion models for diffuse optical tomography with uncertainty quantification
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Fabian Schneider, Meghdoot Mozumder, Konstantin Tamarov, Leila Taghizadeh, Tanja Tarvainen, Tapio Helin, Duc-Lam Duong</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Applying score-based diffusion models to the ill-posed problem of Diffuse Optical Tomography, a novel mixed score regularization approach successfully generated accurate, low-variance posterior samples using both simulated and experimental data despite the presence of modeling errors. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Score-based diffusion models are a recently developed framework for posterior sampling in Bayesian inverse problems with a state-of-the-art performance for severely ill-posed problems by leveraging a powerful prior distribution learned from empirical data. Despite generating significant interest especially in the machine-learning community, a thorough study of realistic inverse problems in the presence of modelling error and utilization of physical measurement data is still outstanding. In this work, the framework of unconditional representation for the conditional score function (UCoS) is evaluated for linearized difference imaging in diffuse optical tomography (DOT). DOT uses boundary measurements of near-infrared light to estimate the spatial distribution of absorption and scattering parameters in biological tissues. The problem is highly ill-posed and thus sensitive to noise and modelling errors. We introduce a novel regularization approach that prevents overfitting of the score function by constructing a mixed score composed of a learned and a model-based component. Validation of this approach is done using both simulated and experimental measurement data. The experiments demonstrate that a data-driven prior distribution results in posterior samples with low variance, compared to classical model-based estimation, and centred around the ground truth, even in the context of a highly ill-posed problem and in the presence of modelling errors.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.03449" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.03449" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.03449" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">stat.ML</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">45. DeltaEvolve: Accelerating Scientific Discovery through Momentum-Driven Evolution
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Jiachen Jiang, Tianyu Ding, Zhihui Zhu</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The DeltaEvolve framework enhances LLM-driven evolutionary systems by utilizing structured semantic deltas—which capture effective algorithmic changes—instead of full-code histories, resulting in more efficient context usage and the discovery of superior solutions across scientific domains. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">LLM-driven evolutionary systems have shown promise for automated science discovery, yet existing approaches such as AlphaEvolve rely on full-code histories that are context-inefficient and potentially provide weak evolutionary guidance. In this work, we first formalize the evolutionary agents as a general Expectation-Maximization framework, where the language model samples candidate programs (E-step) and the system updates the control context based on evaluation feedback (M-step). Under this view, constructing context via full-code snapshots constitutes a suboptimal M-step, as redundant implement details dilutes core algorithmic ideas, making it difficult to provide clear inspirations for evolution. To address this, we propose DeltaEvolve, a momentum-driven evolutionary framework that replaces full-code history with structured semantic delta capturing how and why modifications between successive nodes affect performance. As programs are often decomposable, semantic delta usually contains many effective components which are transferable and more informative to drive improvement. By organizing semantic delta through multi-level database and progressive disclosure mechanism, input tokens are further reduced. Empirical evaluations on tasks across diverse scientific domains show that our framework can discover better solution with less token consumption over full-code-based evolutionary agents.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.02919" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.02919" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.02919" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">46. Digging into the chemical complexity in the outer Galaxy: A hot molecular core in Sharpless 2-283
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Toki Ikeda, Takashi Shimonishi, Hiroyuki Kaneko, Kenji Furuya, Kei Tanaka, Natsuko Izumi</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Chemical analysis of the low-metallicity outer Galactic hot core Sh 2-283-1a SMM1 indicates that the abundance of complex organic molecules and overall chemical complexity are primarily regulated by environmental factors, such as cosmic ray intensity, rather than solely by metallicity scaling. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The outer Galaxy (galactocentric distance $\gtrsim$13.5 kpc) serves as an excellent laboratory for investigating the chemical complexity in low-metallicity environments. Here, we present the chemical analyses for the outer Galactic hot core Sh 2-283-1a SMM1 ($D_\mathrm{GC}$ = 15.7 kpc and $Z$ $\sim$0.3 $Z_\odot$), recently detected by Ikeda et al. (2025) using ALMA. Toward this source, a variety of molecular species, including complex organic molecules (COMs: CH$_3$OH, $^{13}$CH$_3$OH, CH$_2$DOH, and CH$_3$OCH$_3$) are detected. The molecular abundances relative to CH$_3$OH are similar to those of another outer Galactic hot core, demonstrating that chemically rich hot cores exist in different regions of the outer Galaxy. We also compared molecular abundances among hot cores in the inner Galaxy, outer Galaxy, and Magellanic Clouds. This comparison revealed that the metallicity-corrected $N$(SO$_2$)/$N$(H$_2$) ratios of outer Galactic hot cores are significantly lower than those of the inner Galactic ones, while their $N$(CH$_3$OH)/$N$(H$_2$) ratios are similar. The Magellanic hot cores show different trends despite having metallicities similar to those of the outer Galaxy, indicating that the chemical complexity of hot cores is governed by environmental conditions (e.g., cosmic ray intensity and dust temperature) rather than simple metallicity scaling. These environmental differences would also affect the production efficiency of COMs derived from CH$_3$OH, as the $N$(CH$_3$OCH$_3$)/$N$(CH$_3$OH) and $N$(C$_2$H$_5$OH)/$N$(CH$_3$OH) ratios in the outer Galactic sources are moderately lower than those of inner Galactic sources. The $N$(CH$_2$DOH)/$N$(CH$_3$OH) ratio of Sh 2-283-1a SMM1 is 1.5$^{+3.9}_{-1.2}$$\%$, comparable to that of inner Galactic high-mass sources.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.03122" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.03122" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.03122" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Weak Lensing, Galaxy Clustering, Cosmology / Galaxy Clustering, Weak Lensing, Halo Model</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">47. Kinematic Signatures in the Stellar Halo from Cosmological Encounters between the Milky Way and its Clouds
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Mia Mansfield, Robyn Sanderson, Daniel Hey, Daniel Huber, Arpit Arora, Emily Cunningham, Nondh Panithanpaisal</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Cosmological simulations confirm that the LMC interaction induces prominent velocity asymmetry in the Milky Way&#39;s stellar halo, where spherical harmonic decomposition successfully isolates the dipole of the global reflex motion and the quadrupole of the local dynamical wake, validating observational detection strategies. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Recent theoretical and observational analysis of the interaction between the Milky Way (MW) and LMC suggest that it has a significant dynamical impact on the MW&#39;s stellar halo. We investigate this effect using simulations from the Latte project, a simulation suite from the Feedback In Realistic Environments 2 (FIRE-2) Project. By comparing simulations with and without an LMC-analog interaction, we show that fully cosmological LMC interactions create prominent velocity asymmetry in the stellar halo of the MW, resulting from both barycentric displacement (the &#34;reflex motion&#34;) and the dynamical wake of the LMC. The strength and direction of this asymmetry depend on the mass ratio at pericenter and orbit of the LMC analog. We perform a spherical-harmonic decomposition of the velocities of halo star particles to confirm that the identified signatures are LMC-induced and persist even when LMC star particles are removed. We also show that this strategy separates and individually detects the dipole (l=1) of the global reflex motion and the quadrupole (l=2) of the local wake. These asymmetries are consistent with those identified in previous work using non-cosmological simulations; the dipole is easily distinguishable from other complex halo substructure using spherical harmonics while the quadrupole is sometimes confused. These findings support the detectability of MW--LMC interaction signatures in upcoming observational surveys of the MW stellar halo.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.03528" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.03528" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.03528" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">48. WLM: Dynamics of an isolated Dwarf Irregular Galaxy Under Ram Pressure in the Local Group
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Neel Kolhe, Francois Hammer, Yanbin Yang, Brenda Namumba, Laurent Chemin, Philippe Amram, Roger Ianjamasimanana, Claude Carignan</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Ram pressure forces significantly perturb the extended disk component of the dwarf irregular galaxy WLM, causing asymmetric rotation that necessitates a full dynamical model accounting for distinct structural components to accurately estimate the galaxy&#39;s mass. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">WLM is an archetypal dwarf irregular galaxy that has not experienced interactions with major Local Group galaxies within the past 8 Gyr. It has recently been shown that WLM is losing its gas due to ram pressure forces exerted by the surrounding intergalactic medium (IGM). In this work, we explore how ram pressure may also affect the WLM gas kinematics, and we show that its dynamics is especially perturbed at its outskirts, explaining the asymmetric rotation between the approaching and receding sides. Moreover, we have been able to decompose WLM in two main components, a compact one with a solid-body rotation that resembles a bar-like structure, and a more extended one with a characteristic double-horn profile suggesting an edge-on disk. The former is relatively unaffected by ram pressure while the latter has its dynamics considerably affected by ram pressure. This study shows that mass estimates of a dwarf galaxy like WLM should account for a full modeling of its dynamical components, especially accounting for its asymmetric rotation curve.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.02652" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.02652" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.02652" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">49. Cosmic CO and [CII] backgrounds and the fueling of star formation over 12 Gyr
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Yi-Kuan Chiang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Tomographic clustering yielded the first detections of the mean cosmic CO and [CII] backgrounds, revealing a total molecular gas density double that found in galaxy surveys, which implies a global picture of galaxy growth driven by a large, short-lived molecular reservoir consistent with a universal super-linear Kennicutt-Schmidt law. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Molecular gas, modest in mass yet pivotal within the cosmic inventory, regulates baryon cycling as the immediate fuel for star formation. Across most of cosmic history, its reservoir has remained elusive, with only the tip of the iceberg revealed by luminous carbon monoxide (CO) emitting galaxies. Here we report the first detections of the mean cosmic CO background across its rotational ladder at 7$σ$, together with ionized carbon ([CII]) at 3$σ$, over $0&lt;z&lt;4.2$. This uses tomographic clustering of diffuse broadband intensities with reference galaxies, directly probing aggregate emission in the cosmic web. From CO(1-0) we infer the total molecular gas density, $Ω_{\rm H_2}$, finding it about twice that resolved in galaxy surveys. The global depletion time is $\sim$1 Gyr, shorter than the Hubble time, requiring sustained inflow. CO excitation links to star-formation surface density and, with depletion time, yields a super-linear Kennicutt-Schmidt law that appears universal. Together these results establish a global picture of galaxy growth fueled by a larger, short-lived molecular reservoir. The CO and [CII] detections mark a turning point for line-intensity mapping, replacing forecasts with empirical line strengths and defining sensitivity requirements for upcoming 3D experiments poised to open new windows on galaxy formation and cosmology.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.02658" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.02658" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.02658" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">50. Studying Energy-Energy Correlators in pp Collisions at the LHC with a Jet-Free Event-Topology Method
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Yazhen Lin, Liang Zheng, Zhongbao Yin</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A novel jet-free method for measuring energy-energy correlators in proton-proton collisions, anchored by the leading charged hadron, robustly probes the transition between perturbative and non-perturbative QCD dynamics and directly reveals the dead-cone effect using heavy flavor triggers. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We present a jet-free approach for measuring energy-energy correlators (EEC) in proton-proton (pp) collisions at the Large Hadron Collider (LHC), employing an event-topology method that does not rely on explicit jet reconstruction. Using the leading charged hadron as a reference axis, the azimuthal plane is divided into Toward and Transverse regions, enabling a robust background subtraction and extending EEC measurements into the low $p_T$ regime where conventional jet-based approaches become unreliable. The method is validated through comparisons with conventional jet reconstruction results. We systematically explore the dependence of the EEC on the leading-particle transverse momentum and parton flavor. The observed scaling between the EEC peak position and the hard scale suggests that this topology-based EEC captures effectively the transition between perturbative and non-perturbative QCD regimes. Distinct differences are found between quark- and gluon-initiated events, reflecting their different color charges and radiation patterns. Extending the analysis to heavy flavor, EECs triggered by leading charm mesons exhibit a suppressed magnitude and a peak shifted toward larger angular separations relative to inclusive charged-particle triggers, providing a direct manifestation of the dead-cone effect. This jet-free EEC framework offers a simple and experimentally robust tool for studying the scale and flavor dependence of the QCD dynamics, with promising applications to proton-nucleus and heavy-ion collisions at the LHC.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2602.03180" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2602.03180" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2602.03180" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">hep-ph</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
    </div>

    <footer class="footer">
        &copy; 2026 arXiv Daily · Powered by <a href="https://arxiv.org/" target="_blank">arXiv</a>
    </footer>
</body>
</html>