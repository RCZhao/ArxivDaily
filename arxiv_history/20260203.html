<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>arXiv Daily: 2026-02-03</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Roboto:400,700&display=swap" rel="stylesheet">
    <style>
        body { font-family: 'Roboto', Arial, sans-serif; background: #f8f9fa; transition: background 0.3s; }
        .arxiv-card { margin: 2em auto; max-width: 900px; box-shadow: 0 2px 8px rgba(0,0,0,0.08); border-radius: 16px; transition: box-shadow 0.3s, transform 0.3s; }
        .arxiv-card:hover { box-shadow: 0 4px 12px rgba(0,0,0,0.1); transform: translateY(-1px); }
        .arxiv-title { background: linear-gradient(90deg, #0d6efd 60%, #6610f2 100%); color: #fff; border-radius: 16px 16px 0 0; padding: 1.5em; font-size: 1.5em; font-weight: 700; letter-spacing: 0.5px;}
        .arxiv-meta { font-size: 1em; color: #555; margin-bottom: 1em; }
        .arxiv-abstract { background: #fff; padding: 1.5em; border-radius: 0 0 16px 16px; font-size: 1.1em; line-height: 1.7;}
        .arxiv-links a { margin-right: 1em; }
        .arxiv-scores { margin-top: 1em; font-size: 1em; }
        .navbar { background: #fff; box-shadow: 0 2px 8px rgba(0,0,0,0.04);}
        .footer { text-align: center; color: #888; padding: 2em 0 1em 0; font-size: 0.95em;}
        @media (prefers-color-scheme: dark) {
            body { background: #181a1b; color: #e4e6eb; }
            .arxiv-card { background: #23272b; box-shadow: 0 2px 8px rgba(0,0,0,0.28);}
            .arxiv-card:hover { box-shadow: 0 5px 15px rgba(0,0,0,0.25); transform: translateY(-1px); }
            .arxiv-title { background: linear-gradient(90deg, #375a7f 60%, #6f42c1 100%);}
            .arxiv-abstract { background: #23272b; color: #e4e6eb;}
            .navbar { background: #23272b; color: #e4e6eb;}
            .text-muted { color: #adb5bd !important; }
        }
        /* Improved abstract readability */
        .arxiv-abstract-text {
            font-size: 1.1em;
            line-height: 1.7;
        }
        p.big {
            line-height: 1.6;
            font-size: large;
        }
    </style>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'] ],
          processEscapes: true
        }
      });
    </script>
    <script>
    function toggleAuthors(element) {
        const fullList = element.querySelector('.author-full');
        const shortList = element.querySelector('.author-short');
        const toggleText = element.querySelector('.author-toggle');
        
        fullList.style.display = fullList.style.display === 'none' ? 'inline' : 'none';
        shortList.style.display = shortList.style.display === 'none' ? 'inline' : 'none';
        toggleText.textContent = fullList.style.display === 'none' ? ' (show all)' : ' (show less)';
    }
    </script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
</head>
<body>
    <nav class="navbar navbar-expand-lg mb-4">
        <div class="container">
            <a class="navbar-brand fw-bold text-primary" href="#">arXiv Daily</a>
            <span class="navbar-text">Modern arXiv Reader</span>
        </div>
    </nav>

    
    <div class="container py-4">
        <header class="mb-4"><h2 class="display-6 text-center">Analysis of Your Favorites</h2></header>
        
        <div class="row justify-content-center">
            <div class="col-lg-8 mb-4">
                <div class="card">
                    <div class="card-header fw-bold">Interest Word Cloud</div>
                    <div class="card-body text-center p-2">
                        <img src="analysis_results/word_cloud.png" class="img-fluid rounded" alt="Word Cloud of favorite paper topics">
                    </div>
                </div>
            </div>
        </div>
        
        
        <div class="row justify-content-center">
            <div class="col-lg-8 mb-4">
                <div class="card">
                    <div class="card-header fw-bold">Interest Clusters</div>
                    <div class="card-body text-center p-2">
                        <img src="analysis_results/daily_cluster_map.png" class="img-fluid rounded" alt="2D Cluster plot of favorite papers">
                    </div>
                </div>
            </div>
        </div>
        
    </div>
    

    <div class="container py-4">
        <header class="mb-4"><h1 class="display-5 text-center text-primary">arXiv: 2026-02-03</h1></header>

        
        <div class="row justify-content-center">
            <div class="col-lg-8 mb-4">
                <div class="card">
                    <div class="card-header fw-bold">Score Distribution of All Papers Found Today</div>
                    <div class="card-body text-center p-2">
                        <img src="analysis_results/score_distribution.png" class="img-fluid rounded" alt="Score distribution of all papers found today">
                    </div>
                </div>
            </div>
        </div>
        

        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">1. Mapping dark matter in the Bullet Cluster using JWST imaging and spectroscopy
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">Gregor Rihtaršič, Maruša Bradač, Guillaume Desprez, Anishya Harshan, Nicholas S. Martis, Chris J. Willott, Yoshihisa Asada, Ghassan T. E. Sarrouh, Carla Cornil-Baiotto, Andrea Biviano, et al.</span>
                                <span class="author-full" style="display: none;">Gregor Rihtaršič, Maruša Bradač, Guillaume Desprez, Anishya Harshan, Nicholas S. Martis, Chris J. Willott, Yoshihisa Asada, Ghassan T. E. Sarrouh, Carla Cornil-Baiotto, Andrea Biviano, Douglas Clowe, Anthony H. Gonzalez, Christine Jones, Jon Judež, Stacy Y. Kim, Marco Lombardi, Danilo Marchesini, Maxim Markevitch, Vladan Markov, Gaël Noirot, Annika H. G. Peter, Scott W. Randall, Andrew Robertson, Marcin Sawicki, Roberta Tripodi</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> An updated gravitational lens model of the Bullet cluster, constrained by 135 JWST-derived spectroscopic multiple images, reveals a refined, complex mass distribution incorporating group-scale substructures and achieving a threefold improvement in the alignment precision of the subcluster&#39;s brightest cluster galaxy. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We present an updated gravitational lens model of the Bullet cluster (1E 0657-56) by combining JWST NIRCam imaging and NIRSpec spectroscopy. Although previous lens models relied on many multiply imaged galaxies, only six systems had spectroscopic redshifts prior to this work. Our lens model is constrained by a catalogue of 135 secure multiple images from 27 background galaxies with spectroscopic redshifts, uniformly covering both subclusters and a wide redshift range of 0.9 - 6.7. We also provide a catalogue of 199 multiple image candidates. We model the cluster with Lenstool and incorporate several large-scale haloes, cluster members, the intracluster gas, and group-scale haloes surrounding the cluster core, motivated by spectroscopic studies of cluster member kinematics. We describe the main cluster component with a complex, elongated double-peaked distribution, and the subcluster with a single large-scale halo aligning closely with the brightest cluster galaxy ($4_{-2}^{+4}$ kpc). The uncertainty of the alignment is improved threefold with the addition of JWST systems. The addition of group-scale substructures, roughly following the two axes of cluster assembly, improves the fit to the multiple image positions and provides a physically motivated alternative to constant shear. Our lens model shows the closest agreement with previous studies in aperture mass profiles at $\sim60$ kpc from the BCGs, but exhibits significant differences in the detailed mass distribution as a result of different lens-modelling strategies and adopted constraints. The differences are reflected in small but spatially coherent deviations between the new spectroscopic redshifts and redshifts predicted by earlier lens models.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22245" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22245" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22245" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 10.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.14</span>
                        <span class="badge bg-primary">Semantic Score: 0.95</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Weak Lensing, Galaxy Clustering, Cosmological Constraints / Galaxy Clustering, Weak Lensing, Halo Occupation</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">2. Detectability of Gravitational-Wave Memory with LISA: A Bayesian Approach
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Adrien Cogez, Silvia Gasparotto, Jann Zosso, Henri Inchauspé, Chantal Pitte, Lorena Magaña Zertuche, Antoine Petiteau, Marc Besancon</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Bayesian analysis applied to state-of-the-art LISA simulations establishes the conditions for detecting and precisely reconstructing the gravitational wave displacement memory effect from individual massive black hole binary mergers, enabling future tests of General Relativity. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Gravitational wave (GW) astronomy opens a new venue to explore the universe. Future observatories such as LISA, the Laser Interferometer Space Antenna, are expected to observe previously undetectable fundamental physics effects in signals predicted by General Relativity (GR).One particularly interesting such signal is associated to the displacement memory effect, which corresponds to a permanent deformation of spacetime due to the passage of gravitational radiation. In this work, we explore the ability of LISA to observe and characterize this effect. In order to do this, we use state-of-the-art simulations of the LISA instrument, and we perform a Bayesian analysis to assess the detectability and establish general conditions to claim detection of the displacement memory effect from individual massive black hole binary (MBHB) merger events in LISA. We perform parameter estimation both to explore the impact of the displacement memory effect and to reconstruct its amplitude. We discuss the precision at which such a reconstruction can be obtained thus opening the way to tests of GR and alternative theories. To provide astrophysical context, we apply our analysis to black hole binary populations models and estimate the rates at which the displacement memory effect could be observed within the LISA planned lifetime.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.23230" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.23230" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.23230" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">gr-qc</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">3. Why Self-Rewarding Works: Theoretical Guarantees for Iterative Alignment of Language Models
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Shi Fu, Yingjie Wang, Shengchao Hu, Peng Wang, Dacheng Tao</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Rigorous theoretical guarantees for Self-Rewarding Language Models establish finite-sample error bounds and prove that the influence of poor initialization decays exponentially across iterations, providing a formal explanation for the robust success of the iterative self-improvement paradigm. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Self-Rewarding Language Models (SRLMs) achieve notable success in iteratively improving alignment without external feedback. Yet, despite their striking empirical progress, the core mechanisms driving their capabilities remain unelucidated, leaving a critical gap in theoretical understanding. This paper provides the first rigorous theoretical guarantees for SRLMs. We first establish a lower bound that characterizes the fundamental limits of a single update step, revealing a critical dependence on the quality of the initial model. We then derive finite-sample error bounds for the full iterative paradigm, showing that performance improves at a rate of $\widetilde{\mathcal{O}}\left(1/\sqrt{n}\right)$ with sample size $n$. Crucially, our analysis reveals that the dependence on the initial model decays exponentially with the number of iterations $T$. This provides a formal explanation for why self-rewarding succeeds: it robustly overcomes poor initialization by steering the dynamics toward internal stability and consistency. Finally, we instantiate our theoretical framework for the linear softmax model class, yielding tailored guarantees that connect our high-level insights to practical model architectures.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22513" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22513" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22513" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods / Representation Learning, Advanced Architectures, Inference</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">4. Best-of-Q: Improving VLM agents with Q-function Action Ranking at Inference
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Emilien Biré, María Santos, Kai Yuan</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Enhancing agentic Vision-Language Models without policy retraining, a novel inference paradigm uses a lightweight, offline-trained Q-function to rerank candidate actions proposed by the frozen VLM, significantly boosting success rates on web navigation benchmarks. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Vision-Language Models (VLMs) have become powerful backbones for agents to autonomously operate in digital environments like the web and operating systems. However, these models suffer from inadaptability to fast-changing environments like the web, which can be alleviated by fine-tuning requiring expansive model training and data collection. In this work, we introduce a novel paradigm for enhancing agentic VLM policies at inference without policy retraining. Fundamentally, our approach decouples the VLM&#39;s role as a high-capacity action proposer from the final action selection mechanism. We keep the VLM policy frozen and use it to generate a set of candidate actions for a given state. Then, a lightweight, offline-trained Q-function reranks these candidates, and the agent executes the action with the highest estimated value. The main contribution is to apply the Q-function directly during inference for immediate policy improvement, and not offline to relabel data for policy retraining. We demonstrate on the academic WebVoyager benchmark that our method significantly boosts agent success rates, improving a Qwen2.5-VL-7B agent from 38.8% to 55.7% and a proprietary GPT-4.1 agent from 82.4% to 88.8%.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22701" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22701" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22701" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods / Representation Learning, Advanced Architectures, Inference</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">5. The LBT Y$_\mathrm{p}$ Project IV: A New Value of the Primordial Helium Abundance
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Erik Aver, Evan D. Skillman, Richard W. Pogge, Noah S. J. Rogers, Miqaela K. Weller, Keith A. Olive, Danielle A. Berg, John J. Salzer, John H. Miller, José Eduardo Méndez-Delgado</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> New high-quality LBT observations of metal-poor H II regions yield a primordial helium abundance of $Y_p = 0.2458 \pm 0.0013$ through a robust weighted average of low-metallicity targets, achieving an unprecedented precision of 0.5% and aligning closely with standard BBN predictions. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We present a new determination of the primordial helium abundance based on new, high-quality Large Binocular Telescope (LBT) observations of 54 metal-poor H II regions. These regions have been observed and analyzed uniformly. We also describe a number of updates to our methodology, including updated helium emissivities. Enabled by the large, high-quality dataset, we examine our sample targets for potential systematic errors, which could bias their results. We perform a standard 95% confidence level $χ^2$ cut and find that a significantly larger fraction (47/54 = 87%) of our sample qualifies than for previous datasets. We also screen for quality and reliability, flagging targets which may introduce significant systematic errors, producing a dataset of 41 targets. In a significant breakthrough for the field, that dataset includes 15 high SNR targets with low metallicity (O/H &lt; 4 $\times$ 10$^{-5}$). Due to this low-metallicity dataset, for the first time, a weighted average for determining the primordial helium abundance (Y$_\mathrm{p}$) is well-justified and produces a robust result. By weighted average of our 15 low-metallicity targets, we determine Y$_\mathrm{p}$ = 0.2458 $\pm$ 0.0013. This result achieves an unprecedented precision of 0.5%, and it is in good agreement with the BBN result, Y$_\mathrm{p}$ = 0.2467 $\pm$ 0.0002, based on the Planck determination of the baryon density.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22238" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22238" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22238" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">6. Neural Backward Filtering Forward Guiding
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Gefan Yang, Frank van der Meulen, Stefan Sommer</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A unified framework called Neural Backward Filtering Forward Guiding (NBFFG) enables efficient inference in non-linear continuous stochastic processes on trees by leveraging a closed-form backward filter from an auxiliary linear-Gaussian process to guide the generative path, complemented by a learned neural residual. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Inference in non-linear continuous stochastic processes on trees is challenging, particularly when observations are sparse (leaf-only) and the topology is complex. Exact smoothing via Doob&#39;s $h$-transform is intractable for general non-linear dynamics, while particle-based methods degrade in high dimensions. We propose Neural Backward Filtering Forward Guiding (NBFFG), a unified framework for both discrete transitions and continuous diffusions. Our method constructs a variational posterior by leveraging an auxiliary linear-Gaussian process. This auxiliary process yields a closed-form backward filter that serves as a ``guide&#39;&#39;, steering the generative path toward high-likelihood regions. We then learn a neural residual--parameterized as a normalizing flow or a controlled SDE--to capture the non-linear discrepancies. This formulation allows for an unbiased path-wise subsampling scheme, reducing the training complexity from tree-size dependent to path-length dependent. Empirical results show that NBFFG outperforms baselines on synthetic benchmarks, and we demonstrate the method on a high-dimensional inference task in phylogenetic analysis with reconstruction of ancestral butterfly wing shapes.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.23030" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.23030" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.23030" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">stat.ML</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods / Representation Learning, Advanced Architectures, Inference</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">7. Generative and Nonparametric Approaches for Conditional Distribution Estimation: Methods, Perspectives, and Comparative Evaluations
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Yen-Shiu Chin, Zhi-Yu Jou, Toshinari Morimoto, Chia-Tse Wang, Ming-Chung Chang, Tso-Jung Yen, Su-Yun Huang, Tailen Hsing</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A systematic review numerically compares classical nonparametric methods and modern deep generative models for conditional distribution inference, providing a unified evaluation framework based on metrics including Wasserstein distance and mean-squared errors of conditional statistics. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The inference of conditional distributions is a fundamental problem in statistics, essential for prediction, uncertainty quantification, and probabilistic modeling. A wide range of methodologies have been developed for this task. This article reviews and compares several representative approaches spanning classical nonparametric methods and modern generative models. We begin with the single-index method of Hall and Yao (2005), which estimates the conditional distribution through a dimension-reducing index and nonparametric smoothing of the resulting one-dimensional cumulative conditional distribution function. We then examine the basis-expansion approaches, including FlexCode (Izbicki and Lee, 2017) and DeepCDE (Dalmasso et al., 2020), which convert conditional density estimation into a set of nonparametric regression problems. In addition, we discuss two recent generative simulation-based methods that leverage modern deep generative architectures: the generative conditional distribution sampler (Zhou et al., 2023) and the conditional denoising diffusion probabilistic model (Fu et al., 2024; Yang et al., 2025). A systematic numerical comparison of these approaches is provided using a unified evaluation framework that ensures fairness and reproducibility. The performance metrics used for the estimated conditional distribution include the mean-squared errors of conditional mean and standard deviation, as well as the Wasserstein distance. We also discuss their flexibility and computational costs, highlighting the distinct advantages and limitations of each approach.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22650" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22650" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22650" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">stat.ML</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">8. Toward IIT-Inspired Consciousness in LLMs: A Reward-Based Learning Framework
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Hamid Reza Akbari, Mohammad Hossein Sameti, Amir M. Mansourian, Mohammad Hossein Rohban, Hossein Sameti</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A novel reward function inspired by Integrated Information Theory (IIT) principles, which quantifies causality and integration, is used in a reward-based learning paradigm for language models, resulting in significantly more concise text generation while preserving accuracy and offering computational efficiency. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The pursuit of Artificial General Intelligence (AGI) is a central goal in language model development, in which consciousness-like processing could serve as a key facilitator. While current language models are not conscious, they exhibit behaviors analogous to certain aspects of consciousness. This paper investigates the implementation of a leading theory of consciousness, Integrated Information Theory (IIT), within language models via a reward-based learning paradigm. IIT provides a formal, axiom-based mathematical framework for quantifying consciousness. Drawing inspiration from its core principles, we formulate a novel reward function that quantifies a text&#39;s causality, coherence and integration, characteristics associated with conscious processing. Empirically, it is found that optimizing for this IIT-inspired reward leads to more concise text generation. On out of domain tasks, careful tuning achieves up to a 31% reduction in output length while preserving accuracy levels comparable to the base model. In addition to primary task performance, the broader effects of this training methodology on the model&#39;s confidence calibration and test-time computational scaling is analyzed. The proposed framework offers significant practical advantages: it is conceptually simple, computationally efficient, requires no external data or auxiliary models, and leverages a general, capability-driven signal rather than task-specific heuristics. Code available at https://github.com/MH-Sameti/LLM_PostTraining.git</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22786" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22786" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22786" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods / Representation Learning, Advanced Architectures, Inference</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">9. Towards Claiming a Detection of Gravitational Memory
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Jann Zosso, Lorena Magaña Zertuche, Silvia Gasparotto, Adrien Cogez, Henri Inchauspé, Milo Jacobs</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A theoretical framework is established for defining and modeling the time-dependent gravitational memory rise signal from compact binary coalescences, providing the necessary foundation for statistically robust hypothesis testing to enable future observational claims of gravitational memory using space-based detectors like LISA. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Gravitational memory is a zero-frequency effect associated with a permanent change in the asymptotic spacetime metric induced by radiation. While its universal manifestation is a net change of proper distances, gravitational-wave detectors are intrinsically insensitive to the final offset and can only probe the associated transition. A central challenge for any claim of detection therefore lies in defining a physically meaningful and operationally robust model of this time-dependent signal, which is uniquely attributable to gravitational memory and distinguishable from purely oscillatory radiation. In this work, we propose a general solution to this challenge. Building on a self-contained review of the theory of gravitational memory, we discuss a theoretical framework for defining and modeling a gravitational memory rise, in particular applicable to compact binary coalescences. Specializing to space-based detectors, we analyze the response of LISA to gravitational radiation including a memory contribution, with particular emphasis on mergers of supermassive black hole binaries, which offer the most promising prospects for a first single-event detection. The framework developed here provides the theoretical foundation for statistically well-defined hypothesis testing between memory-free and memory-full radiation and quantitative assessments of detection prospects. As such, these results establish a principled pathway toward a future observational claim of gravitational memory.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.23019" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.23019" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.23019" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">gr-qc</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">10. Tensions in Cosmology: Interpreting Them Through Inhomogeneous Models
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Valerio Marra</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Current cosmological tensions affecting the $\Lambda$CDM model are reinterpreted using the spherically symmetric inhomogeneous $\Lambda$LTB framework, demonstrating how spatial gradients can mimic anisotropic expansion, local $H_0$ shifts, and an evolving dark energy equation of state, although a single configuration&#39;s ability to resolve all anomalies remains unclear. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We review a subset of the current tensions affecting the standard $Λ$CDM cosmological model, emphasizing the role of chronic systematics and significance inflation in shaping their interpretation. As a unifying framework, we consider the spherically symmetric inhomogeneous $Λ$LTB model and use it as a set of &#34;glasses&#34; through which to reinterpret the Hubble, dipole, and dark-energy tensions. Large-scale spatial gradients in this model introduce anisotropic expansion and position-dependent observables, allowing local estimates of $H_{0}$ to shift, dipolar signatures to arise, and an apparently evolving dark-energy equation of state to be mimicked without invoking genuinely dynamical dark energy. We discuss how these effects are constrained once the full supernova, CMB, and large-scale-structure data sets are included, and argue that it remains unclear whether any single $Λ$LTB configuration can simultaneously account for all major anomalies. More broadly, we highlight that cosmology currently lacks a widely accepted baseline model that is both theoretically well founded and capable of accommodating the Hubble and dark-energy tensions, leaving us without a true concordance framework for forecasting future surveys.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22278" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22278" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22278" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">11. Distinguishing the nature of dark matter by mapping cosmic filaments from Lyman-alpha emission
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Yizhou Liu, Liang Gao, Shihong Liao, Kai Zhu, Yingjie Jing, Huijie Hu</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Lyman $\alpha$ emission tracing cosmic filaments at $z=4$ offers a distinct observational signature—differences in filament smoothness and surface brightness—to constrain the nature of dark matter, distinguishing between $\Lambda$CDM and warm dark matter models. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The standard $Λ$CDM cosmological model predicts that cosmic filaments are highly clumpy, whereas warm dark matter -- invoked to address small-scale challenges in $Λ$CDM -- produces filaments that are noticeably smoother and less structured. In this work, we investigate the potential of Lyman $α$ (Ly$α$) emission to trace cosmic filaments at redshifts $z=2.5$ and $z=4$, and assess their potential for constraining the nature of dark matter. Our analysis shows that Ly$α$ filaments provide a promising observational probe of dark matter: at $z=4$, differences in filament smoothness and surface brightness serve as distinctive signatures between models. Looking ahead, the upcoming generation of 30-meter class telescopes will be critical for enabling these measurements, offering a compelling opportunity to distinguish the nature of dark matter by mapping the structure of cosmic filaments.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22677" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22677" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22677" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">12. Decoding in Geometry: Alleviating Embedding-Space Crowding for Complex Reasoning
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Yixin Yang, Qingxiu Dong, Zhifang Sui</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Embedding-space crowding, a novel phenomenon where LLM next-token probability concentrates on geometrically close tokens, is mitigated by the proposed geometry-guided reweighting sampling method, CraEG, which enhances reasoning performance and generation diversity. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Sampling-based decoding underlies complex reasoning in large language models (LLMs), where decoding strategies critically shape model behavior. Temperature- and truncation-based methods reshape the next-token distribution through global probability reweighting or thresholding to balance the quality-diversity tradeoff. However, they operate solely on token probabilities, ignoring fine-grained relationships among tokens in the embedding space. We uncover a novel phenomenon, embedding-space crowding, where the next-token distribution concentrates its probability mass on geometrically close tokens in the embedding space. We quantify crowding at multiple granularities and find a statistical association with reasoning success in mathematical problem solving. Motivated by this finding, we propose CraEG, a plug-and-play sampling method that mitigates crowding through geometry-guided reweighting. CraEG is training-free, single-pass, and compatible with standard sampling strategies. Experiments on multiple models and benchmarks demonstrate improved generation performance, with gains in robustness and diversity metrics.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22536" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22536" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22536" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods / Representation Learning, Advanced Architectures, Inference</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">13. IceCube DeepCore&#39;s sensitivity to Non-Standard neutrino Interactions in the Earth
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Samyak Jain, Veronika Palusova, Thomas Ehrhardt, Sebastian Boser, Francis Halzen</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> IceCube DeepCore is sensitive enough to probe Non-Standard Interactions (NSI) in neutrino matter interactions, potentially resolving the observed tension in $\delta_{\text{CP}}$ measurements between the T2K and NOvA long baseline experiments. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Neutrino oscillations continue to provide one of the most promising avenues for uncovering physics beyond the Standard Model. In particular, beyond-standard-model neutrino matter interactions may perturb neutrino oscillations in matter, leading to an observable signal in long baseline oscillation experiments. Moreover, such interactions can be a possible explanation of the rising tension between T2K and NOvA&#39;s $δ_{\text{CP}}$ measurements. We examine IceCube DeepCore&#39;s sensitivity to these Non-Standard Interactions (NSI) by employing a model-independent NSI parameterization, and examine IceCube DeepCore&#39;s ability to comment on NSI being the cause of the T2K-NOvA $δ_{\text{CP}}$ tension.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22374" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22374" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22374" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.3</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">hep-ph</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">14. OneFlowSBI: One Model, Many Queries for Simulation-Based Inference
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Mayank Nautiyal, Li Ju, Melker Ernfors, Klara Hagland, Ville Holma, Maximilian Werkö Söderholm, Andreas Hellander, Prashant Singh</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The unified OneFlowSBI framework utilizes a single flow-matching generative model trained on the joint parameter-observation distribution, employing query-aware masking to efficiently support multiple simulation-based inference tasks like posterior sampling and likelihood estimation. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We introduce \textit{OneFlowSBI}, a unified framework for simulation-based inference that learns a single flow-matching generative model over the joint distribution of parameters and observations. Leveraging a query-aware masking distribution during training, the same model supports multiple inference tasks, including posterior sampling, likelihood estimation, and arbitrary conditional distributions, without task-specific retraining. We evaluate \textit{OneFlowSBI} on ten benchmark inference problems and two high-dimensional real-world inverse problems across multiple simulation budgets. \textit{OneFlowSBI} is shown to deliver competitive performance against state-of-the-art generalized inference solvers and specialized posterior estimators, while enabling efficient sampling with few ODE integration steps and remaining robust under noisy and partially observed data.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22951" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22951" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22951" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">stat.ML</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods / Representation Learning, Advanced Architectures, Inference</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">15. Learn More with Less: Uncertainty Consistency Guided Query Selection for RLVR
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Hao Yi, Yulan Hu, Xin Li, Sheng Ouyang, Lizhong Ding, Yong Liu</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Active learning for RLVR is significantly improved by introducing an uncertainty consistency metric—derived from the Point-Biserial Correlation Coefficient and its online variant—which effectively selects informative samples and reduces the required training data budget by 70% for reasoning tasks. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Large Language Models (LLMs) have recently improved mathematical reasoning through Reinforcement Learning with Verifiable Reward (RLVR). However, existing RLVR algorithms require large query budgets, making annotation costly. We investigate whether fewer but more informative queries can yield similar or superior performance, introducing active learning (AL) into RLVR. We identify that classic AL sampling strategies fail to outperform random selection in this setting, due to ignoring objective uncertainty when only selecting by subjective uncertainty. This work proposes an uncertainty consistency metric to evaluate how well subjective uncertainty aligns with objective uncertainty. In the offline setting, this alignment is measured using the Point-Biserial Correlation Coefficient (PBC). For online training, because of limited sampling and dynamically shifting output distributions, PBC estimation is difficult. Therefore, we introduce a new online variant, computed from normalized advantage and subjective uncertainty. Theoretically, we prove that the online variant is strictly negatively correlated with offline PBC and supports better sample selection. Experiments show our method consistently outperforms random and classic AL baselines, achieving full-dataset performance while training on only 30% of the data, effectively reducing the cost of RLVR for reasoning tasks.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22595" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22595" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22595" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods / Representation Learning, Advanced Architectures, Inference</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">16. A Step Back: Prefix Importance Ratio Stabilizes Policy Optimization
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Shiye Lei, Zhihao Cheng, Dacheng Tao</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The Minimum Prefix Ratio (MinPRO) objective stabilizes off-policy RL post-training for LLMs by replacing the unstable prefix importance ratio with a non-cumulative surrogate based on the minimum token-level ratio, leading to improved stability and performance on reasoning benchmarks. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Reinforcement learning (RL) post-training has increasingly demonstrated strong ability to elicit reasoning behaviors in large language models (LLMs). For training efficiency, rollouts are typically generated in an off-policy manner using an older sampling policy and then used to update the current target policy. To correct the resulting discrepancy between the sampling and target policies, most existing RL objectives rely on a token-level importance sampling ratio, primarily due to its computational simplicity and numerical stability. However, we observe that token-level correction often leads to unstable training dynamics when the degree of off-policyness is large. In this paper, we revisit LLM policy optimization under off-policy conditions and show that the theoretically rigorous correction term is the prefix importance ratio, and that relaxing it to a token-level approximation can induce instability in RL post-training. To stabilize LLM optimization under large off-policy drift, we propose a simple yet effective objective, Minimum Prefix Ratio (MinPRO). MinPRO replaces the unstable cumulative prefix ratio with a non-cumulative surrogate based on the minimum token-level ratio observed in the preceding prefix. Extensive experiments on both dense and mixture-of-experts LLMs, across multiple mathematical reasoning benchmarks, demonstrate that MinPRO substantially improves training stability and peak performance in off-policy regimes.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22718" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22718" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22718" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods / Representation Learning, Advanced Architectures, Inference</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">17. Exploring Layered Structure Inside Earth Using Atmospheric Neutrino Oscillation at IceCube DeepCore
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>J Krishnamoorthi</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Utilizing the matter effects imprinted on multi-GeV atmospheric neutrino oscillations, IceCube DeepCore can distinguish between homogeneous and layered Earth density profiles, rejecting the simpler homogeneous model at a $1.4\sigma$ confidence level using 9.3 years of data. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The IceCube detector, using its densely instrumented center, called DeepCore, can detect multi-GeV atmospheric neutrinos. The oscillation pattern of neutrinos is altered due to interactions with ambient electrons as they pass through Earth. The changes in these patterns are influenced by the amount of matter and its specific arrangement. As neutrinos propagate, they retain information about the densities they encounter. Our study demonstrates that IceCube DeepCore can utilize the Earth&#39;s matter effects to distinguish between a homogeneous matter density profile and a layered structure density profile of Earth. In this contribution, we present that IceCube DeepCore data equivalent to 9.3 years of observation can reject the homogeneous matter density profile with a confidence level of 1.4$σ$.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.23057" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.23057" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.23057" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">hep-ph</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">18. Real-Time Aligned Reward Model beyond Semantics
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">Zixuan Huang, Xin Xia, Yuxi Ren, Jianbin Zheng, Xuefeng Xiao, Hongyan Xie, Li Huaqiu, Songshi Liang, Zhongxiang Dai, Fuzhen Zhuang, et al.</span>
                                <span class="author-full" style="display: none;">Zixuan Huang, Xin Xia, Yuxi Ren, Jianbin Zheng, Xuefeng Xiao, Hongyan Xie, Li Huaqiu, Songshi Liang, Zhongxiang Dai, Fuzhen Zhuang, Jianxin Li, Yikun Ban, Deqing Wang</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The R2M framework addresses reward overoptimization in RLHF by utilizing the evolving hidden states of the policy model as real-time feedback to continuously align the reward model with the shifting policy distribution, moving beyond reliance solely on semantic representations. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Reinforcement Learning from Human Feedback (RLHF) is a pivotal technique for aligning large language models (LLMs) with human preferences, yet it is susceptible to reward overoptimization, in which policy models overfit to the reward model, exploit spurious reward patterns instead of faithfully capturing human intent. Prior mitigations primarily relies on surface semantic information and fails to efficiently address the misalignment between the reward model (RM) and the policy model caused by continuous policy distribution shifts. This inevitably leads to an increasing reward discrepancy, exacerbating reward overoptimization. To address these limitations, we introduce R2M (Real-Time Aligned Reward Model), a novel lightweight RLHF framework. R2M goes beyond vanilla reward models that solely depend on the semantic representations of a pretrained LLM. Instead, it leverages the evolving hidden states of the policy (namely policy feedback) to align with the real-time distribution shift of the policy during the RL process. This work points to a promising new direction for improving the performance of reward models through real-time utilization of feedback from policy models.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22664" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22664" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22664" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods / Representation Learning, Advanced Architectures, Inference</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">19. Alignment among Language, Vision and Action Representations
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Nicola Milano, Stefano Nolfi</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Action-grounded language representations derived from embodied agents show robust cross-modal alignment with state-of-the-art decoder-only LLMs and vision-language models like BLIP, indicating a convergence toward shared, modality-independent semantic structures. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">A fundamental question in cognitive science and AI concerns whether different learning modalities: language, vision, and action, give rise to distinct or shared internal representations. Traditional views assume that models trained on different data types develop specialized, non-transferable representations. However, recent evidence suggests unexpected convergence: models optimized for distinct tasks may develop similar representational geometries. We investigate whether this convergence extends to embodied action learning by training a transformer-based agent to execute goal-directed behaviors in response to natural language instructions. Using behavioral cloning on the BabyAI platform, we generated action-grounded language embeddings shaped exclusively by sensorimotor control requirements. We then compared these representations with those extracted from state-of-the-art large language models (LLaMA, Qwen, DeepSeek, BERT) and vision-language models (CLIP, BLIP). Despite substantial differences in training data, modality, and objectives, we observed robust cross-modal alignment. Action representations aligned strongly with decoder-only language models and BLIP (precision@15: 0.70-0.73), approaching the alignment observed among language models themselves. Alignment with CLIP and BERT was significantly weaker. These findings indicate that linguistic, visual, and action representations converge toward partially shared semantic structures, supporting modality-independent semantic organization and highlighting potential for cross-domain transfer in embodied AI systems.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22948" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22948" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22948" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods / Representation Learning, Advanced Architectures, Inference</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">20. The size-velocity dispersion relationship of Galactic HII regions
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">Lin Ma, Yunning Zhao, Wei Zhang, Youliang Feng, Shiming Wen, Shichao Han, Chaojian Wu, Juanjuan Ren, Jianjun Chen, Yuzhong Wu, et al.</span>
                                <span class="author-full" style="display: none;">Lin Ma, Yunning Zhao, Wei Zhang, Youliang Feng, Shiming Wen, Shichao Han, Chaojian Wu, Juanjuan Ren, Jianjun Chen, Yuzhong Wu, Zhongrui Bai, Yonghui Hou, Yongheng Zhao, Hong Wu</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> An evolutionary transition in turbulence mechanisms is observed in small HII regions, where the size-velocity dispersion relation shifts from being weak and dominated by stellar input in young, density-bounded regions to being strongly correlated and driven by expansion in older, matter-bounded regions. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The size-velocity dispersion ($σ$) relation, while well established for giant HII regions, remains uncertain for their smaller counterparts (physical radii R 0.5 Myr), matter-bounded HII regions, a clear correlation emerges, implying that expansion-driven processes begin to play a significant role in generating turbulence. We therefore propose an evolutionary transition in the primary turbulence mechanisms, from being dominated by stellar winds and radiation to being increasingly influenced by expansion-driven dynamics, during the evolution of HII regions. Considering the small sample size used in this work, particularly the inclusion of only two young HII regions, which also have large uncertainties in their expansion velocities, further confirmation of this interpretation will require higher-resolution 2D spectroscopy to resolve blended kinematic components along the line of sight for more accurate estimation of expansion velocities, along with an expanded sample that specifically includes more young HII regions.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22656" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22656" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22656" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">21. Physically-motivated priors in the local distance ladder significantly reduce the Hubble tension
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Marcus Högås, Edvard Mörtsell</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Applying physically motivated, uniform priors to distance moduli in the local distance ladder recalibration shifts the inferred Hubble constant from $73.0$ to $70.6$ km/s/Mpc, substantially reducing the Hubble tension from $5\sigma$ to $2\sigma$. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Determinations of the Hubble constant based on the local distance ladder remain in significant tension with early-Universe inferences from the cosmic microwave background. While this tension is often discussed in terms of new physics or unmodeled systematics, the role of the assumed priors on the model parameters has received comparatively little attention. Recently, Desmond et al. (2025) pointed out that the commonly adopted flat prior on distance moduli upweights smaller distances and systematically favors high inferred values of the Hubble constant. Motivated by this observation, we perform a comprehensive Bayesian recalibration of the distance ladder, applying physically motivated priors uniformly to all distances, including the Milky Way Cepheids, which are incorporated directly into the joint fit. Together with a conservative treatment of the Gaia EDR3 residual parallax offset, the Hubble constant shifts from $H_0 = 73.0 \pm 1.0 \, \mathrm{km/s/Mpc}$ to $H_0 = 70.6 \pm 1.0 \, \mathrm{km/s/Mpc}$, reducing the Hubble tension from $5 \, σ$ to $2 \, σ$. Our results show that the assumed priors -- often treated as innocuous defaults -- may play a central role in the Hubble tension. Because all local distance ladders rely on the calibration of distances, similar prior-driven effects are expected to arise across distance-ladder methods.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22215" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22215" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22215" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">22. Scalar-tensor-vector gravity theory is tested by black hole photon rings
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Qiao Yue</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Analysis of the Reissner-Nordström black hole within scalar-tensor-vector gravity demonstrates that the MOG parameter and charge uniquely determine the non-degenerate photon ring radius, offering a distinct optical diagnostic for testing modified gravity models consistent with EHT observations. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">This paper investigates the photon ring and shadow structure of the Reissner-Nordström black hole in the scalar-tensor-vector gravitational framework. The black hole is characterized by the ( MOG) parameter (α) and the charge (Q). The study finds that as (α) increases, the event horizon radius (r_h), photon sphere radius (r_{ph}), and critical impact parameter (b_{ph}) all increase, while these decrease as (Q) increases. The innermost stable circular orbit radius (r_{isco}) exhibits similar monotonic behavior. Ray-tracing shows that as (Q) increases, the impact parameter (b) interval between the lensing ring and photon ring widens; (b_{\text{ph}}) is non-degenerate, and the photon ring radius is uniquely determined by (α) and (Q). Using $EHT$ constraints on (SgrA^*) and (M87^*), the bounds on (α) and (Q) are derived. For (Q = 0), (0.5), and (1), the allowed ranges are (α\in [0, 0.06]), ([0, 0.11]), and ([0.19, 0.36]), respectively. Radiative simulations show that for fixed (Q), larger (α) leads to a larger, non-degenerate photon ring. The Schwarzschild case is approached only when both (α) and (Q) are small. This provides a computational basis for testing modified black holes and offers a non-degenerate observational criterion for distinguishing quantum gravity models, consistent with current $EHT$ data. Future observations with $ngEHT$ and multi-band polarization can further test this. The results suggest that studying the photon ring structure of a Reissner-Nordström black hole in scalar-tensor-vector gravity provides a unique optical diagnostic for potential quantum-gravity tests and black hole properties.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.23012" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.23012" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.23012" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">gr-qc</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">23. EntroCut: Entropy-Guided Adaptive Truncation for Efficient Chain-of-Thought Reasoning in Small-scale Large Reasoning Models
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Hongxi Yan, Qingjie Liu, Yunhong Wang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> EntroCut, a training-free method, leverages output distribution entropy in early steps to dynamically truncate the chain-of-thought reasoning of Large Reasoning Models, achieving superior efficiency-performance trade-offs by reducing token usage up to 40%. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Large Reasoning Models (LRMs) excel at complex reasoning tasks through extended chain-of-thought generation, but their reliance on lengthy intermediate steps incurs substantial computational cost. We find that the entropy of the model&#39;s output distribution in early reasoning steps reliably distinguishes correct from incorrect reasoning. Motivated by this observation, we propose EntroCut, a training-free method that dynamically truncates reasoning by identifying high-confidence states where reasoning can be safely terminated. To comprehensively evaluate the trade-off between efficiency and accuracy, we introduce the Efficiency-Performance Ratio (EPR), a unified metric that quantifies relative token savings per unit accuracy loss. Experiments on four benchmarks show that EntroCut reduces token usage by up to 40\% with minimal accuracy sacrifice, achieving superior efficiency-performance trade-offs compared with existing training-free methods. These results demonstrate that entropy-guided dynamic truncation provides a practical approach to mitigate the inefficiency of LRMs.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22617" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22617" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22617" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods / Representation Learning, Advanced Architectures, Inference</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">24. Test-Time Mixture of World Models for Embodied Agents in Dynamic Environments
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Jinwoo Jang, Minjong Yoo, Sihyung Yoon, Honguk Woo</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The Test-time Mixture of World Models (TMoW) framework enhances the adaptability of embodied agents in dynamic environments by implementing test-time refinement and multi-granular prototype-based routing to continually update the mixture of world models during inference. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Language model (LM)-based embodied agents are increasingly deployed in real-world settings. Yet, their adaptability remains limited in dynamic environments, where constructing accurate and flexible world models is crucial for effective reasoning and decision-making. To address this challenge, we extend the Mixture-of-Experts (MoE) paradigm to embodied agents. While conventional MoE architectures modularize knowledge into expert components with pre-trained routing, they remain rigid once deployed, making them less effective for adapting to unseen domains in dynamic environments. We therefore propose Test-time Mixture of World Models (TMoW), a framework that enhances adaptability to unseen and evolving domains. TMoW updates its routing function over world models at test time, unlike conventional MoE where the function remains fixed, enabling agents to recombine existing models and integrate new ones for continual adaptation. It achieves this through (i) multi-granular prototype-based routing, which adapts mixtures across object- to scene-level similarities, (ii) test-time refinement that aligns unseen domain features with prototypes during inference, and (iii) distilled mixture-based augmentation, which efficiently constructs new models from few-shot data and existing prototypes. We evaluate TMoW on VirtualHome, ALFWorld, and RLBench benchmarks, demonstrating strong performance in both zero-shot adaptation and few-shot expansion scenarios, and showing that it enables embodied agents to operate effectively in dynamic environments.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22647" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22647" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22647" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods / Representation Learning, Advanced Architectures, Inference</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">25. TSPO: Breaking the Double Homogenization Dilemma in Multi-turn Search Policy Optimization
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">Shichao Ma, Zhiyuan Ma, Ming Yang, Xiaofan Li, Xing Wu, Jintao Du, Yu Cheng, Weiqiang Wang, Qiliang Liu, Zhengyang Zhou, et al.</span>
                                <span class="author-full" style="display: none;">Shichao Ma, Zhiyuan Ma, Ming Yang, Xiaofan Li, Xing Wu, Jintao Du, Yu Cheng, Weiqiang Wang, Qiliang Liu, Zhengyang Zhou, Yang Wang</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Turn-level Stage-aware Policy Optimization (TSPO) addresses the sparse reward problem in multi-turn tool-integrated reasoning by using the First-Occurrence Latent Reward (FOLR) mechanism to provide process-level signals, resulting in substantial performance gains over state-of-the-art baselines. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Multi-turn tool-integrated reasoning enables Large Language Models (LLMs) to solve complex tasks through iterative information retrieval. However, current reinforcement learning (RL) frameworks for search-augmented reasoning predominantly rely on sparse outcome-level rewards, leading to a &#34;Double Homogenization Dilemma.&#34; This manifests as (1) Process homogenization, where the thinking, reasoning, and tooling involved in generation are ignored. (2) Intra-group homogenization, coarse-grained outcome rewards often lead to inefficiencies in intra-group advantage estimation with methods like Group Relative Policy Optimization (GRPO) during sampling. To address this, we propose Turn-level Stage-aware Policy Optimization (TSPO). TSPO introduces the First-Occurrence Latent Reward (FOLR) mechanism, allocating partial rewards to the step where the ground-truth answer first appears, thereby preserving process-level signals and increasing reward variance within groups without requiring external reward models or any annotations. Extensive experiments demonstrate that TSPO significantly outperforms state-of-the-art baselines, achieving average performance gains of 24% and 13.6% on Qwen2.5-3B and 7B models, respectively.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22776" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22776" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22776" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods / Representation Learning, Advanced Architectures, Inference</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">26. Statistical study for binary star evolution in dense embedded clusters
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Wenjie Wu, Pavel Kroupa, Vikrant V. Jadhav</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Direct N-body simulations characterizing the early dynamical evolution of primordial binaries in embedded star clusters reveal that binding energy and orbital period are the primary governing factors, leading to the enhancement of high mass-ratio systems and providing an improved dynamical operator for Galactic population synthesis. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Context: The dynamical evolution of binary populations in embedded star clusters shapes the statistical properties of binaries observed in the Galactic field. Accurately modelling this process requires resolving both early cluster dynamics and binary interactions. Aims: We aim to characterize the early dynamical evolution of primordial binaries in embedded clusters and identify the key parameters that govern binary survival and disruption. Methods: We perform a set of direct $N$-body simulations starting from 100\% primordial binaries in a time-varying gas potential of a gas-embedded cluster. To describe the evolution of binary orbital properties, we define empirical dynamical operators for period, binding energy, and mass ratio, and calibrate them across the simulated ensemble. Results:The binding energy and orbital period evolve in a consistent, sigmoidal fashion. Their dynamical operators reveal that hard binaries heat the cluster and suppress wide binary formation, while a small residual population of soft binaries survives. The evolution of the mass-ratio distribution is less directly linked to dynamical processing and more shaped by internal processes such as stellar physics process in the pre-main-sequence phase. High-$q$ systems tend to be enhanced, while low-$q$ systems are prone to disruption. Conclusions: The binary evolution in clusters is primarily governed by binding energy and orbital period. Our model improves over previous parameterizations of the dynamical operator by allowing for the existence of wide binaries and incorporating the embedded cluster phase. For individual clusters, direct $N$-body modelling remains the only reliable approach. On Galactic scales, population synthesis methods based on the stellar dynamical operator approach developed here remain essential.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22767" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22767" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22767" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">27. Cosmological Dynamics of Hyperbolic Evolution Models in $f(Q,L_m)$ Gravity
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>V. A. Kshirsagar, S. A. Kadam, Vishwajeet S. Goswami</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Two cosmologically viable sine and cosine hyperbolic models within $f(Q,\mathcal{L}_m)$ gravity successfully describe the universe&#39;s transition from early deceleration to late-time acceleration, exhibiting a quintessence-like equation of state parameter that approaches the $\Lambda$CDM model. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">This paper highlights cosmologically viable sine and cosine hyperbolic evolution functions in the framework of $f(Q,\mathcal{L}_m)$ gravity. The models have been tested to check the behavior of the equation of state (EoS) parameter under the variation of parametric values. The EoS parameter experiences a quintessence phase, and is approaching to $-1$ at late time. The models are showing inclined behaviour with the $Λ$CDM model at the late time. The viability of both the models is retested using the widely accepted energy conditions in both cases. The violation of the strong energy condition admits the accelerating behaviour of the models. The same has been explained through the analysis of the profile of deceleration parameter, which concretely supports the evidence that the models explain early deceleration to late time acceleration phenomena.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22780" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22780" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22780" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">gr-qc</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">28. JAF: Judge Agent Forest
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Sahil Garg, Brad Cheezum, Sridhar Dutta, Vishal Agarwal</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The Judge Agent Forest (JAF) framework enhances LLM self-refinement by enabling judge agents to perform joint inference across related responses, using a flexible locality-sensitive hashing algorithm to select diverse peer exemplars and propagate robust, context-sensitive critique. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Judge agents are fundamental to agentic AI frameworks: they provide automated evaluation, and enable iterative self-refinement of reasoning processes. We introduce JAF: Judge Agent Forest, a framework in which the judge agent conducts joint inference across a cohort of query--response pairs generated by a primary agent, rather than evaluating each in isolation. This paradigm elevates the judge from a local evaluator to a holistic learner: by simultaneously assessing related responses, the judge discerns cross-instance patterns and inconsistencies, whose aggregate feedback enables the primary agent to improve by viewing its own outputs through the judge&#39;s collective perspective. Conceptually, JAF bridges belief propagation and ensemble-learning principles: overlapping in-context neighborhoods induce a knowledge-graph structure that facilitates propagation of critique, and repeated, randomized evaluations yield a robust ensemble of context-sensitive judgments. JAF can be instantiated entirely via ICL, with the judge prompted for each query using its associated primary-agent response plus a small, possibly noisy set of peer exemplars. While kNN in embedding space is a natural starting point for exemplars, this approach overlooks categorical structure, domain metadata, or nuanced distinctions accessible to modern LLMs. To overcome these limitations, we develop a flexible locality-sensitive hashing (LSH) algorithm that learns informative binary codes by integrating semantic embeddings, LLM-driven hash predicates, supervision from categorical labels, and relevant side information. These hash codes support efficient, interpretable, and relation-aware selection of diverse exemplars, and further optimize exploration of CoT reasoning paths. We validate JAF with an empirical study on the demanding task of cloud misconfigs triage in large-scale cloud environments.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22269" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22269" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22269" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods / Representation Learning, Advanced Architectures, Inference</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">29. Scaling Multiagent Systems with Process Rewards
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Ed Li, Junyu Ren, Cat Yan</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Per-Action Process Rewards from AI Feedback (MAPPA) improves the finetuning of multiagent systems by assigning credit to individual agent actions rather than just task completion, significantly boosting success rates on complex, long-horizon tasks like competition math and data analysis. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">While multiagent systems have shown promise for tackling complex tasks via specialization, finetuning multiple agents simultaneously faces two key challenges: (1) credit assignment across agents, and (2) sample efficiency of expensive multiagent rollouts. In this work, we propose finetuning multiagent systems with per-action process rewards from AI feedback (MAPPA) to address both. Through assigning credit to individual agent actions rather than only at task completion, MAPPA enables fine-grained supervision without ground truth labels while extracting maximal training signal from each rollout. We demonstrate our approach on competition math problems and tool-augmented data analysis tasks. On unseen math problems, MAPPA achieves +5.0--17.5pp on AIME and +7.8--17.2pp on AMC. For data analysis tasks, our method improves success rate by +12.5pp while quality metrics improve by up to 30%, validating that per-action supervision can lead to improvements across different multiagent system on various domains. By addressing these challenges, our work takes a first step toward scaling multiagent systems for complex, long-horizon tasks with minimal human supervision.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.23228" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.23228" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.23228" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods / Representation Learning, Advanced Architectures, Inference</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">30. Modified Teleparallel $f(T)$ Gravity, DESI BAO and the $H_0$ Tension
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Mariam Bouhmadi-López, Carlos G. Boiza, Maria Petronikolou, Emmanuel N. Saridakis</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Late-time modifications of gravity within the minimal $f(T)$ teleparallel framework can non-trivially redistribute cosmological tensions, with phantom-like regimes favoring higher $H_0$ values and partially shifting the Hubble constant toward local measurements, although the models are not statistically favored over $\Lambda$CDM. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We investigate whether late-time modifications of gravity in the teleparallel framework can impact the current tension in the Hubble constant $H_0$, focusing on $f(T)$ cosmology as a minimal and well-controlled extension of General Relativity. We consider three representative $f(T)$ parametrisations that recover the teleparallel equivalent of General Relativity at early times and deviate from it only at late epochs. The models are confronted with unanchored Pantheon+ Type~Ia supernovae, DESI DR2 baryon acoustic oscillations, compressed Planck cosmic microwave background distance priors, and redshift-space distortion data, allowing us to jointly probe the background expansion and the growth of cosmic structures. Two of the three models partially shift the inferred value of $H_0$ towards local measurements, while the third worsens the discrepancy. This behaviour is directly linked to the effective torsional dynamics, with phantom-like regimes favouring higher $H_0$ and quintessence-like regimes producing the opposite effect. A global statistical comparison shows that the minimal $f(T)$ extensions considered here are not favoured over $Λ$CDM by the combined data. Nevertheless, our results demonstrate that late-time torsional modifications can non-trivially redistribute current cosmological tensions among the background and growth sectors.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22225" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22225" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22225" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">gr-qc</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">31. Enhanced Stochastic Gravitational Waves signals from Wess-Zumino chiral superfield
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>AlexKen Lee, Keyun Wu</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Investigating the reheating era, a phenomenological model demonstrates that supersymmetry-preserving chiral multiplet structures substantially enhance the amplitude of the resulting stochastic gravitational-wave spectrum by at least an order of magnitude. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">In this work, we investigate the possibility that supersymmetric structures may leave observable imprints in the stochastic gravitational-wave (GW) background generated during the reheating era. To this end, we construct a phenomenological interaction vertex describing the coupling between a single inflaton and the D-term sectors of a pair of chiral and anti-chiral superfields. In contrast to the conventional Yukawa coupling between the inflaton and structureless matter fields, we find that the supersymmetry-preserving chiral multiplet structure leads to a substantial enhancement, by at least one order of magnitude, in the amplitude of the resulting GWs spectrum. Our results therefore suggest that the interplay between reheating-era stochastic GWs and supersymmetric phenomenology merits further exploration and development.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22421" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22421" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22421" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">hep-ph</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">32. Enhancing TableQA through Verifiable Reasoning Trace Reward
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Tung Sum Thomas Kwok, Xinyu Wang, Hengzhi He, Xiaofeng Lin, Peng Lu, Liheng Ma, Chunhe Wang, Ying Nian Wu, Lei Ding, Guang Cheng</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The RE-Tab framework enhances Table Question Answering performance and reduces inference cost by architecturally improving trajectory search via explicit, training-free reward modeling during stepwise table state transitions. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">A major challenge in training TableQA agents, compared to standard text- and image-based agents, is that answers cannot be inferred from a static input but must be reasoned through stepwise transformations of the table state, introducing multi-step reasoning complexity and environmental interaction. This leads to a research question: Can explicit feedback on table transformation action improve model reasoning capability? In this work, we introduce RE-Tab, a plug-and-play framework that architecturally enhances trajectory search via lightweight, training-free reward modeling by formulating the problem as a Partially Observable Markov Decision Process. We demonstrate that providing explicit verifiable rewards during State Transition (``What is the best action?&#39;&#39;) and Simulative Reasoning (``Am I sure about the output?&#39;&#39;) is crucial to steer the agent&#39;s navigation in table states. By enforcing stepwise reasoning with reward feedback in table transformations, RE-Tab achieves state-of-the-art performance in TableQA with almost 25\% drop in inference cost. Furthermore, a direct plug-and-play implementation of RE-Tab brings up to 41.77% improvement in QA accuracy and 33.33% drop in test-time inference samples for consistent answer. Consistent improvement pattern across various LLMs and state-of-the-art benchmarks further confirms RE-Tab&#39;s generalisability. The repository is available at https://github.com/ThomasK1018/RE_Tab .</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22530" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22530" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22530" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods / Representation Learning, Advanced Architectures, Inference</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">33. Study of the internal structure of the Earth using neutrino oscillations at IceCube DeepCore
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Sharmistha Chattopadhyay</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Utilizing atmospheric neutrino oscillations and their matter effects observed at DeepCore, scientists can independently estimate Earth&#39;s total mass and internal layer densities, a measurement expected to be refined by the upcoming IceCube Upgrade. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Earth&#39;s mass and internal structure have been primarily studied through gravitational and seismic methods. Neutrinos, however, offer an independent way to explore Earth&#39;s interior via matter effects in neutrino oscillations that depend on the electron distribution inside Earth, and hence its matter density. Our study uses atmospheric neutrinos at DeepCore, a densely instrumented sub-detector of the IceCube Neutrino Observatory, to estimate Earth&#39;s mass and layer densities. We also assess how the upcoming IceCube Upgrade, with denser instrumentation, could improve these measurements.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.23079" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.23079" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.23079" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.2</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">hep-ph</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">34. Amortized Simulation-Based Inference in Generalized Bayes via Neural Posterior Estimation
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Shiyi Sun, Geoff K. Nicholls, Jeong Eun Lee</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A novel, fully amortized variational approximation uses a single conditioned neural posterior estimator trained via self-normalized importance sampling to efficiently sample from the tempered posterior family in Generalized Bayesian Inference across various temperature parameters. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Generalized Bayesian Inference (GBI) tempers a loss with a temperature $β&gt;0$ to mitigate overconfidence and improve robustness under model misspecification, but existing GBI methods typically rely on costly MCMC or SDE-based samplers and must be re-run for each new dataset and each $β$ value. We give the first fully amortized variational approximation to the tempered posterior family $p_β(θ\mid x) \propto π(θ)\,p(x \mid θ)^β$ by training a single $(x,β)$-conditioned neural posterior estimator $q_φ(θ\mid x,β)$ that enables sampling in a single forward pass, without simulator calls or inference-time MCMC. We introduce two complementary training routes: (i) synthesize off-manifold samples $(θ,x) \sim π(θ)\,p(x \mid θ)^β$ and (ii) reweight a fixed base dataset $π(θ)\,p(x \mid θ)$ using self-normalized importance sampling (SNIS). We show that the SNIS-weighted objective provides a consistent forward-KL fit to the tempered posterior with finite weight variance. Across four standard simulation-based inference (SBI) benchmarks, including the chaotic Lorenz-96 system, our $β$-amortized estimator achieves competitive posterior approximations in standard two-sample metrics, matching non-amortized MCMC-based power-posterior samplers over a wide range of temperatures.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22367" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22367" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22367" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">stat.ML</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">35. Establishing Earth&#39;s Matter Effect in Atmospheric Neutrino Oscillations at IceCube DeepCore
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Anuj Kumar Upadhyay</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Preliminary results from the IceCube DeepCore detector confirm its sensitivity to observe Earth&#39;s matter effects on three-flavor atmospheric neutrino oscillations, allowing for the rejection of the vacuum oscillation hypothesis in favor of the Preliminary Reference Earth Model. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The discovery of the non-zero value of $θ_{13}$ has opened an exciting opportunity to probe the Earth&#39;s matter effects in three-flavor oscillations of atmospheric neutrinos. These matter effects depend on both neutrino energy and the electron density distributions encountered during their propagation through Earth. In this contribution, we present preliminary sensitivities from the DeepCore detector, a densely instrumented sub-array of the IceCube neutrino observatory at the South Pole, demonstrating its ability to observe these matter effects in atmospheric neutrino oscillations. Using simulated data equivalent to 9.3 years of observations at IceCube DeepCore, we show the sensitivity of the DeepCore to reject the vacuum oscillation hypothesis and align with the Preliminary Reference Earth Model. Additionally, we present the expected improvement in sensitivity for rejecting the vacuum oscillations using the upcoming IceCube Upgrade, a low-energy extension of the IceCube detector.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.23047" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.23047" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.23047" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">hep-ph</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">36. Corrected Samplers for Discrete Flow Models
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Zhengyan Wan, Yidong Ouyang, Liyan Xie, Fang Fang, Hongyuan Zha, Guang Cheng</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> By establishing non-asymptotic discretization error bounds for Discrete Flow Model samplers, researchers developed location- and time-corrected samplers that significantly reduce iteration complexity and improve generation quality in simulation and text-to-image tasks. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Discrete flow models (DFMs) have been proposed to learn the data distribution on a finite state space, offering a flexible framework as an alternative to discrete diffusion models. A line of recent work has studied samplers for discrete diffusion models, such as tau-leaping and Euler solver. However, these samplers require a large number of iterations to control discretization error, since the transition rates are frozen in time and evaluated at the initial state within each time interval. Moreover, theoretical results for these samplers often require boundedness conditions of the transition rate or they focus on a specific type of source distributions. To address those limitations, we establish non-asymptotic discretization error bounds for those samplers without any restriction on transition rates and source distributions, under the framework of discrete flow models. Furthermore, by analyzing a one-step lower bound of the Euler sampler, we propose two corrected samplers: \textit{time-corrected sampler} and \textit{location-corrected sampler}, which can reduce the discretization error of tau-leaping and Euler solver with almost no additional computational cost. We rigorously show that the location-corrected sampler has a lower iteration complexity than existing parallel samplers. We validate the effectiveness of the proposed method by demonstrating improved generation quality and reduced inference time on both simulation and text-to-image generation tasks. Code can be found in https://github.com/WanZhengyan/Corrected-Samplers-for-Discrete-Flow-Models.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22519" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22519" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22519" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">stat.ML</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">37. Too many or too massive? Investigating the high-$z$ demography of active SMBHs from JWST
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">Daniel Roberts, Francesco Shankar, Vieri Cammelli, Fabio Fontanot, Alessandro Trinca, Laura Bisigello, Elena Dalla Bonta, Hao Fu, Roberto Gilli, Andrea Grazian, et al.</span>
                                <span class="author-full" style="display: none;">Daniel Roberts, Francesco Shankar, Vieri Cammelli, Fabio Fontanot, Alessandro Trinca, Laura Bisigello, Elena Dalla Bonta, Hao Fu, Roberto Gilli, Andrea Grazian, Luca Graziani, Andrea Lapi, Nicola Menci, Jan Scholtz, Karthik Mahesh Varadarajan</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Continuity-equation modeling, constrained by JWST observations of high-redshift low-luminosity active galactic nuclei, suggests that Supermassive Black Holes at $z \sim 5$ lie slightly above local scaling relations, favoring moderate initial mass relations over steep evolutionary scenarios. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Recent JWST observations have unveiled a numerous population of low-luminosity active galactic nuclei (AGN) at $4 5.5$. Continuity-equation modelling shows that initially high $M_{\rm BH}-M_{*}$ relations predict a strong two-phase evolutionary scenario and very steep low-mass SMBH mass functions in tension with several current estimates, while more moderate relations generate local SMBH mass functions in better agreement with present determinations and near-constant scaling relations. Our results favour a scenario where SMBHs at $z \sim 5$ on average lie modestly above local AGN scaling relations, with elevated but physically plausible duty cycles. Future wide-field clustering and demographic studies will help break the remaining degeneracies between SMBH scaling relations and AGN duty cycles at early cosmic times.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.23250" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.23250" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.23250" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">38. Insights into the Physical Nature of Polar Ring Galaxies from H I Observations
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">Niankun Yu, Han Zheng, Chao-Wei Tsai, Pei Zuo, Luis C. Ho, Amelie Saintonge, Zheng Zheng, Nathan Deg, Ningyu Tang, Xin Ai, et al.</span>
                                <span class="author-full" style="display: none;">Niankun Yu, Han Zheng, Chao-Wei Tsai, Pei Zuo, Luis C. Ho, Amelie Saintonge, Zheng Zheng, Nathan Deg, Ningyu Tang, Xin Ai, Junzhi Wang, Xiang Jie, Di Li</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Kinematic analysis of Polar Ring Galaxies (PRGs) reveals that they are gas-rich outliers occupying the green valley, and their adherence to the Baryonic Tully-Fisher relation depends critically on assuming the H I gas is primarily confined to the polar ring rather than the host galaxy. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Polar ring galaxies (PRGs) host an outer ring of gas and stars oriented nearly perpendicular to the main stellar body. They represent extreme examples of misaligned systems and provide valuable insight into galaxy interactions, gas accretion, and peculiar gas dynamics. We compile a complete sample of kinematically confirmed PRGs and collect their H I measurements. Combining literature data with new observations from FAST, we detect H I emission in 22 sources, identify one potential H I absorption feature, and find four non-detections among 40 confirmed PRGs. Compared to galaxies in the ALFALFA and xGASS surveys, PRGs predominantly occupy the green valley or quenched regimes but exhibit higher gas fractions than typical early-type galaxies, suggesting gas accretion. The H I profile asymmetry and shape for PRGs are not consistent with that of the ALFALFA sample with p&lt;0.05. We examine their Tully-Fisher relation (TFR) and baryonic TFR (bTFR), linking the systems&#39; rotation velocities to their masses. The extreme outliers in TFRs for the control sample tend to display single-peaked H I profiles. PRGs do not follow a tight TFR or bTFR if the H I resides primarily in the host galaxy. But the scatter decreases significantly if we assume the gas is mainly distributed in the polar ring. Spatially resolved H I observations are essential to disentangle the gas distribution and kinematics in PRGs, which are key to understanding their formation mechanisms.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22222" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22222" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22222" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">39. Helicity Soft Dipole Pomeron Model for Vetor Meson Photoproduction by Circularly or Linearly Polarized Photons down to the Production Threshold
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Dart-yin A. Soh</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A novel dipole Pomeron model, constructed within the Regge theory framework, accurately describes vector meson photoproduction by simultaneously fitting cross sections and spin-density matrix elements, offering improved agreement with experimental data and insights into strong interaction dynamics. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We present a model with dipole Pomeron bassed on Regge theory framework for vetor meson photoproduction by arbitarily polaried photons. The accurate helicity amplitude is constructed with free trajectory parameters. This model consistently describes the total and momentum-transfer differential cross sections and he spin-density matrix elements in photoproduction of $ρ^{0}$, by fitting it to the data of $3$ categories simultaneously to determine its $20$ parameters. The agreements with experimental data of our model improve those of the previous models remarkably and predictions for circular SDMEs are made. The model provides key description of the process for our innovative polarimetry of cosmic photons and essential insight to explore the non-perturbative regime and the spin dynamics of strong interaction.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22826" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22826" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22826" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">hep-ph</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">40. Spectral Gradient Descent Mitigates Anisotropy-Driven Misalignment: A Case Study in Phase Retrieval
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Guillaume Braun, Han Bao, Wei Huang, Masaaki Imaizumi</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Analyzing a nonlinear phase retrieval model, researchers determined that spectral gradient descent accelerates training by eliminating the variance-induced misalignment that plagues standard gradient descent in anisotropic input settings. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Spectral gradient methods, such as the Muon optimizer, modify gradient updates by preserving directional information while discarding scale, and have shown strong empirical performance in deep learning. We investigate the mechanisms underlying these gains through a dynamical analysis of a nonlinear phase retrieval model with anisotropic Gaussian inputs, equivalent to training a two-layer neural network with the quadratic activation and fixed second-layer weights. Focusing on a spiked covariance setting where the dominant variance direction is orthogonal to the signal, we show that gradient descent (GD) suffers from a variance-induced misalignment: during the early escaping stage, the high-variance but uninformative spike direction is multiplicatively amplified, degrading alignment with the true signal under strong anisotropy. In contrast, spectral gradient descent (SpecGD) removes this spike amplification effect, leading to stable alignment and accelerated noise contraction. Numerical experiments confirm the theory and show that these phenomena persist under broader anisotropic covariances.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22652" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22652" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22652" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">stat.ML</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">41. Linear perturbation theory and structure formation in a Brans-Dicke theory of gravity without dark matter
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Lorenzo Gervani, Antonaldo Diaferio, Francesco Pace, Andrea Pierfrancesco Sanna</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A scalar-tensor gravity model, which reduces to Refracted Gravity in the weak-field limit and attempts to explain cosmic dynamics without dark matter, severely delays structure formation until low redshift, contradicting early galaxy observations. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We investigate the formation of the large-scale cosmic structure in a scalar-tensor theory of gravity belonging to the class of the Brans--Dicke theories. The universe contains baryonic matter alone and neither dark matter nor dark energy. The two arbitrary functions of the scalar field characterizing the kinetic term and the self-interaction potential are set to $W(\varphi)=-1$ and $V(\varphi) = -Ξ\varphi$, respectively, with $Ξ$ a positive constant. In the weak-field limit, the theory reduces to Refracted Gravity, a non-relativistic theory whose modified Poisson equation contains the scalar field $\varphi$ that provides the gravitational boost required to describe the dynamics of galaxies and galaxy clusters without dark matter. In a flat, matter-dominated, homogeneous and isotropic universe the same scalar field $\varphi$ drives the accelerated expansion of the universe and describes the observed redshift evolution of the Hubble-Lemaître parameter $H(z)$. However, in the equation of the growth factor of the linear perturbation theory, the form of $V(\varphi)$ makes the coefficient of the source of the gravitational field proportional to $H^{-1}(z)$; therefore the gravitational field is strongly suppressed at early times and structure formation is delayed to redshift $z&lt; 1$, in disagreement with the observation of formed galaxies at much larger redshifts. In addition, the form of $W(\varphi)$ and a linear $V(\varphi)$ imply that $\varphi$ generates twice the gravitational boost on massive particles than on photons, with possible observable consequences on the gravitational lensing phenomenon. It remains to be investigated whether different choices of $W(\varphi)$ and $V(\varphi)$, that can still make the theory reduce to Refracted Gravity in the weak-field limit, might alleviate these problems.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22937" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22937" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22937" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Weak Lensing, Galaxy Clustering, Cosmological Constraints / Galaxy Clustering, Weak Lensing, Halo Occupation</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">42. Graph Attention Network for Node Regression on Random Geometric Graphs with Erdős--Rényi contamination
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Somak Laha, Suqi Liu, Morgane Austern</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Rigorous analysis demonstrates that a specialized Graph Attention Network, utilizing denoised proxy features, achieves provably lower asymptotic error in node regression tasks compared to standard methods when facing simultaneous covariate and edge corruption. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Graph attention networks (GATs) are widely used and often appear robust to noise in node covariates and edges, yet rigorous statistical guarantees demonstrating a provable advantage of GATs over non-attention graph neural networks~(GNNs) are scarce. We partially address this gap for node regression with graph-based errors-in-variables models under simultaneous covariate and edge corruption: responses are generated from latent node-level covariates, but only noise-perturbed versions of the latent covariates are observed; and the sample graph is a random geometric graph created from the node covariates but contaminated by independent Erdős--Rényi edges. We propose and analyze a carefully designed, task-specific GAT that constructs denoised proxy features for regression. We prove that regressing the response variables on the proxies achieves lower error asymptotically in (a) estimating the regression coefficient compared to the ordinary least squares (OLS) estimator on the noisy node covariates, and (b) predicting the response for an unlabelled node compared to a vanilla graph convolutional network~(GCN) -- under mild growth conditions. Our analysis leverages high-dimensional geometric tail bounds and concentration for neighbourhood counts and sample covariances. We verify our theoretical findings through experiments on synthetically generated data. We also perform experiments on real-world graphs and demonstrate the effectiveness of the attention mechanism in several node regression tasks.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.23239" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.23239" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.23239" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">stat.ML</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods / Representation Learning, Advanced Architectures, Inference</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">43. Task-Aware LLM Council with Adaptive Decision Pathways for Decision Support
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Wei Zhu, Lixing Yu, Hao-Ren Yao, Zhiwen Tang, Kun Yue</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The Task-Aware LLM Council (TALC) framework improves multi-step decision-making by combining Monte Carlo Tree Search with dynamic routing to specialized LLMs, leveraging structured success memory and dual-signal value estimation for enhanced performance and search efficiency. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Large language models (LLMs) have shown strong capabilities across diverse decision-making tasks. However, existing approaches often overlook the specialization differences among available models, treating all LLMs as uniformly applicable regardless of task characteristics. This limits their ability to adapt to varying reasoning demands and task complexities. In this work, we propose Task-Aware LLM Council (TALC), a task-adaptive decision framework that integrates a council of LLMs with Monte Carlo Tree Search (MCTS) to enable dynamic expert selection and efficient multi-step planning. Each LLM is equipped with a structured success memory profile derived from prior task trajectories, enabling semantic matching between current reasoning context and past successes. At each decision point, TALC routes control to the most contextually appropriate model and estimates node value using a dual-signal mechanism that fuses model-based evaluations with historical utility scores. These signals are adaptively weighted based on intra-node variance and used to guide MCTS selection, allowing the system to balance exploration depth with planning confidence. Experiments on WebShop, HumanEval, and the Game of 24 demonstrate that TALC achieves superior task success rates and improved search efficiency compared to strong baselines, validating the benefits of specialization-aware routing and adaptive planning.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22662" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22662" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22662" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods / Representation Learning, Advanced Architectures, Inference</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">44. Scattering sections from regular black holes immersed in perfect fluid dark matter
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Omar Pedraza, L. A. López, Isaac Fernández</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The presence of Perfect Fluid Dark Matter surrounding black holes significantly increases the classical scattering cross section and modifies the width of semi-classical interference fringes, suggesting important phenomenological effects near the horizon. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">In this contribution, we investigate the scattering cross sections of black holes immersed in perfect fluid dark matter (PFDM). We present both the classical and semi-classical scattering cross sections for different values of the parameter that characterizes the PFDM contribution. Our results show that the presence of dark matter increases the classical scattering cross section and modifies the width of the interference fringes in the semi-classical regime. In addition, the scattering cross section is also computed using the partial wave method for the black holes considered, exhibiting similar qualitative behavior. These findings suggest that the effects of dark matter surrounding black holes may play an important role in black holes phenomenology, particularly in certain regions near the black hole.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22299" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22299" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22299" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">gr-qc</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">45. Slow-roll approximations for Gauss-Bonnet inflation revisited
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Bogdan A. Rudenko, Maria A. Skugoreva, Alexey V. Toporensky</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Analyzing Gauss-Bonnet inflation with growing coupling functions reveals that advanced slow-roll approximations do not improve precision over standard methods, and in some cases perform worse, contradicting findings from models using decaying coupling functions. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">In our paper we consider the validity of slow-roll approximations for Gauss-Bonnet inflation introduced in [1]. In contrast to the cited paper where the coupling function before the Gauss-Bonnet term have been chosen as a decaying function of the scalar field, here we consider growing coupling functions. We have found that while in [1] new slow-roll approximations work considerably better, now they do not increase the precision. Moreover, we identify some cases where more involved approximations work worse than the standard one. Corresponding explanations of such a situation are given.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.23256" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.23256" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.23256" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">gr-qc</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">46. Make Anything Match Your Target: Universal Adversarial Perturbations against Closed-Source MLLMs via Multi-Crop Routed Meta Optimization
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Hui Lu, Yi Yu, Yiming Yang, Chenyu Yi, Xueyi Ke, Qixing Zhang, Bingquan Shen, Alex Kot, Xudong Jiang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The MCRMO-Attack framework significantly enhances Universal Targeted Transferable Adversarial Attacks against commercial Multimodal LLMs by stabilizing supervision through multi-crop aggregation, improving token reliability via alignability-gated routing, and meta-learning a cross-target perturbation prior. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Targeted adversarial attacks on closed-source multimodal large language models (MLLMs) have been increasingly explored under black-box transfer, yet prior methods are predominantly sample-specific and offer limited reusability across inputs. We instead study a more stringent setting, Universal Targeted Transferable Adversarial Attacks (UTTAA), where a single perturbation must consistently steer arbitrary inputs toward a specified target across unknown commercial MLLMs. Naively adapting existing sample-wise attacks to this universal setting faces three core difficulties: (i) target supervision becomes high-variance due to target-crop randomness, (ii) token-wise matching is unreliable because universality suppresses image-specific cues that would otherwise anchor alignment, and (iii) few-source per-target adaptation is highly initialization-sensitive, which can degrade the attainable performance. In this work, we propose MCRMO-Attack, which stabilizes supervision via Multi-Crop Aggregation with an Attention-Guided Crop, improves token-level reliability through alignability-gated Token Routing, and meta-learns a cross-target perturbation prior that yields stronger per-target solutions. Across commercial MLLMs, we boost unseen-image attack success rate by +23.7\% on GPT-4o and +19.9\% on Gemini-2.0 over the strongest universal baseline.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.23179" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.23179" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.23179" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">cs.AI</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods / Representation Learning, Advanced Architectures, Inference</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">47. Simulation-based Bayesian inference with ameliorative learned summary statistics -- Part I
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Getachew K. Befekadu</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Simulation-based Bayesian inference is enhanced by using a transformation based on the Cressie-Read discrepancy criterion to generate learned summary statistics that act as an empirical likelihood, facilitating robust inference and distributed computation for complex models. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">This paper, which is Part 1 of a two-part paper series, considers a simulation-based inference with learned summary statistics, in which such a learned summary statistic serves as an empirical-likelihood with ameliorative effects in the Bayesian setting, when the exact likelihood function associated with the observation data and the simulation model is difficult to obtain in a closed form or computationally intractable. In particular, a transformation technique which leverages the Cressie-Read discrepancy criterion under moment restrictions is used for summarizing the learned statistics between the observation data and the simulation outputs, while preserving the statistical power of the inference. Here, such a transformation of data-to-learned summary statistics also allows the simulation outputs to be conditioned on the observation data, so that the inference task can be performed over certain sample sets of the observation data that are considered as an empirical relevance or believed to be particular importance. Moreover, the simulation-based inference framework discussed in this paper can be extended further, and thus handling weakly dependent observation data. Finally, we remark that such an inference framework is suitable for implementation in distributed computing, i.e., computational tasks involving both the data-to-learned summary statistics and the Bayesian inferencing problem can be posed as a unified distributed inference problem that will exploit distributed optimization and MCMC algorithms for supporting large datasets associated with complex simulation models.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22441" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22441" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22441" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">stat.ML</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">48. Dependence-Aware Label Aggregation for LLM-as-a-Judge via Ising Models
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Krishnakumar Balasubramanian, Aleksandr Podkopaev, Shiva Prasad Kasiviswanathan</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Addressing the failure of conditional independence assumptions in large-scale AI evaluation, dependence-aware label aggregation models based on Ising graphical models prove strictly superior to classical methods, mitigating miscalibrated posteriors caused by correlated annotator judgments. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Large-scale AI evaluation increasingly relies on aggregating binary judgments from $K$ annotators, including LLMs used as judges. Most classical methods, e.g., Dawid-Skene or (weighted) majority voting, assume annotators are conditionally independent given the true label $Y\in\{0,1\}$, an assumption often violated by LLM judges due to shared data, architectures, prompts, and failure modes. Ignoring such dependencies can yield miscalibrated posteriors and even confidently incorrect predictions. We study label aggregation through a hierarchy of dependence-aware models based on Ising graphical models and latent factors. For class-dependent Ising models, the Bayes log-odds is generally quadratic in votes; for class-independent couplings, it reduces to a linear weighted vote with correlation-adjusted parameters. We present finite-$K$ examples showing that methods based on conditional independence can flip the Bayes label despite matching per-annotator marginals. We prove separation results demonstrating that these methods remain strictly suboptimal as the number of judges grows, incurring nonvanishing excess risk under latent factors. Finally, we evaluate the proposed method on three real-world datasets, demonstrating improved performance over the classical baselines.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22336" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22336" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22336" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">stat.ML</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods / Representation Learning, Advanced Architectures, Inference</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">49. Asymptotic Theory of Iterated Empirical Risk Minimization, with Applications to Active Learning
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Hugo Cui, Yue M. Lu</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Sharp asymptotic analysis of two-stage iterated Empirical Risk Minimization in the high-dimensional limit characterizes the test error, uncovering a critical resource allocation tradeoff in active learning and demonstrating a data-selection-driven double-descent behavior. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We study a class of iterated empirical risk minimization (ERM) procedures in which two successive ERMs are performed on the same dataset, and the predictions of the first estimator enter as an argument in the loss function of the second. This setting, which arises naturally in active learning and reweighting schemes, introduces intricate statistical dependencies across samples and fundamentally distinguishes the problem from classical single-stage ERM analyses. For linear models trained with a broad class of convex losses on Gaussian mixture data, we derive a sharp asymptotic characterization of the test error in the high-dimensional regime where the sample size and ambient dimension scale proportionally. Our results provide explicit, fully asymptotic predictions for the performance of the second-stage estimator despite the reuse of data and the presence of prediction-dependent losses. We apply this theory to revisit a well-studied pool-based active learning problem, removing oracle and sample-splitting assumptions made in prior work. We uncover a fundamental tradeoff in how the labeling budget should be allocated across stages, and demonstrate a double-descent behavior of the test error driven purely by data selection, rather than model size or sample count.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.23031" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.23031" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.23031" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">stat.ML</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods / Representation Learning, Advanced Architectures, Inference</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">50. Revisiting the energy-momentum squared gravity
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Mihai Marciu</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Incorporating thermodynamical corrections into Energy-Momentum Squared Gravity yields a stable scalar-tensor representation that successfully models the transition from the matter domination era to the late-time accelerated expansion of the Universe. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">In this paper we have revisited the energy-momentum squared gravity theory, by taking into account the second derivative of the matter Lagrangian with respect to the metric, encapsulating relations originated from thermodynamical grounds. After obtaining the scalar tensor representation of the energy-momentum squared gravity with the new corrections, we have analyzed the physical implications by relying on the linear stability theory. The results show that the current cosmological system is compatible with the expansion of the Universe for some specific matter Lagrangians, explaining the emergence of matter domination era, approaching the late time accelerated expansion era close to the de-Sitter phenomenology.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2601.22333" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2601.22333" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2601.22333" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.1</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">gr-qc</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Inference, Sampling Algorithms, Bayesian Methods</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
    </div>

    <footer class="footer">
        &copy; 2026 arXiv Daily · Powered by <a href="https://arxiv.org/" target="_blank">arXiv</a>
    </footer>
</body>
</html>