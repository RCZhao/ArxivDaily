<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>arXiv Daily: Backfill (2025-12-07 to 2025-12-14)</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Roboto:400,700&display=swap" rel="stylesheet">
    <style>
        body { font-family: 'Roboto', Arial, sans-serif; background: #f8f9fa; transition: background 0.3s; }
        .arxiv-card { margin: 2em auto; max-width: 900px; box-shadow: 0 2px 8px rgba(0,0,0,0.08); border-radius: 16px; transition: box-shadow 0.3s, transform 0.3s; }
        .arxiv-card:hover { box-shadow: 0 4px 12px rgba(0,0,0,0.1); transform: translateY(-1px); }
        .arxiv-title { background: linear-gradient(90deg, #0d6efd 60%, #6610f2 100%); color: #fff; border-radius: 16px 16px 0 0; padding: 1.5em; font-size: 1.5em; font-weight: 700; letter-spacing: 0.5px;}
        .arxiv-meta { font-size: 1em; color: #555; margin-bottom: 1em; }
        .arxiv-abstract { background: #fff; padding: 1.5em; border-radius: 0 0 16px 16px; font-size: 1.1em; line-height: 1.7;}
        .arxiv-links a { margin-right: 1em; }
        .arxiv-scores { margin-top: 1em; font-size: 1em; }
        .navbar { background: #fff; box-shadow: 0 2px 8px rgba(0,0,0,0.04);}
        .footer { text-align: center; color: #888; padding: 2em 0 1em 0; font-size: 0.95em;}
        @media (prefers-color-scheme: dark) {
            body { background: #181a1b; color: #e4e6eb; }
            .arxiv-card { background: #23272b; box-shadow: 0 2px 8px rgba(0,0,0,0.28);}
            .arxiv-card:hover { box-shadow: 0 5px 15px rgba(0,0,0,0.25); transform: translateY(-1px); }
            .arxiv-title { background: linear-gradient(90deg, #375a7f 60%, #6f42c1 100%);}
            .arxiv-abstract { background: #23272b; color: #e4e6eb;}
            .navbar { background: #23272b; color: #e4e6eb;}
            .text-muted { color: #adb5bd !important; }
        }
        /* Improved abstract readability */
        .arxiv-abstract-text {
            font-size: 1.1em;
            line-height: 1.7;
        }
        p.big {
            line-height: 1.6;
            font-size: large;
        }
    </style>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'] ],
          processEscapes: true
        }
      });
    </script>
    <script>
    function toggleAuthors(element) {
        const fullList = element.querySelector('.author-full');
        const shortList = element.querySelector('.author-short');
        const toggleText = element.querySelector('.author-toggle');
        
        fullList.style.display = fullList.style.display === 'none' ? 'inline' : 'none';
        shortList.style.display = shortList.style.display === 'none' ? 'inline' : 'none';
        toggleText.textContent = fullList.style.display === 'none' ? ' (show all)' : ' (show less)';
    }
    </script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
</head>
<body>
    <nav class="navbar navbar-expand-lg mb-4">
        <div class="container">
            <a class="navbar-brand fw-bold text-primary" href="#">arXiv Daily</a>
            <span class="navbar-text">Modern arXiv Reader</span>
        </div>
    </nav>

    
    <div class="container py-4">
        <header class="mb-4"><h2 class="display-6 text-center">Analysis of Your Favorites</h2></header>
        
        <div class="row justify-content-center">
            <div class="col-lg-8 mb-4">
                <div class="card">
                    <div class="card-header fw-bold">Interest Word Cloud</div>
                    <div class="card-body text-center p-2">
                        <img src="analysis_results/word_cloud.png" class="img-fluid rounded" alt="Word Cloud of favorite paper topics">
                    </div>
                </div>
            </div>
        </div>
        
        
        <div class="row justify-content-center">
            <div class="col-lg-8 mb-4">
                <div class="card">
                    <div class="card-header fw-bold">Interest Clusters</div>
                    <div class="card-body text-center p-2">
                        <img src="analysis_results/backfill_cluster_map.png" class="img-fluid rounded" alt="2D Cluster plot of favorite papers">
                    </div>
                </div>
            </div>
        </div>
        
    </div>
    

    <div class="container py-4">
        <header class="mb-4"><h1 class="display-5 text-center text-primary">arXiv: Backfill (2025-12-07 to 2025-12-14)</h1></header>

        
        <div class="row justify-content-center">
            <div class="col-lg-8 mb-4">
                <div class="card">
                    <div class="card-header fw-bold">Score Distribution of All Papers Found Today</div>
                    <div class="card-body text-center p-2">
                        <img src="analysis_results/score_distribution.png" class="img-fluid rounded" alt="Score distribution of all papers found today">
                    </div>
                </div>
            </div>
        </div>
        

        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">1. Euclid preparation. Review of forecast constraints on dark energy and modified gravity
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">Euclid Collaboration, N. Frusciante, M. Martinelli, L. Lombriser, A. Silvestri, M. Archidiacono, M. Baldi, M. Ballardini, N. Bartolo, E. Bellini, et al.</span>
                                <span class="author-full" style="display: none;">Euclid Collaboration, N. Frusciante, M. Martinelli, L. Lombriser, A. Silvestri, M. Archidiacono, M. Baldi, M. Ballardini, N. Bartolo, E. Bellini, G. Benevento, D. Bertacca, C. Bonvin, B. Bose, P. Brax, V. F. Cardone, S. Casas, M. Y. Elkhashab, P. G. Ferreira, F. Finelli, F. Hassani, S. Ilić, K. Koyama, M. Kunz, F. Lepori, J. Lesgourgues, C. J. A. P. Martins, D. F. Mota, J. Noller, F. Pace, D. Paoletti, G. Parimbelli, V. Pettorino, Z. Sakr, S. Srinivasan, E. M. Teixeira, I. Tutusaus, P. Valageas, H. -A. Winther, J. Adamek, I. S. Albuquerque, L. Atayde, M. -A. Breton, S. Camera, C. Carbone, E. Carella, P. Carrilho, F. J. Castander, R. Durrer, B. Fiorini, P. Fosalba, M. Marinucci, C. Moretti, M. Pietroni, L. Piga, G. Rácz, F. Sorrenti, F. Vernizzi, C. Viglione, L. Amendola, S. Andreon, C. Baccigalupi, S. Bardelli, R. Bender, A. Biviano, D. Bonino, E. Branchini, M. Brescia, J. Brinchmann, A. Caillat, G. Cañas-Herrera, V. Capobianco, J. Carretero, M. Castellano, G. Castignani, S. Cavuoti, K. C. Chambers, A. Cimatti, C. Colodro-Conde, G. Congedo, C. J. Conselice, L. Conversi, Y. Copin, F. Courbin, H. M. Courtois, M. Cropper, A. Da Silva, H. Degaudenzi, G. De Lucia, A. M. Di Giorgio, J. Dinis, H. Dole, F. Dubath, X. Dupac, S. Dusini, A. Ealet, S. Escoffier, M. Farina, S. Farrens, F. Faustini, S. Ferriol, S. Fotopoulou, M. Frailis, E. Franceschi, M. Fumana, S. Galeotta, B. Gillis, C. Giocoli, J. Gracia-Carpio, A. Grazian, F. Grupp, L. Guzzo, S. V. H. Haugan, H. Hoekstra, W. Holmes, I. Hook, F. Hormuth, A. Hornstrup, P. Hudelot, K. Jahnke, M. Jhabvala, B. Joachimi, E. Keihänen, S. Kermiche, A. Kiessling, B. Kubik, H. Kurki-Suonio, O. Lahav, A. M. C. Le Brun, S. Ligori, P. B. Lilje, V. Lindholm, I. Lloro, G. Mainetti, D. Maino, E. Maiorano, O. Mansutti, O. Marggraf, K. Markovic, N. Martinet, F. Marulli, R. Massey, S. Maurogordato, E. Medinaceli, S. Mei, M. Melchior, Y. Mellier, M. Meneghetti, E. Merlin, G. Meylan, A. Mora, M. Moresco, L. Moscardini, C. Neissner, R. C. Nichol, S. -M. Niemi, J. W. Nightingale, C. Padilla, S. Paltani, F. Pasian, K. Pedersen, W. J. Percival, S. Pires, G. Polenta, M. Poncet, L. A. Popa, L. Pozzetti, F. Raison, R. Rebolo, A. Renzi, J. Rhodes, G. Riccio, E. Romelli, M. Roncarelli, R. Saglia, A. G. Sánchez, D. Sapone, B. Sartoris, R. Scaramella, J. A. Schewtschenko, M. Schirmer, T. Schrabback, A. Secroun, E. Sefusatti, G. Seidel, M. Seiffert, S. Serrano, C. Sirignano, G. Sirri, A. Spurio Mancini, L. Stanco, J. Steinwagner, P. Tallada-Crespí, D. Tavagnacco, A. N. Taylor, I. Tereno, N. Tessore, S. Toft, R. Toledo-Moreo, F. Torradeflot, E. A. Valentijn, L. Valenziano, J. Valiviita, T. Vassallo, G. Verdoes Kleijn, A. Veropalumbo, Y. Wang, J. Weller, A. Zacchei, G. Zamorani, E. Zucca, E. Bozzo, C. Burigana, M. Calabrese, D. Di Ferdinando, J. A. Escartin Vigo, G. Fabbian, M. Maturi, N. Mauri, A. Pezzotta, M. Pöntinen, C. Porciani, V. Scottez, M. Tenti, M. Viel, M. Wiesmann, Y. Akrami, V. Allevato, S. Anselmi, F. Atrio-Barandela, A. Balaguera-Antolinez, A. Blanchard, L. Blot, H. Böhringer, S. Borgani, M. L. Brown, S. Bruton, R. Cabanac, A. Calabro, B. Camacho Quevedo, A. Cappi, F. Caro, C. S. Carvalho, T. Castro, F. Cogato, S. Contarini, A. R. Cooray, S. Davini, G. Desprez, A. Díaz-Sánchez, S. Di Domizio, A. G. Ferrari, I. Ferrero, A. Finoguenov, F. Fornari, L. Gabarra, K. Ganga, J. García-Bellido, T. Gasparetto, V. Gautard, E. Gaztanaga, F. Giacomini, F. Gianotti, G. Gozaliasl, A. Gregorio, M. Guidi, C. M. Gutierrez, A. Hall, H. Hildebrandt, J. Hjorth, A. Jimenez Muñoz, J. J. E. Kajava, Y. Kang, V. Kansal, D. Karagiannis, C. C. Kirkpatrick, S. Kruk, F. Lacasa, M. Lattanzi, S. Lee, J. Le Graet, L. Legrand, M. Lembo, T. I. Liaudat, S. J. Liu, A. Loureiro, J. Macias-Perez, M. Magliocchetti, F. Mannucci, R. Maoli, J. Martín-Fleitas, L. Maurin, R. B. Metcalf, M. Migliaccio, M. Miluzio, P. Monaco, A. Montoro, G. Morgante, S. Nadathur, K. Naidoo, P. Natoli, Nicholas A. Walton, L. Pagano, K. Paterson, L. Patrizii, A. Pisani, V. Popa, D. Potter, P. Reimberg, I. Risso, P. -F. Rocci, M. Sahlén, E. Sarpa, A. Schneider, M. Schultheis, D. Sciotti, M. Sereno, L. C. Smith, K. Tanidis, C. Tao, G. Testera, R. Teyssier, S. Tosi, A. Troja, M. Tucci, C. Valieri, D. Vergani, G. Verza, P. Vielzeuf</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Pre-launch analyses confirm the Euclid mission&#39;s substantial potential to tightly constrain dark energy and modified gravity parameters using complementary probes like weak lensing and galaxy clustering, incorporating necessary nonlinear and relativistic corrections. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The Euclid mission has been designed to provide, as one of its main deliverables, information on the nature of the gravitational interaction, which determines the expansion of the Universe and the formation of structures. Thus, Euclid has the potential to test deviations from general relativity that will allow us to shed light on long-lasting problems in the standard cosmological model, $Λ$CDM. Euclid will mainly do this by using two complementary probes: weak gravitational lensing and galaxy clustering. In this paper we review pre-launch Euclid analyses for dark energy and modified gravity. These include forecast constraints with future Euclid data on cosmological parameters for different cosmological models, such as a time-varying dark energy component, phenomenological modifications of the perturbation sector and specific modified gravity models, with further extensions that include neutrino physics and the coupling to the electromagnetic sector through the fine-structure constant. We review the study of the impact of nonlinear clustering methods on beyond-$Λ$CDM constraints with Euclid. This is of fundamental importance to efficiently predict the large-scale clustering of matter and dark matter halos, given that we will have access to a wealth of information on scales beyond the linear regime. We inspect the extension of theoretical predictions for observable quantities in alternative cosmologies to $Λ$CDM at fully nonlinear scales by means of $N$-body simulations. We discuss the impact of relativistic corrections in extended cosmological models. Overall, this review highlights the significant potential of the Euclid mission to tightly constrain parameters of dark energy and modified gravity models, or perhaps to detect possible signatures of a $Λ$CDM failure.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.09748" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.09748" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.09748" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 14.5</span>
                        <span class="badge bg-info text-dark">Author Score: 0.98</span>
                        <span class="badge bg-primary">Semantic Score: 0.96</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling / Cluster 2</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">2. Euclid Quick Data Release (Q1): Euclid spectroscopy of QSOs. 1. Identification and redshift determination of 3500 bright QSOs
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">Euclid Collaboration, Y. Fu, R. Bouwens, K. I. Caputi, D. Vergani, M. Scialpi, B. Margalef-Bentabol, L. Wang, M. Bolzonella, M. Banerji, et al.</span>
                                <span class="author-full" style="display: none;">Euclid Collaboration, Y. Fu, R. Bouwens, K. I. Caputi, D. Vergani, M. Scialpi, B. Margalef-Bentabol, L. Wang, M. Bolzonella, M. Banerji, E. Bañados, A. Feltre, Y. Toba, J. Calhau, F. Tarsitano, P. A. C. Cunha, A. Humphrey, G. Vietri, F. Mannucci, S. Bisogni, F. Ricci, H. Landt, L. Spinoglio, T. Matamoro Zatarain, D. Stern, M. J. Page, D. M. Alexander, G. Zamorani, W. Roster, M. Salvato, Y. Copin, J. G. Sorce, D. Scott, Y. -H. Zhang, E. Lusso, J. Wolf, D. Yang, H. J. A. Rottgering, B. Laloux, M. Siudek, S. Belladitta, Q. Liu, V. Allevato, S. Andreon, N. Auricchio, C. Baccigalupi, M. Baldi, A. Balestra, S. Bardelli, P. Battaglia, A. Biviano, E. Branchini, M. Brescia, J. Brinchmann, S. Camera, G. Cañas-Herrera, V. Capobianco, C. Carbone, J. Carretero, S. Casas, M. Castellano, G. Castignani, S. Cavuoti, K. C. Chambers, A. Cimatti, C. Colodro-Conde, G. Congedo, C. J. Conselice, L. Conversi, A. Costille, F. Courbin, H. M. Courtois, M. Cropper, A. Da Silva, H. Degaudenzi, G. De Lucia, C. Dolding, H. Dole, F. Dubath, C. A. J. Duncan, X. Dupac, S. Dusini, S. Escoffier, M. Fabricius, M. Farina, R. Farinelli, S. Ferriol, F. Finelli, P. Fosalba, N. Fourmanoit, M. Frailis, E. Franceschi, P. Franzetti, M. Fumana, S. Galeotta, K. George, W. Gillard, B. Gillis, C. Giocoli, J. Gracia-Carpio, A. Grazian, F. Grupp, L. Guzzo, S. V. H. Haugan, H. Hoekstra, W. Holmes, I. M. Hook, F. Hormuth, A. Hornstrup, K. Jahnke, M. Jhabvala, B. Joachimi, E. Keihänen, S. Kermiche, A. Kiessling, B. Kubik, M. Kümmel, M. Kunz, H. Kurki-Suonio, R. Laureijs, A. M. C. Le Brun, S. Ligori, P. B. Lilje, V. Lindholm, I. Lloro, G. Mainetti, D. Maino, E. Maiorano, O. Mansutti, S. Marcin, O. Marggraf, K. Markovic, M. Martinelli, N. Martinet, F. Marulli, R. J. Massey, E. Medinaceli, S. Mei, M. Melchior, Y. Mellier, M. Meneghetti, E. Merlin, G. Meylan, A. Mora, M. Moresco, L. Moscardini, R. Nakajima, C. Neissner, R. C. Nichol, S. -M. Niemi, C. Padilla, S. Paltani, F. Pasian, K. Pedersen, W. J. Percival, V. Pettorino, S. Pires, G. Polenta, M. Poncet, L. A. Popa, L. Pozzetti, F. Raison, R. Rebolo, A. Renzi, J. Rhodes, G. Riccio, E. Romelli, M. Roncarelli, E. Rossetti, R. Saglia, Z. Sakr, D. Sapone, B. Sartoris, M. Schirmer, P. Schneider, T. Schrabback, M. Scodeggio, A. Secroun, E. Sefusatti, G. Seidel, S. Serrano, P. Simon, C. Sirignano, G. Sirri, L. Stanco, J. -L. Starck, J. Steinwagner, C. Surace, P. Tallada-Crespí, D. Tavagnacco, A. N. Taylor, H. I. Teplitz, I. Tereno, N. Tessore, S. Toft, R. Toledo-Moreo, F. Torradeflot, I. Tutusaus, L. Valenziano, J. Valiviita, T. Vassallo, A. Veropalumbo, D. Vibert, Y. Wang, J. Weller, A. Zacchei, E. Zucca, M. Ballardini, E. Bozzo, C. Burigana, R. Cabanac, M. Calabrese, A. Cappi, D. Di Ferdinando, J. A. Escartin Vigo, L. Gabarra, W. G. Hartley, M. Huertas-Company, J. Martín-Fleitas, S. Matthew, N. Mauri, R. B. Metcalf, A. A. Nucita, A. Pezzotta, M. Pöntinen, C. Porciani, I. Risso, V. Scottez, M. Sereno, M. Tenti, M. Viel, M. Wiesmann, Y. Akrami, S. Alvi, I. T. Andika, S. Anselmi, M. Archidiacono, F. Atrio-Barandela, E. Aubourg, D. Bertacca, M. Bethermin, L. Bisigello, A. Blanchard, L. Blot, M. Bonici, S. Borgani, M. L. Brown, S. Bruton, A. Calabro, B. Camacho Quevedo, F. Caro, C. S. Carvalho, T. Castro, F. Cogato, S. Conseil, A. R. Cooray, O. Cucciati, G. Daste, F. De Paolis, G. Desprez, A. Díaz-Sánchez, J. J. Diaz, S. Di Domizio, J. M. Diego, P. Dimauro, P. -A. Duc, M. Y. Elkhashab, A. Enia, Y. Fang, A. G. Ferrari, A. Finoguenov, F. Fontanot, A. Franco, K. Ganga, J. García-Bellido, T. Gasparetto, V. Gautard, E. Gaztanaga, F. Giacomini, F. Gianotti, G. Gozaliasl, M. Gray, M. Guidi, C. M. Gutierrez, A. Hall, C. Hernández-Monteagudo, H. Hildebrandt, J. Hjorth, J. J. E. Kajava, Y. Kang, V. Kansal, D. Karagiannis, K. Kiiveri, J. Kim, C. C. Kirkpatrick, S. Kruk, V. Le Brun, J. Le Graet, L. Legrand, M. Lembo, F. Lepori, G. Leroy, G. F. Lesci, J. Lesgourgues, T. I. Liaudat, A. Loureiro, J. Macias-Perez, M. Magliocchetti, C. Mancini, R. Maoli, C. J. A. P. Martins, L. Maurin, M. Miluzio, P. Monaco, C. Moretti, G. Morgante, S. Nadathur, K. Naidoo, P. Natoli, A. Navarro-Alsina, S. Nesseris, D. Paoletti, F. Passalacqua, K. Paterson, L. Patrizii, A. Pisani, D. Potter, S. Quai, M. Radovich, P. -F. Rocci, G. Rodighiero, S. Sacquegna, M. Sahlén, D. B. Sanders, E. Sarpa, C. Scarlata, A. Schneider, D. Sciotti, E. Sellentin, F. Shankar, L. C. Smith, E. Soubrie, K. Tanidis, C. Tao, G. Testera, R. Teyssier, S. Tosi, A. Troja, M. Tucci, C. Valieri, A. Venhola, G. Verza, P. Vielzeuf, A. Viitanen, N. A. Walton, J. R. Weaver</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A large, homogeneous sample of approximately 3500 bright quasars was identified using Euclid NISP slitless spectroscopy, enabling the creation of the first Euclid composite NIR spectrum and revealing a shift toward nuclear dominance in morphology at intermediate redshifts. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The slitless spectroscopy mode of the NISP onboard Euclid has enabled efficient spectroscopy of objects within a large FoV. We present a large and homogeneous sample of bright quasars identified from the Euclid Quick Data Release (Q1) by combining high-purity candidate selections from Gaia and WISE with the NISP spectra. Through visual inspection of the Euclid spectra of these quasar candidates, we identify approximately 3500 quasars with reliable redshifts at $0&lt;z\lesssim 4.8$. We generate the first Euclid composite spectrum of quasars covering rest-frame NUV to NIR wavelengths without telluric lines, which will be pivotal to NIR quasar spectral analysis. We obtain an empirical spectroscopic depth of $J_{\rm E}\lesssim 21.5$ and $H_{\rm E}\lesssim 21.3$ at the sensitivity of the Wide Field Survey, beyond which the number of securely identified quasars declines sharply. We analyse VIS morphologies using Sersic and CAS metrics, and a deep-learning PSF fraction to track nuclear dominance. At low redshift ($z&lt;0.5$), obvious host structures are common and a single Sersic model fits about half of the sources; at intermediate redshift ($0.5&lt;z&lt;2$), the nuclear component dominates, with 90% of the Sersic fits saturating at the upper index limit. In this intermediate redshift regime, $f_{\rm PSF}$ is available, and we use it as a more reliable compactness measure than the single-Sersic and CAS parameters to quantify nuclear versus host emission. We also explore the novel Euclid NIR colour space and discuss the role of these quasars in refining AGN selection techniques for future Euclid data releases. Our results highlight the potential of Euclid spectroscopy to advance quasar surveys and enable the construction of more complete AGN catalogues. The spectroscopic bright quasar catalogue of this work, and the composite quasar spectrum, will be available at https://cdsarc.cds.unistra.fr/. (abridged)</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.08803" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.08803" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.08803" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 14.0</span>
                        <span class="badge bg-info text-dark">Author Score: 0.99</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">3. Neutrino mass constraints in the context of 4-parameter dark energy equation of state and DESI DR2 observations
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Gowri S Nair, Amlan Chakraborty, Luca Amendola, Subinoy Das</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Employing a flexible four-parameter dark energy equation of state (4pDE) with Planck, DESI DR2 BAO, and Pantheon+ data yields a stringent upper bound on the total neutrino mass ($\sum m_\nu &lt; 0.101$ eV) that is tighter than standard $w_0w_a$CDM constraints. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Cosmological constraints on the total neutrino mass, $\sum m_ν$, are strongly shaped by assumptions about the dark-energy equation of state due to the well-known degeneracy between massive neutrinos and late-time cosmic acceleration. In this work, we move beyond the two-parameter Chevallier-Polarski-Linder (CPL) form adopted in recent DESI analyses and re-examine neutrino mass constraints using a flexible four-parameter dark energy equation of state (4pDE). We implement the 4pDE model in a modified version of CLASS and perform a full MCMC analysis using Planck, DESI DR2 BAO, and Pantheon+ data. Relative to our previous 4pDE study based on pre-DESI BAO datasets, the inclusion of DESI DR2 substantially tightens the constraints on the transition parameters while still yielding a relaxed neutrino-mass bound compared to $Λ$CDM, $\sum m_ν&lt; 0.101$ eV ($95\%$ C.L.). This upper limit is more stringent than the DESI DR2 constraint obtained within the $w_0w_a$CDM framework. From the best-fit parameters, we reconstruct the evolution of the 4pDE equation of state along with both $68\%$ and $95\%$C.L. We do not find a statistically significant phantom-crossing at $z \sim 0.5$, consistent with the conclusion from the DESI collaboration; at higher redshifts, the reconstructed $w(z)$ follows the CPL evolution and deviates only at low redshift. Additionally we also find reduction in $Δχ^2_{\rm min}=-7.3$ compared to $Λ$CDM model.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.08752" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.08752" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.08752" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 10.8</span>
                        <span class="badge bg-info text-dark">Author Score: 0.34</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">4. Probing the environment around GW170817 with DESI: insights on galaxy group peculiar velocities for standard siren measurements
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">A. J. Amsellem, A. Palmese, K. Douglass, C. Howlett, Juliana S. M. Karp, I. Magaña Hernandez, J. Moustakas, R. H. Wechsler, J. Aguilar, S. Ahlen, et al.</span>
                                <span class="author-full" style="display: none;">A. J. Amsellem, A. Palmese, K. Douglass, C. Howlett, Juliana S. M. Karp, I. Magaña Hernandez, J. Moustakas, R. H. Wechsler, J. Aguilar, S. Ahlen, S. Benzvi, D. Bianchi, D. Brooks, A. Carr, T. Claybaugh, A. Cuceu, Tamara M. Davis, A. de la Macorra, Arjun Dey, Biprateep Dey, P. Doel, A. Font-Ribera, J. E. Forero-Romero, E. Gaztañaga, S. Gontcho A Gontcho, G. Gutierrez, K. Honscheid, M. Ishak, R. Joyce, R. Kehoe, T. Kisner, A. Kremin, O. Lahav, A. Lambert, M. Landriau, L. Le Guillou, M. Manera, V. Manwadkar, A. Meisner, R. Miquel, A. D. Myers, S. Nadathur, G. Niz, N. Palanque-Delabrouille, W. J. Percival, C. Poppett, F. Prada, I. Pérez-Ràfols, A. Raichoor, G. Rossi, E. Sanchez, D. Schlegel, M. Schubnell, H. Seo, J. Silber, D. Sprayberry, G. Tarlé, R. Zhou, the DESI Collaboration</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Utilizing extensive DESI spectroscopic observations to accurately model the local dynamics and peculiar velocity of the GW170817 host galaxy group, new standard siren measurements yield Hubble constant values ranging from $70.9$ to $73.4$ km s$^{-1}$ Mpc$^{-1}$. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We present a new measurement of the Hubble constant, $H_0$, following the gravitational wave event GW170817 and Dark Energy Spectroscopic Instrument (DESI) observations. A standard siren measurement with a nearby (luminosity distance $\sim 40 $ Mpc) event such as GW170817 is typically sensitive to the peculiar motion of the host galaxy due to local dynamics. Previous measurements from this event have taken advantage of peculiar velocity measurements of nearby galaxies, including a handful of objects in the galaxy group that the host of the event, NGC 4993, has been associated with. Still, the group&#39;s properties and NGC 4993&#39;s membership were debated. We present DESI observations of thousands of galaxies in the vicinity of NGC 4993, resulting in 39 group galaxies and a five-fold increase in galaxies compared to previous observations with many of these galaxies contributing to a peculiar velocity measurement. Examining the local dynamics, our observations support the presence of a galaxy group of which NGC 4993 is part with a halo mass of order $\sim$$10^{13}~M_\odot$. Using peculiar velocity measurements from our Fundamental Plane galaxies observations, we find $H_0 =70.9^{+6.4}_{-8.5}$ km s$^{-1}$ Mpc$^{-1}$. In addition, using a peculiar velocity measurement for NGC 4993 from Surface Brightness Fluctuations in Cosmicflows-4 we find $H_0 =73.4^{+3.3}_{-3.9}$ km s$^{-1}$ Mpc$^{-1}$. We study the impact of different galaxy selection criteria on the determination of the peculiar velocity and, in turn, on the $H_0$ measurement. Our results highlight the importance of multiplexed spectroscopic observations of the environments of gravitational wave events to probe local dynamics, which can ultimately affect standard siren measurements.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.08818" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.08818" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.08818" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 10.6</span>
                        <span class="badge bg-info text-dark">Author Score: 0.23</span>
                        <span class="badge bg-primary">Semantic Score: 0.95</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Weak Lensing, Cosmic Shear, Galaxy Surveys</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">5. Vision Transformers for Cosmological Fields: Application to Weak Lensing Mass Maps
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Jash Kakadia, Shubh Agrawal, Kunhao Zhong, Bhuvnesh Jain</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Attention-based architectures, particularly the Swin transformer, effectively extract non-Gaussian information from weak lensing mass maps for cosmological parameter inference, achieving performance comparable to convolutional neural networks under realistic noise constraints. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Weak gravitational lensing is a powerful probe of the universe&#39;s growth history. While traditional two-point statistics capture only the Gaussian features of the convergence field, deep learning methods such as convolutional neural networks (CNNs) have shown promise in extracting non-Gaussian information from small-scale, nonlinear structures. In this work, we evaluate the effectiveness of attention-based architectures, including variants of vision transformers (ViTs) and shifted window (Swin) transformers, in constraining the cosmological parameters $Ω_m$ and $S_8$ from weak lensing mass maps. Using a simulation-based inference (SBI) framework, we compare transformer-based methods to CNNs. We also examine performance scaling with the number of available $N$-body simulations, highlighting the importance of pre-training for transformer architectures. We find that the Swin transformer performs significantly better than vanilla ViTs, especially with limited training data. Despite their higher representational capacity, the Figure of Merit for cosmology achieved by transformers is comparable to that of CNNs under realistic noise conditions.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.07125" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.07125" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.07125" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 10.0</span>
                        <span class="badge bg-info text-dark">Author Score: 0.11</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">6. Revisiting the X-ray-to-UV relation of Quasars in the era of all-sky surveys
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">Maria Chira, Antonis Georgakakis, Angel Ruiz, Shi-Jiang Chen, Johannes Buchner, Amy L. Rankine, Elias Kammoun, Catarina Aydar, Mara Salvato, Andrea Merloni, et al.</span>
                                <span class="author-full" style="display: none;">Maria Chira, Antonis Georgakakis, Angel Ruiz, Shi-Jiang Chen, Johannes Buchner, Amy L. Rankine, Elias Kammoun, Catarina Aydar, Mara Salvato, Andrea Merloni, Mirko Krumpe</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A hierarchical Bayesian analysis of 136,745 QSOs confirms a tight, sublinear X-ray-to-UV correlation that exhibits a mild systematic redshift evolution, characterized by flattening and reduced scatter at higher redshifts, contrary to predictions regarding Eddington ratio dependence. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The X-ray--to--UV relation of active galactic nuclei (AGNs), commonly parametrized via the monochromatic luminosities at $2500\,\mathring{A}$ and $2\,keV$, reflects the energetic interplay between the accretion disc and the X-ray-emitting corona, and is key for understanding accretion physics. Previous studies suggest that disc-dominated emission becomes more prominent with increasing optical luminosity. However, the redshift evolution of this relation remains debated, and a dependence on Eddington ratio, predicted by accretion flow models, is still observationally unconstrained. We revisit this relation using a large, nearly all-sky sample by combining the SDSS DR16Q QSO catalogue with X-ray data from XMM-Newton and the SRG/eROSITA All-Sky Survey DR1, yielding 136,745 QSOs at redshifts $0.5 \leq z &lt; 3.0$. We introduce a hierarchical Bayesian framework that treats X-ray detections and upper limits uniformly, enabling robust inference from both parametric and non-parametric models. We confirm a tight, sublinear $\log L_X({\rm 2\,keV})$-$\log L_ν({\rm 2500\,\mathring{A}})$ correlation, but with a normalization at the lower end of previous estimates. Contrary to most literature results, we detect a mild but systematic redshift evolution: the relation flattens and its intrinsic scatter decreases at higher redshift. This trend is consistent with disc emission increasingly dominated by scattering and enhanced energy transfer to the X-ray corona, potentially indicating redshift evolution in the X-ray bolometric correction. We find no significant dependence on Eddington ratio, in tension with recent accretion flow models.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.09767" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.09767" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.09767" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.9</span>
                        <span class="badge bg-info text-dark">Author Score: 0.19</span>
                        <span class="badge bg-primary">Semantic Score: 0.90</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">7. Galaxy Phase-Space and Field-Level Cosmology: The Strength of Semi-Analytic Models
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">Natalí S. M. de Santi, Francisco Villaescusa-Navarro, Pablo Araya-Araya, Gabriella De Lucia, Fabio Fontanot, Lucia A. Perez, Manuel Arnés-Curto, Violeta Gonzalez-Perez, Ángel Chandro-Gómez, Rachel S. Somerville, et al.</span>
                                <span class="author-full" style="display: none;">Natalí S. M. de Santi, Francisco Villaescusa-Navarro, Pablo Araya-Araya, Gabriella De Lucia, Fabio Fontanot, Lucia A. Perez, Manuel Arnés-Curto, Violeta Gonzalez-Perez, Ángel Chandro-Gómez, Rachel S. Somerville, Tiago Castro</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A graph neural network trained solely on galaxy phase-space data from semi-analytic models can robustly estimate the matter density parameter ($\Omega_{\rm m}$) with 10% precision, successfully extrapolating its predictions to diverse hydrodynamical simulations. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Semi-analytic models are a widely used approach to simulate galaxy properties within a cosmological framework, relying on simplified yet physically motivated prescriptions. They have also proven to be an efficient alternative for generating accurate galaxy catalogs, offering a faster and less computationally expensive option compared to full hydrodynamical simulations. In this paper, we demonstrate that using only galaxy $3$D positions and radial velocities, we can train a graph neural network coupled to a moment neural network to obtain a robust machine learning based model capable of estimating the matter density parameters, $Ω_{\rm m}$, with a precision of approximately 10%. The network is trained on ($25 h^{-1}$Mpc)$^3$ volumes of galaxy catalogs from L-Galaxies and can successfully extrapolate its predictions to other semi-analytic models (GAEA, SC-SAM, and Shark) and, more remarkably, to hydrodynamical simulations (Astrid, SIMBA, IllustrisTNG, and SWIFT-EAGLE). Our results show that the network is robust to variations in astrophysical and subgrid physics, cosmological and astrophysical parameters, and the different halo-profile treatments used across simulations. This suggests that the physical relationships encoded in the phase-space of semi-analytic models are largely independent of their specific physical prescriptions, reinforcing their potential as tools for the generation of realistic mock catalogs for cosmological parameter inference.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.10222" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.10222" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.10222" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.8</span>
                        <span class="badge bg-info text-dark">Author Score: 0.06</span>
                        <span class="badge bg-primary">Semantic Score: 0.95</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">8. Probing the Warm Dark Matter mass with [C II] intensity mapping
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Elena Marcuzzo, Cristiano Porciani, Emilio Romano-Díaz, Azadeh Moradinezhad Dizgah, Prachi Khatri, Matteo Viel</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Forecasts utilizing the [C II] power spectrum from line-intensity mapping surveys demonstrate that ambitious future setups, particularly those with increased spectral resolution, can set competitive lower limits on the warm dark matter particle mass ($m_\mathrm{WDM}$), potentially exceeding 5 keV. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The nature of dark matter (DM) is still debated. While cold DM (CDM) is the standard paradigm, warm DM (WDM) may ease some small-scale tensions in the $Λ$CDM framework. Line-intensity mapping (LIM) offers a novel probe of DM properties. To explore the potential of LIM surveys in constraining the WDM particle mass ($m_\mathrm{WDM}$) by means of the [C II] power spectrum (PS), we provide forecasts for the Deep Spectroscopic Survey (DSS) at $z\simeq3.6$ and extend the analysis to larger sky coverage, higher sensitivity, and/or increased spectral resolution. We develop a formulation for the [C II] PS based on the halo-model approach, incorporating the uncertainty in the luminosity function (LF) through two alternative parameterisations. We perform a Bayesian analysis on mock data to derive constraints on $m_\mathrm{WDM}$. In a CDM universe, the DSS yields lower limits on $m_\mathrm{WDM}$ at $95\%$ credibility level (CL) of $1.10$ keV and $0.58$ keV when considering the optimistic and pessimistic LF ($α= -1.1$), respectively. Ambitious surveys can improve these figures to $5.82$ keV and $1.90$ keV, and assuming a steeper faint-end slope ($α= -1.9$) further boosts these limits. A fivefold increase in spectral resolution enhances sensitivity to the damping scale associated to redshift-space distortions, tightening the constraints on $m_\mathrm{WDM}$ by a factor of up to $\sim1.8$. Finally, Bayesian inference on mock data with $m_\mathrm{WDM}=3$ keV results in a well-constrained and unbiased posterior only in futuristic survey setups. Upcoming LIM surveys can provide meaningful limits on $m_\mathrm{WDM}$, although the negligible contribution from small haloes reduces the constraining power of the [C II] PS. Future progress will benefit from combining multiple redshifts and emission lines, opening the way to competitive constraints on the nature of DM.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.07933" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.07933" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.07933" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.7</span>
                        <span class="badge bg-info text-dark">Author Score: 0.04</span>
                        <span class="badge bg-primary">Semantic Score: 0.95</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Weak Lensing, Cosmic Shear, Galaxy Surveys</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">9. FEASTS Compared with Simulations: Abnormally Irregular and Extended HI Morphologies at a Column Density of $10^{18}\,\text{cm}^{-2}$ in TNG50 and Auriga
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Xuchen Lin, Jing Wang, Guinevere Kauffmann, Volker Springel, Rüdiger Pakmor</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A statistical comparison of low-column density HI morphology reveals that over one-third of simulated IllustrisTNG50 galaxies exhibit abnormally irregular structures compared to FEASTS observations, indicating that stellar feedback is the primary driver of this discrepancy. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">With new atomic-hydrogen (HI) observations of FAST Extended Atlas of Selected Targets Survey (FEASTS), we present the first statistical comparison of HI morphology between observations and cosmological simulations, focusing on low-column density ($10^{18}\,\text{cm}^{-2}$) regions of Milky Way-like central galaxies. We select a 330-galaxy sample from IllustrisTNG50 (TNG50) matched to 33 FEASTS galaxies by stellar and HI masses, and mock observe them to the FAST resolution and depth at corresponding inclinations and distances for a fair comparison. In contrast to FEASTS, abnormally irregular and extended morphology is found in more than one-third of TNG50 galaxies, especially those massive and HI poor. Stellar feedback is the property that most significantly correlates with the HI morphological deviation from observations, although these deviations mostly occur at a high stellar or black-hole mass. These results indicate that in TNG50, stellar feedback significantly influences the HI morphology at $10^{18}\,\text{cm}^{-2}$, while active galactic nucleus (AGN) feedback has not so direct a role as expected. With an additional sample from Auriga, we find that the magnetic field may help HI to be more regular in its morphology, while improving the mass resolution does not alleviate the discrepancy from observation. This study reveals the potential of constraining future simulations of galaxies by observing low-column density HI.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.07223" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.07223" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.07223" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.7</span>
                        <span class="badge bg-info text-dark">Author Score: 0.11</span>
                        <span class="badge bg-primary">Semantic Score: 0.91</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">10. Self-calibration of weak lensing cosmic shear biases
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>G. Congedo, A. N. Taylor</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A novel methodology is introduced for robustly inferring multiplicative and additive shear biases in weak lensing measurements directly from parameterized ellipticity distributions, eliminating the need for external simulations and providing a cosmology-independent calibration tool. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">In order to reach the required performance of Stage-III and IV weak lensing surveys, cosmic shear measurements have to rely on external simulations to calibrate residual biases. Over the years, several techniques have been developed to mitigate the impact of residual biases prior to calibration, including the inference of shear responses on images to correct multiplicative biases, and the empirical correction of additive biases. We introduce a novel methodology that generalises upon the state-of-the-art approaches by inferring multiplicative and additive biases jointly from parameterised distributions of measured ellipticities, crucially without relying on external simulations and independently from cosmology. Shear biases are marginalised over the unknown hyper-parameters in the modelling, hence mitigating the impact of degeneracies. We apply the technique to a representative problem and show the performance of the estimation, even in the presence of noise. The method has a high potential for applicability to the calibration of weak lensing cosmic shear in current and future lensing surveys.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.09922" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.09922" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.09922" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.6</span>
                        <span class="badge bg-info text-dark">Author Score: 0.05</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">11. What matters for Representation Alignment: Global Information or Spatial Structure?
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Jaskirat Singh, Xingjian Leng, Zongze Wu, Liang Zheng, Richard Zhang, Eli Shechtman, Saining Xie</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Empirical analysis demonstrates that the spatial structure of pretrained vision encoder representations, rather than their global semantic performance, is the critical factor driving generative model quality, leading to the introduction of iREPA, a simple modification that accelerates convergence. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Representation alignment (REPA) guides generative training by distilling representations from a strong, pretrained vision encoder to intermediate diffusion features. We investigate a fundamental question: what aspect of the target representation matters for generation, its \textit{global} \revision{semantic} information (e.g., measured by ImageNet-1K accuracy) or its spatial structure (i.e. pairwise cosine similarity between patch tokens)? Prevalent wisdom holds that stronger global semantic performance leads to better generation as a target representation. To study this, we first perform a large-scale empirical analysis across 27 different vision encoders and different model scales. The results are surprising; spatial structure, rather than global performance, drives the generation performance of a target representation. To further study this, we introduce two straightforward modifications, which specifically accentuate the transfer of \emph{spatial} information. We replace the standard MLP projection layer in REPA with a simple convolution layer and introduce a spatial normalization layer for the external representation. Surprisingly, our simple method (implemented in $&lt;$4 lines of code), termed iREPA, consistently improves convergence speed of REPA, across a diverse set of vision encoders, model sizes, and training variants (such as REPA, REPA-E, Meanflow, JiT etc). %, etc. Our work motivates revisiting the fundamental working mechanism of representational alignment and how it can be leveraged for improved training of generative models. The code and project page are available at https://end2end-diffusion.github.io/irepa</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.10794" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.10794" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.10794" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.6</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.96</span>
                        
                            <span class="badge bg-secondary">cs.CV</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling / Neural Architectures, Representation Learning, Advanced Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">12. JEPA as a Neural Tokenizer: Learning Robust Speech Representations with Density Adaptive Attention
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Georgios Ioannides, Christos Constantinou, Aman Chadha, Aaron Elkins, Linsey Pang, Ravid Shwartz-Ziv, Yann LeCun</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A two-stage self-supervised framework combining JEPA with a Density Adaptive Attention Mechanism effectively learns robust semantic audio features, yielding highly compressed, reversible, and efficient speech tokens competitive with established neural audio codecs. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We introduce a two-stage self-supervised framework that combines the Joint-Embedding Predictive Architecture (JEPA) with a Density Adaptive Attention Mechanism (DAAM) for learning robust speech representations. Stage~1 uses JEPA with DAAM to learn semantic audio features via masked prediction in latent space, fully decoupled from waveform reconstruction. Stage~2 leverages these representations for efficient tokenization using Finite Scalar Quantization (FSQ) and a mixed-radix packing scheme, followed by high-fidelity waveform reconstruction with a HiFi-GAN decoder. By integrating Gaussian mixture-based density-adaptive gating into the JEPA encoder, the model performs adaptive temporal feature selection and discovers hierarchical speech structure at a low frame rate of 2.5~Hz. The resulting tokens (47.5 tokens/sec) provide a reversible, highly compressed, and language-model-friendly representation that is competitive with, and often more efficient than, existing neural audio codecs.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.07168" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.07168" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.07168" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.6</span>
                        <span class="badge bg-info text-dark">Author Score: 0.07</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.SD</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling / Neural Architectures, Representation Learning, Advanced Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">13. Self-consistent secondary cosmic microwave background anisotropies and extragalactic foregrounds in the FLAMINGO simulations
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Tianyi Yang, Ian G. McCarthy, Fiona McCarthy, Boris Bolliet, Jens Chluba, William Coulton, John C. Helly, Matthieu Schaller, Joop Schaye</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Self-consistent mock cosmic microwave background maps generated from the FLAMINGO hydrodynamical simulations, incorporating various secondary anisotropies, successfully match observational constraints and provide novel predictions for cross-correlations that depend on cosmology and feedback modeling. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Secondary anisotropies in the cosmic microwave background (CMB) contain information that can be used to test both cosmological models and models of galaxy formation. Starting from lightcone-based HEALPix maps and catalogues, we present a new set of mock CMB maps constructed in a self-consistent manner from the FLAMINGO suite of cosmological hydrodynamical simulations, including CMB lensing, thermal and kinetic Sunyaev-Zeldovich effects, cosmic infrared background, radio point source and anisotropic screening maps. We show that these simulations reproduce a wide range of observational constraints. We also compare our simulations with previous predictions based on dark matter-only simulations which generally model the secondary anisotropies independently from one another, concluding that our hydrodynamical simulation mocks perform at least as well as previous mocks in matching the observations whilst retaining self-consistency in the predictions of the different components. Using the model variations in FLAMINGO, we further explore how the signals depend on cosmology and feedback modelling, and we predict cross-correlations between some of the signals that differ significantly from those in previous mocks. The mock CMB maps should provide a valuable resource for exploring correlations between different secondary anisotropies and other large-scale structure tracers, and can be applied to forecasts for upcoming surveys.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.09891" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.09891" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.09891" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.5</span>
                        <span class="badge bg-info text-dark">Author Score: 0.01</span>
                        <span class="badge bg-primary">Semantic Score: 0.95</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling / Cluster 2</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">14. SLICE -- Combining Strong Lensing and X-ray in AC\,114. Insights into the Merger Scenario
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">Marceau Limousin, Benjamin Beauchesne, Keren Sharon, Johan Richard, Gourav Khullar, Mathilde Jauzac, Mike Gladders, Eric Jullo, Catherine Cerny, Stefano Ettori, et al.</span>
                                <span class="author-full" style="display: none;">Marceau Limousin, Benjamin Beauchesne, Keren Sharon, Johan Richard, Gourav Khullar, Mathilde Jauzac, Mike Gladders, Eric Jullo, Catherine Cerny, Stefano Ettori, Gavin Leroy, Nency Patel</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> New JWST imaging of the galaxy cluster AC114, combined with X-ray data, significantly increases the strong lensing constraints, revealing a major post-collisional merger scenario involving a dominant system with a large dark matter core and a newly identified companion, AC114b. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">AC114 is a historically significant galaxy cluster, being one of the first strong lensing clusters detected from the ground in the early 1990s, prior to the launch of the HST. Despite this early prominence, no detailed lensing analyses have been carried out for more than fifteen years. We here study this cluster using JWST imaging obtained as part of the SLICE program, complemented by archival HST and X-ray observations. JWST data reveal ten new multiply imaged systems and enable the identification of conjugate substructures in several of the sixteen systems, significantly increasing the number of strong lensing constraints. Using these data, we construct a parametric mass model with Lenstool and extend it by explicitly incorporating the Chandra data in a combined strong lensing+X-ray fit. Our best-fit model reproduces the multiple images with an RMS of 0.4&#34; while simultaneously matching the X-ray data. The dark matter distribution is unimodal and centered on the brightest cluster galaxy, with a large core radius of 83+-5kpc, consistent with values reported in other strong lensing clusters. The strong lensing constraints require the inclusion of an external shear component which position angle points unambiguously towards a nearby (~1Mpc), well defined mass concentration at the same redshift in the North-West, for which we propose the naming AC114b. The spatial coverage of the XMM-Newton data encompasses the whole structure, allowing us to probe the X-ray properties of the companion cluster and the thermodynamics of AC114, providing evidence for a major merger, in line with previous signatures seen in Chandra, radio and optical spectroscopic data. Our results shed new light on the merging scenario, revealing a major merger caught in a late post-collisional phase, where AC114 is the dominant system and Ac114b has likely been stripped of its hot gas.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.09512" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.09512" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.09512" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.5</span>
                        <span class="badge bg-info text-dark">Author Score: 0.04</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Weak Lensing, Cosmic Shear, Galaxy Surveys / Galaxy-Halo Connection, Lensing, Clustering</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">15. One Layer Is Enough: Adapting Pretrained Visual Encoders for Image Generation
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Yuan Gao, Chen Chen, Tianrong Chen, Jiatao Gu</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The Feature Auto-Encoder (FAE) framework successfully bridges the gap between high-dimensional understanding-oriented features and low-dimensional generation-friendly latents using a simple attention mechanism and dual decoders, achieving strong, fast-learning performance in both diffusion and normalizing flow generative models. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Visual generative models (e.g., diffusion models) typically operate in compressed latent spaces to balance training efficiency and sample quality. In parallel, there has been growing interest in leveraging high-quality pre-trained visual representations, either by aligning them inside VAEs or directly within the generative model. However, adapting such representations remains challenging due to fundamental mismatches between understanding-oriented features and generation-friendly latent spaces. Representation encoders benefit from high-dimensional latents that capture diverse hypotheses for masked regions, whereas generative models favor low-dimensional latents that must faithfully preserve injected noise. This discrepancy has led prior work to rely on complex objectives and architectures. In this work, we propose FAE (Feature Auto-Encoder), a simple yet effective framework that adapts pre-trained visual representations into low-dimensional latents suitable for generation using as little as a single attention layer, while retaining sufficient information for both reconstruction and understanding. The key is to couple two separate deep decoders: one trained to reconstruct the original feature space, and a second that takes the reconstructed features as input for image generation. FAE is generic; it can be instantiated with a variety of self-supervised encoders (e.g., DINO, SigLIP) and plugged into two distinct generative families: diffusion models and normalizing flows. Across class-conditional and text-to-image benchmarks, FAE achieves strong performance. For example, on ImageNet 256x256, our diffusion model with CFG attains a near state-of-the-art FID of 1.29 (800 epochs) and 1.70 (80 epochs). Without CFG, FAE reaches the state-of-the-art FID of 1.48 (800 epochs) and 2.08 (80 epochs), demonstrating both high quality and fast learning.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.07829" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.07829" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.07829" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.5</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.95</span>
                        
                            <span class="badge bg-secondary">cs.CV</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling / Neural Architectures, Representation Learning, Advanced Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">16. Squeezed Limit non-Gaussianity Estimation with Cosmic Shear
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Shi-Hui Zang, Moritz Münchmeyer</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A computationally efficient extension of the $\pi$-field method to spherical coordinates successfully constrains local primordial non-Gaussianity using the large-scale modulation of the galaxy lensing power spectrum, achieving a forecasted constraint of $\sigma_{f_{\mathrm{NL}}} \simeq 12$ for future weak lensing surveys. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We present a new method to constrain local primordial non-Gaussianity using the large-scale modulation of the local lensing power spectrum. Our work extends our recently proposed $π$-field method for primordial non-Gaussianity estimation to spherical coordinates and applies it to galaxy lensing. Our approach is computationally efficient and only requires binned multipole power spectra $C_\ell(z_1,z_2)$ on large scales, as well as their covariance. Our method is simpler to implement than a full bispectrum estimator, but still contains the full squeezed-limit information. We validate our model using a suite of N-body simulations and demonstrate its accuracy in recovering the $f_{\mathrm{NL}}$ values. We then perform a Fisher forecast for an LSST-like weak lensing survey, finding $σ_{f_{\mathrm{NL}}} \simeq 12$. Our approach readily combines with other $f_{\mathrm{NL}}$-sensitive fields such as kSZ velocity reconstruction and clustering-based $π$-fields, for a future combined $f_{\mathrm{NL}}$ estimator using various large-scale galaxy and CMB observables.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.07295" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.07295" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.07295" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.5</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.95</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">17. GFH-v2 Pipeline for Searches of Long-Transient Gravitational Waves from Newborn Magnetars
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">Sandhya Sajith Menon, Lorenzo Pierini, Pia Astone, Cristiano Palomba, Lorenzo Silvestri, Sabrina D&#39;Antonio, Simone Dall&#39;Osso, Francesco Safai Tehrani, Stefano Dal Pra, Gaetano Dinatale, et al.</span>
                                <span class="author-full" style="display: none;">Sandhya Sajith Menon, Lorenzo Pierini, Pia Astone, Cristiano Palomba, Lorenzo Silvestri, Sabrina D&#39;Antonio, Simone Dall&#39;Osso, Francesco Safai Tehrani, Stefano Dal Pra, Gaetano Dinatale, Sergio Frasca, Dafne Guetta, Paola Leaci, Alessio Orlandi</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> An enhanced version of the generalized Frequency Hough Transform algorithm (GFH-v2) significantly improves the sensitivity and computational performance for directed searches of long transient gravitational waves associated with newborn magnetars in LVK data. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">This paper presents an enhanced methodology for searching long transient gravitational waves associated with a newborn magnetar using a strongly improved version of the generalized Frequency Hough Transform algorithm, called GFH-v2. We describe the main developments introduced relative to the original implementation and outline the optimized parameter-space selection used in the search. We then compute the theoretical sensitivity of the method and compare it with an empirical sensitivity estimate obtained by injecting simulated signals into LIGO-Virgo-KAGRA O4a data. The updated framework achieves improved sensitivity and computational performance. These results provide a robust basis for future directed searches for long-transient gravitational-wave signals from core-collapse supernovae and other transient events in current and upcoming observing runs.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.09878" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.09878" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.09878" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.IM</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">18. LUNA: Linear Universal Neural Attention with Generalization Guarantees
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Ashkan Shahbazi, Ping He, Ali Abbasi, Yikun Bai, Xinran Liu, Elaheh Akbari, Darian Salehi, Navid NaderiAlizadeh, Soheil Kolouri</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> LUNA, a novel kernelized linear attention mechanism that learns its feature map, overcomes the accuracy limitations of fixed-kernel linear methods, achieving linear computational scaling while matching or exceeding the performance of quadratic softmax attention on long-sequence tasks. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Scaling attention faces a critical bottleneck: the $\mathcal{O}(n^2)$ quadratic computational cost of softmax attention, which limits its application in long-sequence domains. While linear attention mechanisms reduce this cost to $\mathcal{O}(n)$, they typically rely on fixed random feature maps, such as random Fourier features or hand-crafted functions. This reliance on static, data-agnostic kernels creates a fundamental trade-off, forcing practitioners to sacrifice significant model accuracy for computational efficiency. We introduce \textsc{LUNA}, a kernelized linear attention mechanism that eliminates this trade-off, retaining linear cost while matching and surpassing the accuracy of quadratic attention. \textsc{LUNA} is built on the key insight that the kernel feature map itself should be learned rather than fixed a priori. By parameterizing the kernel, \textsc{LUNA} learns a feature basis tailored to the specific data and task, overcoming the expressive limitations of fixed-feature methods. \textsc{Luna} implements this with a learnable feature map that induces a positive-definite kernel and admits a streaming form, yielding linear time and memory scaling in the sequence length. Empirical evaluations validate our approach across diverse settings. On the Long Range Arena (LRA), \textsc{Luna} achieves state-of-the-art average accuracy among efficient Transformers under compute parity, using the same parameter count, training steps, and approximate FLOPs. \textsc{Luna} also excels at post-hoc conversion: replacing softmax in fine-tuned BERT and ViT-B/16 checkpoints and briefly fine-tuning recovers most of the original performance, substantially outperforming fixed linearizations.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.08061" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.08061" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.08061" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.LG</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling / Neural Architectures, Representation Learning, Advanced Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">19. KAN-Dreamer: Benchmarking Kolmogorov-Arnold Networks as Function Approximators in World Models
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Chenwei Shi, Xueyu Luan</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Integrating FastKAN layers as drop-in replacements for the Reward and Continue predictors within the DreamerV3 model-based reinforcement learning framework maintains equivalent sample efficiency and training speed compared to the original MLP architecture. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">DreamerV3 is a state-of-the-art online model-based reinforcement learning (MBRL) algorithm known for remarkable sample efficiency. Concurrently, Kolmogorov-Arnold Networks (KANs) have emerged as a promising alternative to Multi-Layer Perceptrons (MLPs), offering superior parameter efficiency and interpretability. To mitigate KANs&#39; computational overhead, variants like FastKAN leverage Radial Basis Functions (RBFs) to accelerate inference. In this work, we investigate integrating KAN architectures into the DreamerV3 framework. We introduce KAN-Dreamer, replacing specific MLP and convolutional components of DreamerV3 with KAN and FastKAN layers. To ensure efficiency within the JAX-based World Model, we implement a tailored, fully vectorized version with simplified grid management. We structure our investigation into three subsystems: Visual Perception, Latent Prediction, and Behavior Learning. Empirical evaluations on the DeepMind Control Suite (walker_walk) analyze sample efficiency, training time, and asymptotic performance. Experimental results demonstrate that utilizing our adapted FastKAN as a drop-in replacement for the Reward and Continue predictors yields performance on par with the original MLP-based architecture, maintaining parity in both sample efficiency and training speed. This report serves as a preliminary study for future developments in KAN-based world models.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.07437" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.07437" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.07437" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.LG</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling / Neural Architectures, Representation Learning, Advanced Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">20. Stronger Normalization-Free Transformers
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Mingzhi Chen, Taiming Lu, Jiachen Zhu, Mingjie Sun, Zhuang Liu</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A large-scale search for effective point-wise functions identifies $\mathrm{Derf}(x) = \mathrm{erf}(\alpha x + s)$ as a superior normalization-free alternative, consistently surpassing standard normalization layers and Dynamic Tanh across vision, speech, and sequence modeling tasks due to enhanced generalization. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Although normalization layers have long been viewed as indispensable components of deep learning architectures, the recent introduction of Dynamic Tanh (DyT) has demonstrated that alternatives are possible. The point-wise function DyT constrains extreme values for stable convergence and reaches normalization-level performance; this work seeks further for function designs that can surpass it. We first study how the intrinsic properties of point-wise functions influence training and performance. Building on these findings, we conduct a large-scale search for a more effective function design. Through this exploration, we introduce $\mathrm{Derf}(x) = \mathrm{erf}(αx + s)$, where $\mathrm{erf}(x)$ is the rescaled Gaussian cumulative distribution function, and identify it as the most performant design. Derf outperforms LayerNorm, RMSNorm, and DyT across a wide range of domains, including vision (image recognition and generation), speech representation, and DNA sequence modeling. Our findings suggest that the performance gains of Derf largely stem from its improved generalization rather than stronger fitting capacity. Its simplicity and stronger performance make Derf a practical choice for normalization-free Transformer architectures.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.10938" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.10938" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.10938" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.LG</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling / Neural Architectures, Representation Learning, Advanced Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">21. GradientSpace: Unsupervised Data Clustering for Improved Instruction Tuning
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Shrihari Sridharan, Deepak Ravikumar, Anand Raghunathan, Kaushik Roy</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> GradientSpace mitigates gradient interference during LLM instruction tuning by using an online SVD algorithm on full-dimensional LoRA gradients to identify latent skill clusters, enabling efficient routing to specialized experts that outperform prior methods in accuracy and latency. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Instruction tuning is one of the key steps required for adapting large language models (LLMs) to a broad spectrum of downstream applications. However, this procedure is difficult because real-world datasets are rarely homogeneous; they consist of a mixture of diverse information, causing gradient interference, where conflicting gradients pull the model in opposing directions, degrading performance. A common strategy to mitigate this issue is to group data based on semantic or embedding similarity. However, this fails to capture how data influences model parameters during learning. While recent works have attempted to cluster gradients directly, they randomly project gradients into lower dimensions to manage memory, which leads to accuracy loss. Moreover, these methods rely on expert ensembles which necessitates multiple inference passes and expensive on-the-fly gradient computations during inference. To address these limitations, we propose GradientSpace, a framework that clusters samples directly in full-dimensional gradient space. We introduce an online SVD-based algorithm that operates on LoRA gradients to identify latent skills without the infeasible cost of storing all sample gradients. Each cluster is used to train a specialized LoRA expert along with a lightweight router trained to select the best expert during inference. We show that routing to a single, appropriate expert outperforms expert ensembles used in prior work, while significantly reducing inference latency. Our experiments across mathematical reasoning, code generation, finance, and creative writing tasks demonstrate that GradientSpace leads to coherent expert specialization and consistent accuracy gains over state-of-the-art clustering methods and finetuning techniques.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.06678" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.06678" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.06678" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.LG</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling / Neural Architectures, Representation Learning, Advanced Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">22. The stellar and dark matter distributions in elliptical galaxies measured by stacked weak gravitational lensing
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Momoka Fujikawa, Masamune Oguri</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Weak gravitational lensing measurements of luminous red galaxies reveal non-zero core radii in central dark matter profiles for $\sim 10^{11}M_\odot$ galaxies, implying stronger stellar feedback than simulated and favoring a bottom-heavy stellar initial mass function. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We investigate stellar mass and central dark matter density profiles of photometric luminous red galaxies with stellar masses of $\sim10^{10}-10^{12}M_\odot$ using weak gravitational lensing measurements from the Hyper Suprime-Cam Subaru Strategic Program data obtained with the Subaru Telescope. By stacking weak lensing signals from a large number of galaxies, we obtain average tangential shear profiles down to $\sim 10\,\mathrm{kpc}/h$, which are fitted assuming a two-component model consisting of stellar and dark matter components to constrain their central dark matter distribution. We find a preference for non-zero core radii of dark matter distributions in galaxies with stellar masses of $\sim 10^{11}M_\odot$. Our results imply a stronger feedback effect than that typically predicted by current hydrodynamical simulations. In addition, we provide a new constraint on the stellar-to-halo mass relation, where both stellar and halo masses are, for the first time, directly constrained by weak gravitational lensing. Our results prefer the stellar initial mass function (IMF) that is more bottom-heavy than the Salpeter IMF.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.09342" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.09342" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.09342" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.01</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Weak Lensing, Cosmic Shear, Galaxy Surveys / Galaxy-Halo Connection, Lensing, Clustering</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">23. Supervised learning pays attention
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Erin Craig, Robert Tibshirani</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Adapting attention mechanisms to supervised learning for tabular data, attention weighting fits personalized local models by emphasizing predictive features, resulting in improved performance and unique interpretability across heterogeneous and time-series datasets. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">In-context learning with attention enables large neural networks to make context-specific predictions by selectively focusing on relevant examples. Here, we adapt this idea to supervised learning procedures such as lasso regression and gradient boosting, for tabular data. Our goals are to (1) flexibly fit personalized models for each prediction point and (2) retain model simplicity and interpretability. Our method fits a local model for each test observation by weighting the training data according to attention, a supervised similarity measure that emphasizes features and interactions that are predictive of the outcome. Attention weighting allows the method to adapt to heterogeneous data in a data-driven way, without requiring cluster or similarity pre-specification. Further, our approach is uniquely interpretable: for each test observation, we identify which features are most predictive and which training observations are most relevant. We then show how to use attention weighting for time series and spatial data, and we present a method for adapting pretrained tree-based models to distributional shift using attention-weighted residual corrections. Across real and simulated datasets, attention weighting improves predictive performance while preserving interpretability, and theory shows that attention-weighting linear models attain lower mean squared error than the standard linear model under mixture-of-models data-generating processes with known subgroup structure.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.09912" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.09912" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.09912" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">stat.ML</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling / Neural Architectures, Representation Learning, Advanced Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">24. Bayesian Model Selection with an Application to Cosmology
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Nikoloz Gigiberia</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Bayesian model comparison using DES-SN5YR Type Ia supernova data indicates that the $w$CDM cosmological model is statistically preferred over $\Lambda$CDM and CPL, despite all three exhibiting similar predictive accuracy. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We investigate cosmological parameter inference and model selection from a Bayesian perspective. Type Ia supernova data from the Dark Energy Survey (DES-SN5YR) are used to test the $Λ$CDM, $w$CDM, and CPL cosmological models. Posterior inference is performed via Hamiltonian Monte Carlo using the No-U-Turn Sampler (NUTS) implemented in NumPyro and analyzed with ArviZ in Python. Bayesian model comparison is conducted through Bayes factors computed using the bridgesampling library in R. The results indicate that all three models demonstrate similar predictive performance, but $w$CDM shows stronger evidence relative to $Λ$CDM and CPL. We conclude that, under the assumptions and data used in this study, $w$CDM provides a better description of cosmological expansion.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.09724" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.09724" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.09724" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">stat.AP</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">25. Transformers for Tabular Data: A Training Perspective of Self-Attention via Optimal Transport
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Antonio Candelieri, Alessandro Quadrio</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Analyzing self-attention training through Optimal Transport (OT) reveals an inefficient trajectory despite approximating optimal coupling, leading to the development of an OT-based classification algorithm that matches Transformer accuracy while offering improved computational efficiency. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">This thesis examines self-attention training through the lens of Optimal Transport (OT) and develops an OT-based alternative for tabular classification. The study tracks intermediate projections of the self-attention layer during training and evaluates their evolution using discrete OT metrics, including Wasserstein distance, Monge gap, optimality, and efficiency. Experiments are conducted on classification tasks with two and three classes, as well as on a biomedical dataset. Results indicate that the final self-attention mapping often approximates the OT optimal coupling, yet the training trajectory remains inefficient. Pretraining the MLP section on synthetic data partially improves convergence but is sensitive to their initialization. To address these limitations, an OT-based algorithm is introduced: it generates class-specific dummy Gaussian distributions, computes an OT alignment with the data, and trains an MLP to generalize this mapping. The method achieves accuracy comparable to Transformers while reducing computational cost and scaling more efficiently under standardized inputs, though its performance depends on careful dummy-geometry design. All experiments and implementations are conducted in R.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.09530" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.09530" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.09530" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">stat.ML</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling / Neural Architectures, Representation Learning, Advanced Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">26. CWTHF: Subhalo Identification with Continuous Wavelet Transform
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Minxing Li, Yun Wang, Ping He</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The Continuous Wavelet Transform Halo Finder (CWTHF) framework is extended to reliably identify gravitationally bound subhalos in cosmological simulations by incorporating an unbinding procedure, achieving validation against SUBFIND catalogs while maintaining linear time complexity. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">With advances in cosmology and computer science, cosmological simulations now resolve structures in increasingly fine detail. As key tracers of hierarchical structure formation, subhalos are among the most important objects within these simulations. In our previous work, we established that the continuous wavelet transform (CWT) can effectively extract clustering information and serve as a robust halo finder. Here, we extend the CWT framework to subhalo identification by adapting the CWTHF (Continuous Wavelet Transform Halo Finder) code. This extension extends the unbinding procedure, which enables the reliable identification of gravitationally bound substructures. The algorithm identifies density peaks within known halos or subhalos and segments the surrounding volume accordingly. Once a new subhalo is registered, its position is recorded to prevent duplicate detection. We validate our approach using the TNG50-2 and TNG100-1 simulations, as well as a single Friends-of-Friends (FOF) halo, by comparing the resulting CWT catalog against the reference SUBFIND catalog. Because the method inherits the original computational framework, our subhalo finder maintains a favorable linear time complexity of $\mathcal{O}(N)$.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.09359" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.09359" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.09359" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.IM</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">27. Clues from $\mathcal{Q}$--A null test designed for line intensity mapping cross-correlation studies
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Debanjan Sarkar, Ella Iles, Adrian Liu</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A new diagnostic statistic, $\mathcal{Q}$, constructed from multi-line cross-spectra, serves as a data-driven null test in line-intensity mapping (LIM) to reliably identify cosmological modes where the assumptions required for unbiased auto-spectrum reconstruction are valid. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Estimating the auto power spectrum of cosmological tracers from line-intensity mapping (LIM) data is often limited by instrumental noise, residual foregrounds, and systematics. Cross-power spectra between multiple lines offer a robust alternative, mitigating noise bias and systematics. However, inferring the auto spectrum from cross-correlations relies on two key assumptions: that all tracers are linearly biased with respect to the matter density field, and that they are strongly mutually correlated. In this work, we introduce a new diagnostic statistic, \(\mathcal{Q}\), which serves as a data-driven null test of these assumptions. Constructed from combinations of cross-spectra between four distinct spectral lines, \(\mathcal{Q}\) identifies regimes where cross-spectrum-based auto-spectrum reconstruction is unbiased. We validate its behavior using both analytic toy models and simulations of LIM observables, including star formation lines ([CII], [NII], [CI],[OIII]) and the 21-cm signal. We explore a range of redshifts and instrumental configurations, incorporating noise from representative surveys. Our results demonstrate that the criterion \( \mathcal{Q} \approx 1 \) reliably selects the modes where cross-spectrum estimators are valid, while significant deviations are an indicator that the key assumptions have been violated. The \( \mathcal{Q} \) diagnostic thus provides a simple yet powerful data-driven consistency check for multi-tracer LIM analyses.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.09984" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.09984" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.09984" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">28. Evidence for evolving Dark Energy from a new cosmic probe
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Isaque Dutra, Colin J. Burke, Priyamvada Natarajan, Weixiang Yu</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Utilizing Active Galactic Nuclei (AGN) light curves to construct a Hubble diagram up to $z \sim 3.5$, joint cosmological inference provides strong evidence (up to $4.8\sigma$) for an evolving dark energy equation of state over the standard $\Lambda$CDM model, potentially addressing the Hubble tension. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The $Λ$CDM concordance cosmological model provides a remarkably successful description of the formation and evolution of structure in the Universe. However, a growing discrepancy between measurements of the expansion rate $H_0$ from the near and distant Universe now appears to be significant at the ~4-7 $σ$ level. This inconsistency, known as the ``Hubble tension&#39;&#39;, has arisen either due to unrecognized systematics in these measurements or new physics beyond the standard model, such as an evolving dark energy equation of state. Modeling ~20-year, multi-band optical light curves for 6992 active galactic nuclei (AGN), we find a tight relation linking the variability amplitude and characteristic timescale to their intrinsic luminosity. This empirical law enables us to construct an AGN-based Hubble diagram to z ~3.5. Joint inference with supernova distances reveals evidence for an evolving dark energy equation of state at the 3.8-3.9 $σ$ level over constant w models and 4.4-4.8 $σ$ over $Λ$CDM. Our results establish AGN light curves as a powerful tool for cosmography that could offer a novel pathway to test deviations from the standard $Λ$CDM expansion history.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.07931" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.07931" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.07931" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.02</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Weak Lensing, Cosmic Shear, Galaxy Surveys / Galaxy-Halo Connection, Lensing, Clustering</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">29. SparseSwaps: Tractable LLM Pruning Mask Refinement at Scale
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Max Zimmer, Christophe Roux, Moritz Wagner, Deborah Hendrych, Sebastian Pokutta</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A tractable and efficient 1-swap algorithm for LLM pruning, which enforces equal row sparsity to optimize layer-wise mask selection using the Gram matrix, substantially reduces pruning error and improves performance metrics across GPT models. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The resource requirements of Neural Networks can be significantly reduced through pruning -- the removal of seemingly less important parameters. However, with the rise of Large Language Models (LLMs), full retraining to recover pruning-induced performance degradation is often prohibitive and classical approaches such as global magnitude pruning are suboptimal on Transformer architectures. State-of-the-art methods hence solve a layer-wise mask selection problem, the problem of finding a pruning mask which minimizes the per-layer pruning error on a small set of calibration data. Exactly solving this problem to optimality using Integer Programming (IP) solvers is computationally infeasible due to its combinatorial nature and the size of the search space, and existing approaches therefore rely on approximations or heuristics. In this work, we demonstrate that the mask selection problem can be made drastically more tractable at LLM scale. To that end, we decouple the rows by enforcing equal sparsity levels per row. This allows us to derive optimal 1-swaps (exchanging one kept and one pruned weight) that can be computed efficiently using the Gram matrix of the calibration data. Using these observations, we propose a tractable and simple 1-swap algorithm that warm starts from any pruning mask, runs efficiently on GPUs at LLM scale, and is essentially hyperparameter-free. We demonstrate that our approach reduces per-layer pruning error by up to 60% over Wanda (Sun et al., 2023) and consistently improves perplexity and zero-shot accuracy across state-of-the-art GPT architectures.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.10922" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.10922" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.10922" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.LG</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling / Neural Architectures, Representation Learning, Advanced Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">30. Beyond Two Parameters: Revisiting Dark Energy with the Latest Cosmic Probes
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Hanyu Cheng, Supriya Pan, Eleonora Di Valentino</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A four-parameter dynamical dark energy model, constrained by combined CMB, BAO, and supernova data, suggests a transition from early phantom behavior to present-day quintessential behavior and is statistically preferred over the $\Lambda$CDM scenario by specific dataset combinations. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Dark energy (DE) models with many free parameters are often considered excessive, as constraining all parameters poses a significant challenge. On the other hand, such models offer greater flexibility to probe the DE sector in more detail. With the rapid advancement of astronomical surveys and the availability of diverse datasets, it is timely to examine whether current combined observations can effectively constrain an extended parameter space in DE models. This article investigates a four-parameter dynamical dark energy (DDE) model that spans a broad region of the universe&#39;s expansion history through four key parameters: the present-day value of the DE equation of state ($w_0$), its initial value ($w_m$), the scale factor depicting transition from $w_m$ to $w_0$ occurs ($a_t$), and the steepness of this transition ($Δ_{\rm de}$). We constrain the model using CMB data from Planck, BAO from DESI DR2, and three distinct compilations of Type Ia Supernovae: PantheonPlus, DESY5, and Union3. Our results show that constraining all four parameters remains difficult: $a_t$ is not constrained by any dataset, while the remaining three parameters can be constrained only when all observational probes are combined (with the exception of DESY5). The results further show that DE has a quintessential nature at present ($w_0 &gt; -1$), while $w_m$ is negative, indicating a phantom-like behaviour at early times. Interestingly, despite its larger parameter space, the proposed DDE model is preferred over the $Λ$CDM scenario, based on both $Δχ^2$ and Bayesian evidence, for certain combined datasets, particularly CMB+BAO+DESY5 and CMB+BAO+Union3.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.09866" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.09866" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.09866" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.02</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">31. Is Dark Energy Dynamical in the DESI Era? A Critical Review
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Salvatore Capozziello, Himanshu Chaudhary, Tiberiu Harko, Ghulam Mustafa</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A comprehensive MCMC analysis integrating DESI DR2 BAO and Lyα data with other cosmological measurements investigates the statistical preference for dynamical dark energy models over the standard ΛCDM cosmology. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We investigate whether the recent DESI DR2 measurements provide or not evidences for dynamical dark energy by exploring the $ω_0ω_a$CDM model and its extensions with free $\sum m_ν$ and $N_{\mathrm{eff}}$. Using a comprehensive MCMC analysis with a wide range of cosmological datasets including DESI~DR2 BAO and Ly$α$ data, CMB compressed likelihoods, BBN, cosmic chronometers, and multiple Type~Ia supernova compilations, we assess the statistical preference for departures from $Λ$CDM.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.10585" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.10585" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.10585" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling / Cluster 2</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">32. Representation Calibration and Uncertainty Guidance for Class-Incremental Learning based on Vision Language Model
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Jiantao Tan, Peixian Ma, Tong Yu, Wentao Zhang, Ruixuan Wang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> A novel Vision-Language Model framework for class-incremental learning utilizes task-specific adapters, a cross-task representation calibration strategy, and uncertainty-guided inference to effectively mitigate class confusion and outperform state-of-the-art methods. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Class-incremental learning requires a learning system to continually learn knowledge of new classes and meanwhile try to preserve previously learned knowledge of old classes. As current state-of-the-art methods based on Vision-Language Models (VLMs) still suffer from the issue of differentiating classes across learning tasks. Here a novel VLM-based continual learning framework for image classification is proposed. In this framework, task-specific adapters are added to the pre-trained and frozen image encoder to learn new knowledge, and a novel cross-task representation calibration strategy based on a mixture of light-weight projectors is used to help better separate all learned classes in a unified feature space, alleviating class confusion across tasks. In addition, a novel inference strategy guided by prediction uncertainty is developed to more accurately select the most appropriate image feature for class prediction. Extensive experiments on multiple datasets under various settings demonstrate the superior performance of our method compared to existing ones.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.09441" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.09441" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.09441" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.01</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">cs.CV</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling / Neural Architectures, Representation Learning, Advanced Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">33. TreeGRPO: Tree-Advantage GRPO for Online RL Post-Training of Diffusion Models
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Zheng Ding, Weirui Ye</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> TreeGRPO, a novel reinforcement learning framework, accelerates the alignment of visual generative models by recasting the denoising process as a search tree, enabling efficient prefix reuse, fine-grained credit assignment, and 2.4× faster training than baseline methods. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Reinforcement learning (RL) post-training is crucial for aligning generative models with human preferences, but its prohibitive computational cost remains a major barrier to widespread adoption. We introduce \textbf{TreeGRPO}, a novel RL framework that dramatically improves training efficiency by recasting the denoising process as a search tree. From shared initial noise samples, TreeGRPO strategically branches to generate multiple candidate trajectories while efficiently reusing their common prefixes. This tree-structured approach delivers three key advantages: (1) \emph{High sample efficiency}, achieving better performance under same training samples (2) \emph{Fine-grained credit assignment} via reward backpropagation that computes step-specific advantages, overcoming the uniform credit assignment limitation of trajectory-based methods, and (3) \emph{Amortized computation} where multi-child branching enables multiple policy updates per forward pass. Extensive experiments on both diffusion and flow-based models demonstrate that TreeGRPO achieves \textbf{2.4$\times$ faster training} while establishing a superior Pareto frontier in the efficiency-reward trade-off space. Our method consistently outperforms GRPO baselines across multiple benchmarks and reward models, providing a scalable and effective pathway for RL-based visual generative model alignment. The project website is available at treegrpo.github.io.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.08153" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.08153" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.08153" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.LG</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling / Neural Architectures, Representation Learning, Advanced Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">34. Forecasting Dark Matter Subhalo Constraints from Stellar Streams using Implicit Likelihood Inference
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">Tri Nguyen, Rutong Pei, Zhuofu Li, Nora Shipp, Scott Dodelson, Denis Erkal, Peter S. Ferguson, Tjitske K. Starkenburg, Markus M. Rau, Alexander H. Riley, et al.</span>
                                <span class="author-full" style="display: none;">Tri Nguyen, Rutong Pei, Zhuofu Li, Nora Shipp, Scott Dodelson, Denis Erkal, Peter S. Ferguson, Tjitske K. Starkenburg, Markus M. Rau, Alexander H. Riley, Alan Junzhe Zhou, the LSST Dark Energy Science Collaboration</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Neural Posterior Estimation applied to stellar stream kinematics accurately constrains Dark Matter subhalo parameters, demonstrating that combining future large photometric surveys with targeted spectroscopic follow-up effectively resolves kinematic degeneracies and achieves mass uncertainties as low as 20%. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The evidence for dark matter (DM) remains compelling, although attempts to understand its particle nature remain inconclusive. One promising method to study DM is detecting DM subhalos through their gravitational interactions with stellar streams. In this study, we apply Neural Posterior Estimation (NPE) to constrain subhalo interaction parameters, including mass, scale radius, velocity, and encounter geometry, from stellar stream kinematics. We generate particle spray simulations based on the Lagrange Cloud stripping technique, focusing on the ATLAS-Aliqa Uma stream as a test case. We train multiple NPE models across multiple observational scenarios, quantifying how kinematic completeness affects inference and forecasting constraints from upcoming surveys including LSST, 4MOST, and 10-year Gaia data. Our results demonstrate that NPE can produce accurate and well-calibrated posteriors. In the idealized case with full 6D coordinates, we achieve subhalo mass uncertainties of 15-20% for a $10^7 \, \mathrm{M_\odot}$ subhalo, with 5D coordinates (excluding radial velocities) achieving similar performance. Under realistic observational conditions, mass uncertainties range from 50% (present-day) to 20-40% (future scenarios), with comparable performance between the photometric-only LSST sample and a smaller sample that includes Gaia proper motions and 4MOST radial velocities. Most notably, we find that velocity bimodality emerges when phase space is poorly sampled, whether due to missing kinematic information or limited stellar tracers. Combining large photometric samples with targeted spectroscopic follow-up can effectively resolves this degeneracy. These results demonstrate the power of implicit likelihood inference for optimizing stellar stream observational strategies and forecasting DM subhalo constraints from upcoming surveys.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.07960" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.07960" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.07960" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.02</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">35. CONCUR: A Framework for Continual Constrained and Unconstrained Routing
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Peter Baile Chen, Weiyue Li, Dan Roth, Michael Cafarella, Samuel Madden, Jacob Andreas</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The CONCUR continual routing framework utilizes a modular design with strategy-specific predictors and multiple task representations to efficiently map AI tasks to optimal computation strategies, significantly reducing training overhead and improving performance over existing routing methods. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">AI tasks differ in complexity and are best addressed with different computation strategies (e.g., combinations of models and decoding methods). Hence, an effective routing system that maps tasks to the appropriate strategies is crucial. Most prior methods build the routing framework by training a single model across all strategies, which demands full retraining whenever new strategies appear and leads to high overhead. Attempts at such continual routing, however, often face difficulties with generalization. Prior models also typically use a single input representation, limiting their ability to capture the full complexity of the routing problem and leading to sub-optimal routing decisions. To address these gaps, we propose CONCUR, a continual routing framework that supports both constrained and unconstrained routing (i.e., routing with or without a budget). Our modular design trains a separate predictor model for each strategy, enabling seamless incorporation of new strategies with low additional training cost. Our predictors also leverage multiple representations of both tasks and computation strategies to better capture overall problem complexity. Experiments on both in-distribution and out-of-distribution, knowledge- and reasoning-intensive tasks show that our method outperforms the best single strategy and strong existing routing techniques with higher end-to-end accuracy and lower inference cost in both continual and non-continual settings, while also reducing training cost in the continual setting.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.09386" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.09386" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.09386" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.CL</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling / Neural Architectures, Representation Learning, Advanced Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">36. $\mathrm{D}^\mathrm{3}$-Predictor: Noise-Free Deterministic Diffusion for Dense Prediction
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Changliang Xia, Chengyou Jia, Minnan Luo, Zhuohang Dang, Xin Shen, Bowen Ping</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> D³-Predictor is a noise-free deterministic framework that reformulates pretrained diffusion models as an ensemble of visual experts, aggregating their priors to create a clean geometric prior for efficient, single-step, and state-of-the-art dense prediction. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Although diffusion models with strong visual priors have emerged as powerful dense prediction backboens, they overlook a core limitation: the stochastic noise at the core of diffusion sampling is inherently misaligned with dense prediction that requires a deterministic mapping from image to geometry. In this paper, we show that this stochastic noise corrupts fine-grained spatial cues and pushes the model toward timestep-specific noise objectives, consequently destroying meaningful geometric structure mappings. To address this, we introduce $\mathrm{D}^\mathrm{3}$-Predictor, a noise-free deterministic framework built by reformulating a pretrained diffusion model without stochasticity noise. Instead of relying on noisy inputs to leverage diffusion priors, $\mathrm{D}^\mathrm{3}$-Predictor views the pretrained diffusion network as an ensemble of timestep-dependent visual experts and self-supervisedly aggregates their heterogeneous priors into a single, clean, and complete geometric prior. Meanwhile, we utilize task-specific supervision to seamlessly adapt this noise-free prior to dense prediction tasks. Extensive experiments on various dense prediction tasks demonstrate that $\mathrm{D}^\mathrm{3}$-Predictor achieves competitive or state-of-the-art performance in diverse scenarios. In addition, it requires less than half the training data previously used and efficiently performs inference in a single step. Our code, data, and checkpoints are publicly available at https://x-gengroup.github.io/HomePage_D3-Predictor/.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.07062" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.07062" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.07062" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.CV</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling / Neural Architectures, Representation Learning, Advanced Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">37. Model independent approach towards measuring expansion and growth factor from next generation galaxy clustering and lensing angular power spectrum
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Ziad Sakr</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Model-independent Fisher forecasts using 3x2pt joint analysis of future surveys (Euclid, Rubin, SKA) demonstrate that utilizing non-linear scales yields high-precision, percent-level constraints on the expansion factor E(z) and significantly improved constraints on the growth factor G(z). (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">In this work we perform Fisher forecasts on the expansion and the growth factors following model independent approaches from 3x2pt joint analysis of the galaxy lensing, clustering, and their cross-correlated spectra at the linear, and extending as well to non linear scales. For that, instead of choosing a specific model for the matter power spectrum, the main ingredient of these probes, we express it by parametrizing its components, such as the expansion and the growth factor, and those of the standard halo model and excursion set theory in several z bins, besides to the different bias and non-linear bias modelling functions. We apply the technique to Euclid, Rubin and SKA public specifications in the range 0.2 &lt; z &lt; 1.8 and show that one can then obtain model-independent constraints of the expansion E(z i ) and the growth factor G(z i ). We also show the change in gain in precision at each z- shell when going from pessimistic cut at linear scales to more optimistic non-linear settings, or the difference between using each survey alone or a combination of all of them, or the impact from fixing or adding more degrees of freedom in the non-linear modeling. We found that, in the most agnostic case, one can still reach high precision on E(z i ) in the order of the percent level when combining the three surveys at once while the growth factor G(z i ) has for the same settings one order of magnitude weaker constraints. We also found for both factors, an improvement that can reach one order of magnitude in precision when passing from linear to non-linear scales. We conclude that we will be able to constrain the two important factors of the background evolution and structure formation of the Universe when using non linear scales and the combined power of future surveys even in the most agnostic approaches.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.10742" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.10742" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.10742" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">38. Inference of $B$-mode polarization in the presence of non-Gaussian foregrounds
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Sen Li, Chang Feng, Filipe B. Abdalla</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Inference of primordial gravitational wave B-mode signals in CMB polarization is achieved by combining the constrained moment internal linear combination (cMILC) method, which handles spatially varying foreground spectral energy distributions, with a power-spectrum approach to extract cosmological components. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The inflationary $B$-mode signals encode invaluable information about the origin of our Universe and searching for potential signatures of primordial gravitational waves (PGWs) is one of the major science goals for future precision observations of cosmic microwave background (CMB) polarization. However, dominant $B$-mode signals of both Galactic foreground contamination and gravitational lensing effects prevent direct measurements of the PGW $B$-mode signals. There are existing proposals which can effectively eliminate these two contaminants but issues remain for future high-sensitivity and multifrequency CMB polarization observations, such as spatially-varying spectral energy distribution (SED) of polarized foreground and cosmological $B$-mode signals due to primordial magnetic fields (PMFs). In this work, we investigate inference of PGW $B$-mode signals in the presence of both complexities. We employ a constrained moment internal linear combination (cMILC) method to remove polarization signals arising from spatially varying SEDs. Also, we employ a power-spectrum-based approach to extracting both the Galactic and cosmological $B$-mode components. Two methods have been validated by mock data and different consistency tests have been performed. We apply these two methods to end-to-end simulations for future high-sensitivity and multifrequency polarization observations and investigate the detectability of different $B$-mode signals in the presence of non-Gaussian polarized foregrounds under different scenarios. This study will be important for new physics studies with $B$-mode signatures.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.07235" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.07235" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.07235" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.01</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">39. Training-Free Dual Hyperbolic Adapters for Better Cross-Modal Reasoning
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Yi Zhang, Chun-Wun Cheng, Junyi He, Ke Yu, Yushun Tang, Carola-Bibiane Schönlieb, Zhihai He, Angelica I. Aviles-Rivero</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Training-free Dual Hyperbolic Adapters (T-DHA) leverage the Poincaré ball model to embed hierarchical vision-language relationships in hyperbolic space, achieving superior representation and discrimination power for efficient few-shot and domain generalization adaptation of large VLMs. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Recent research in Vision-Language Models (VLMs) has significantly advanced our capabilities in cross-modal reasoning. However, existing methods suffer from performance degradation with domain changes or require substantial computational resources for fine-tuning in new domains. To address this issue, we develop a new adaptation method for large vision-language models, called \textit{Training-free Dual Hyperbolic Adapters} (T-DHA). We characterize the vision-language relationship between semantic concepts, which typically has a hierarchical tree structure, in the hyperbolic space instead of the traditional Euclidean space. Hyperbolic spaces exhibit exponential volume growth with radius, unlike the polynomial growth in Euclidean space. We find that this unique property is particularly effective for embedding hierarchical data structures using the Poincaré ball model, achieving significantly improved representation and discrimination power. Coupled with negative learning, it provides more accurate and robust classifications with fewer feature dimensions. Our extensive experimental results on various datasets demonstrate that the T-DHA method significantly outperforms existing state-of-the-art methods in few-shot image recognition and domain generalization tasks.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.08820" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.08820" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.08820" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.CV</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling / Neural Architectures, Representation Learning, Advanced Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">40. Winning the Lottery by Preserving Network Training Dynamics with Concrete Ticket Search
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Tanay Arora, Christof Teuscher</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Concrete Ticket Search (CTS) efficiently identifies high-performing, highly sparse subnetworks near initialization by framing the discovery as a combinatorial optimization problem using Concrete relaxation and a knowledge distillation objective, significantly reducing the computational cost compared to Lottery Ticket Rewinding. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The Lottery Ticket Hypothesis asserts the existence of highly sparse, trainable subnetworks (&#39;winning tickets&#39;) within dense, randomly initialized neural networks. However, state-of-the-art methods of drawing these tickets, like Lottery Ticket Rewinding (LTR), are computationally prohibitive, while more efficient saliency-based Pruning-at-Initialization (PaI) techniques suffer from a significant accuracy-sparsity trade-off and fail basic sanity checks. In this work, we argue that PaI&#39;s reliance on first-order saliency metrics, which ignore inter-weight dependencies, contributes substantially to this performance gap, especially in the sparse regime. To address this, we introduce Concrete Ticket Search (CTS), an algorithm that frames subnetwork discovery as a holistic combinatorial optimization problem. By leveraging a Concrete relaxation of the discrete search space and a novel gradient balancing scheme (GRADBALANCE) to control sparsity, CTS efficiently identifies high-performing subnetworks near initialization without requiring sensitive hyperparameter tuning. Motivated by recent works on lottery ticket training dynamics, we further propose a knowledge distillation-inspired family of pruning objectives, finding that minimizing the reverse Kullback-Leibler divergence between sparse and dense network outputs (CTS-KL) is particularly effective. Experiments on varying image classification tasks show that CTS produces subnetworks that robustly pass sanity checks and achieve accuracy comparable to or exceeding LTR, while requiring only a small fraction of the computation. For example, on ResNet-20 on CIFAR10, it reaches 99.3% sparsity with 74.0% accuracy in 7.9 minutes, while LTR attains the same sparsity with 68.3% accuracy in 95.2 minutes. CTS&#39;s subnetworks outperform saliency-based methods across all sparsities, but its advantage over LTR is most pronounced in the highly sparse regime.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.07142" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.07142" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.07142" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.LG</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling / Neural Architectures, Representation Learning, Advanced Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">41. ClearPotential: Revealing Local Dark Matter in Three Dimensions
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Eric Putney, David Shih, Sung Hak Lim, Matthew R. Buckley</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Unsupervised machine learning, utilizing a neural network to solve the collisionless Boltzmann equation for Gaia DR3 data, provides the clearest three-dimensional map of the local Milky Way gravitational potential to date, constraining the solar dark matter density and revealing a tilted oblate halo structure. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We present ClearPotential, a data-driven, three-dimensional measurement of the gravitational potential of the local Milky Way using unsupervised machine learning, without the symmetry assumptions, specific functional forms, and binning required in previous work. The potential is modeled as a neural network, optimized to solve the equilibrium collisionless Boltzmann equation for the observed phase space density of Gaia DR3 Red Clump stars within 4 kpc of the Sun. This density is obtained from data using normalizing flows, and our unsupervised solution to the Boltzmann equation automatically corrects for selection effects from crowding and the dust-driven extinction of starlight. Our fully-differentiable model of the gravitational potential allows us to map the acceleration and mass density of the Galaxy in the volume around the Sun, including in the dust-obscured disk towards the Galactic Center. We determine the dark matter density at the Solar radius to be $(0.84 \pm 0.08)\times 10^{-2}\,{M}_\odot/{\rm pc}^3$, and analyze the structure of the dark matter halo. We find strong evidence for a tilted oblate halo, weak preference for a cored inner profile, and the strongest constraints to date on a possible dark matter disk. We place a bound on the timescale of disequilibrium in the local Milky Way, and find mild evidence for disequilibrium using independent acceleration measurements from timings of binary pulsar systems. This work provides the clearest map of the local Galactic potential to date and marks an important step in the era of data-driven astrometry.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.09989" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.09989" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.09989" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Weak Lensing, Cosmic Shear, Galaxy Surveys / Galaxy-Halo Connection, Lensing, Clustering</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">42. The Role of Entropy in Visual Grounding: Analysis and Optimization
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">Shuo Li, Jiajun Sun, Zhihao Zhang, Xiaoran Fan, Senjie Jin, Hui Li, Yuming Yang, Junjie Ye, Lixing Shen, Tao Ji, et al.</span>
                                <span class="author-full" style="display: none;">Shuo Li, Jiajun Sun, Zhihao Zhang, Xiaoran Fan, Senjie Jin, Hui Li, Yuming Yang, Junjie Ye, Lixing Shen, Tao Ji, Tao Gui, Qi Zhang, Xuanjing Huang</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The interpretable ECVGPO algorithm effectively regulates entropy during reinforcement learning fine-tuning of multimodal large language models for visual grounding, successfully balancing exploration and exploitation to achieve superior performance across various benchmarks. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Recent advances in fine-tuning multimodal large language models (MLLMs) using reinforcement learning have achieved remarkable progress, particularly with the introduction of various entropy control techniques. However, the role and characteristics of entropy in perception-oriented tasks like visual grounding, as well as effective strategies for controlling it, remain largely unexplored. To address this issue, we focus on the visual grounding task and analyze the role and characteristics of entropy in comparison to reasoning tasks. Building on these findings, we introduce ECVGPO (Entropy Control Visual Grounding Policy Optimization), an interpretable algorithm designed for effective entropy regulation. Through entropy control, the trade-off between exploration and exploitation is better balanced. Experiments show that ECVGPO achieves broad improvements across various benchmarks and models.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.06726" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.06726" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.06726" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">cs.CV</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling / Neural Architectures, Representation Learning, Advanced Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">43. OutLines: Modeling Spectral Lines from Winds, Bubbles, and Outflows
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Sophia R. Flury</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The publicly released Python code OutLines provides physically motivated astrophysical models for spectral emission and absorption line profiles of outflows, enabling more accurate analysis of kinematics and geometry across diverse environments like H II regions, starburst galaxies, and AGNs. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Common methods for studying the kinematics and geometry of outflowing gas rely on modeling emission and absorption lines in integrated spectra using methods that are not physically motivated, including empirical quantiles or fitting multiple Gaussian or Voigt profiles. Such methods are not always consistent with the interpretation of these features and, as a result, miss key underlying physics and can even lead to inaccurate interpretations of observations. To address this problem, we present the publicly available python code OutLines, which provides astrophysical models of spectral emission and absorption line profiles produced by outflows in a variety of environments. The OutLines code accounts for differences in parameterization of the velocity field and density profile while allowing for different outflow geometries, making OutLines versatile and useful for a wide variety of astrophysical phenomena. We demonstrate the wide applicability of OutLines by using the code to model line profiles in an H II region knot, super star clusters, a starburst galaxy, and an AGN. In each of these contexts, we illustrate how OutLines can illuminate key underlying physics in ways that improve our scientific understanding and address important open questions in astronomy, including the key mechanisms in the baryon cycle, the evolution of H II regions and galaxies, and even Lyman continuum escape. OutLines will be a critical resource as massively multiplexed spectroscopic surveys like WEAVE-LOFAR and 4MOST/WAVES come online, providing the means to probe feedback kinematics with deeper, higher resolution spectroscopy for unprecedented large samples of galaxies.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.10650" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.10650" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.10650" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">44. Generative Modeling from Black-box Corruptions via Self-Consistent Stochastic Interpolants
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Chirag Modi, Jiequn Han, Eric Vanden-Eijnden, Joan Bruna</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The self-consistent stochastic interpolant (SCSI) method iteratively updates a transport map between corrupted and clean data samples to solve inverse problems at the distribution level, efficiently generating clean data by effectively inverting arbitrary nonlinear corruption channels. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Transport-based methods have emerged as a leading paradigm for building generative models from large, clean datasets. However, in many scientific and engineering domains, clean data are often unavailable: instead, we only observe measurements corrupted through a noisy, ill-conditioned channel. A generative model for the original data thus requires solving an inverse problem at the level of distributions. In this work, we introduce a novel approach to this task based on Stochastic Interpolants: we iteratively update a transport map between corrupted and clean data samples using only access to the corrupted dataset as well as black box access to the corruption channel. Under appropriate conditions, this iterative procedure converges towards a self-consistent transport map that effectively inverts the corruption channel, thus enabling a generative model for the clean data. We refer to the resulting method as the self-consistent stochastic interpolant (SCSI). It (i) is computationally efficient compared to variational alternatives, (ii) highly flexible, handling arbitrary nonlinear forward models with only black-box access, and (iii) enjoys theoretical guarantees. We demonstrate superior performance on inverse problems in natural image processing and scientific reconstruction, and establish convergence guarantees of the scheme under appropriate assumptions.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.10857" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.10857" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.10857" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.05</span>
                        <span class="badge bg-primary">Semantic Score: 0.92</span>
                        
                            <span class="badge bg-secondary">cs.LG</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">45. PolySwyft: sequential simulation-based nested sampling
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Kilian H. Scheutwinkel, Will Handley, Christoph Weniger, Eloy de Lera Acedo</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> PolySwyft, a novel simulation-based inference framework, integrates nested sampling with neural ratio estimation using an adaptive KL-divergence criterion, achieving faster and rigorously Bayesian-valid convergence for complex, multimodal posteriors with intractable likelihoods. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We present PolySwyft, a novel, non-amortised simulation-based inference framework that unites the strengths of nested sampling (NS) and neural ratio estimation (NRE) to tackle challenging posterior distributions when the likelihood is intractable but a forward simulator is available. By nesting rounds of NRE within the exploration of NS, and employing a principled KL-divergence criterion to adaptively terminate sampling, PolySwyft achieves faster convergence on complex, multimodal targets while rigorously preserving Bayesian validity. On a suite of toy problems with analytically known posteriors of a dim(theta,D)=(5,100) multivariate Gaussian and multivariate correlated Gaussian mixture model, we demonstrate that PolySwyft recovers all modes and credible regions with fewer simulator calls than swyft&#39;s TNRE. As a real-world application, we infer cosmological parameters dim(theta,D)=(6,111) from CMB power spectra using CosmoPower. PolySwyft is released as open-source software, offering a flexible toolkit for efficient, accurate inference across the astrophysical sciences and beyond.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.08316" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.08316" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.08316" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.01</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.IM</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">46. Counting voids and filaments: Betti Curves as a Powerful Probe for Cosmology
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Jiayi Li, Cheng Zhao</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Utilizing Betti curves derived from persistent homology to characterize the multiscale topology of large-scale structures, Bayesian inference recovers unbiased cosmological parameters and significantly tightens constraints when combined with the traditional power spectrum, particularly when accounting for redshift-space distortions. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">Topological analysis of galaxy distributions has gathered increasing attention in cosmology, as they are able to capture non-Gaussian features of large-scale structures (LSS) that are overlooked by conventional two-point clustering statistics. We utilize Betti curves, a summary statistic derived from persistent homology, to characterize the multiscale topological features of the LSS, including connected components, loops, and voids, as a complementary cosmological probe. Using halo catalogs from the \textsc{Quijote} suite, we construct Betti curves, assess their sensitivity to cosmological parameters, and train automated machine learning based emulators to model their dependence on cosmological parameters. Our Bayesian inference recovers unbiased estimation of cosmological parameters, notably $n_{\mathrm{s}}$, $σ_8$, and $Ω_{\mathrm{m}}$, while validation on sub-box simulations confirms robustness against cosmic variance. We further investigate the impact of redshift-space distortions (RSD) on Betti curves and demonstrate that including RSD enhances sensitivity to growth-related parameters. By jointly analyzing Betti curves and the power spectrum, we achieve significantly tightened constraints than using power spectrum alone on parameters such as $n_{\mathrm{s}}$, $σ_8$, and $w$. These findings highlight Betti curves -- especially when combined with traditional two-point statistics -- as a promising, interpretable tool for future galaxy survey analyses.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.07236" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.07236" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.07236" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">47. Primordial non-Gaussianity -- Fast simulations and persistent summary statistics
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Juan Calles, Gabriella Contardo, Jorge Noreña, Jacky H. T. Yip, Gary Shiu</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Analyzing a new suite of primordial non-Gaussianity simulations, descriptive statistics of topological features (PD-statistics) demonstrate superior constraining power for equilateral $f_{\rm NL}$ compared to power spectrum and bispectrum measurements, with sensitivity predominantly residing in large-mass halos. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We investigate the sensitivity of topological and traditional summary statistics to primordial non-Gaussianity (PNG) using two suites of simulations. First, we introduce a new simulation suite for PNG, PNG-pmwd, comprising more than $20{,}000$ halo catalogs that vary individually local and equilateral shapes, together with variations in $Ω_m$ and $σ_8$. Second, we carry out a systematic comparison of topological descriptors, as well as powerspectrum and bispectrum measurements, evaluating their constraining power on both local and equilateral $f_{\rm NL}$ and how this sensitivity varies with halo mass. This dataset enables likelihood-free neural regression of $f_{\rm NL}$ across multiple halo mass bins for a wide range of summary statistics. Third, we assess the transferability of these learned mappings by testing whether models trained on fast pmwd simulations can robustly infer on simulations from the QuijotePNG suite. We find that a combination of simple descriptive statistics of the topological features (PD-statistics) leads to the best performance to constrain equilateral PNG. We observe that the constraining power of these summaries comes from large-mass halos, with small-mass halos adding noise and degrading performance. Similarly, we find that the transferability of the learned mappings, for both topological and powerspectrum plus bispectrum, degrades if small scales or small-mass halos are included.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.09852" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.09852" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.09852" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.CO</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">48. MorphZ: Enhancing evidence estimation through the Morph approximation
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>El Mehdi Zahraoui, Patricio Maturana-Russel, Avi Vajpeyi, Willem van Straten, Renate Meyer, Sergei Gulyaev</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> The MorphZ estimator, which employs optimal bridge sampling with the Morph approximation to select low-order disjoint parameter blocks, accurately and efficiently estimates the marginal likelihood (Bayesian evidence) using only posterior samples, complementing existing inference workflows. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">We introduce the Morph approximation, a class of product approximations of probability densities that selects low-order disjoint parameter blocks by maximizing the sum of their total correlations. We use the posterior approximation via Morph as the importance distribution in optimal bridge sampling. We denote this procedure by MorphZ, which serves as a post-processing estimator of the marginal likelihood. The MorphZ estimator requires only posterior samples together with the prior and likelihood, and is fully agnostic to the choice of sampler. We evaluate MorphZ&#39;s performance across statistical benchmarks, pulsar timing array (PTA) models, compact binary coalescence (CBC) gravitational-wave (GW) simulations and the GW150914 event. Across these applications, spanning low to high dimensionalities, MorphZ yields accurate evidence at substantially reduced computational cost relative to standard approaches, and can improve these estimates even when posterior coverage is incomplete. Its bridge sampling relative error diagnostic provides conservative uncertainty estimates. Because MorphZ operates directly on posterior draws, it complements exploration-oriented samplers by enabling fast and reliable evidence estimation, while it can be seamlessly integrated into existing inference workflows.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.10283" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.10283" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.10283" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">astro-ph.IM</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">49. New Approximation Results and Optimal Estimation for Fully Connected Deep Neural Networks
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <strong>Zhaoji Tang</strong>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Deriving refined approximation bounds for narrower fully connected deep neural networks demonstrates that the convergence rate for deep neural network estimators can be improved to achieve the optimal rate, mitigating the curse of dimensionality for functions with compositional structure. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">\citet{farrell2021deep} establish non-asymptotic high-probability bounds for general deep feedforward neural network (with rectified linear unit activation function) estimators, with \citet[Theorem 1]{farrell2021deep} achieving a suboptimal convergence rate for fully connected feedforward networks. The authors suggest that improved approximation of fully connected networks could yield sharper versions of \citet[Theorem 1]{farrell2021deep} without altering the theoretical framework. By deriving approximation bounds specifically for a narrower fully connected deep neural network, this note demonstrates that \citet[Theorem 1]{farrell2021deep} can be improved to achieve an optimal rate (up to a logarithmic factor). Furthermore, this note briefly shows that deep neural network estimators can mitigate the curse of dimensionality for functions with compositional structure and functions defined on manifolds.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.09853" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.09853" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.09853" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.00</span>
                        <span class="badge bg-primary">Semantic Score: 0.94</span>
                        
                            <span class="badge bg-secondary">econ.EM</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Cosmological Data Analysis, Bayesian Sampling / Neural Architectures, Representation Learning, Advanced Models</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
        <div class="arxiv-card card mb-4">
            <div class="arxiv-title card-header">50. The Early Maturity of High-Redshift Galaxies: Insights from sSFR, M/L and SFHs at z~7-14
                
            </div>
            <div class="arxiv-abstract card-body">
                <div class="arxiv-meta mb-3">
                    
                        <div onclick="toggleAuthors(this)" style="cursor: pointer;">
                            <strong>
                                <span class="author-short">P. Santini, M. Castellano, A. Calabrò, A. Fontana, E. Merlin, D. Bevacqua, P. Bergamini, S. Cantarella, L. Ciesla, A. Ferrara, et al.</span>
                                <span class="author-full" style="display: none;">P. Santini, M. Castellano, A. Calabrò, A. Fontana, E. Merlin, D. Bevacqua, P. Bergamini, S. Cantarella, L. Ciesla, A. Ferrara, S. L. Finkelstein, F. Fortuni, G. Gandolfi, T. Gasparetto, E. Giallongo, N. A. Grogin, S. T. Guida, A. M. Koekemoer, N. Menci, L. Napolitano, D. Paris, L. Pentericci, B. Perez-Diaz, B. Stoyanova, T. Treu</span>
                            </strong>
                            <a class="author-toggle text-primary" style="text-decoration: none;"> (show all)</a>
                        </div>
                    
                </div>
                <div class="tldr-section mb-3">
                    <p class="fst-italic text-muted"><strong>TLDR:</strong> Non-parametric star formation history modeling of robust JWST galaxy candidates at $z\sim7-14$ indicates a roughly constant median specific star formation rate and mass-to-light ratio, implying that any dust-free starburst phases must be short-lived and confirming the existence of evolved, high mass-to-light ratio systems only hundreds of Myr after the Big Bang. (gemini)</p>
                </div>
                <div class="arxiv-abstract-text">The James Webb Space Telescope (JWST) has revealed an unexpected excess of UV-bright galaxies at z&gt;10, unaccounted for by extrapolations from pre-JWST observations and theoretical models. Understanding the physical properties and star formation histories (SFH) of high redshift systems is key to distinguish between the different proposed scenarios. We identify and analyse a sample of 2420 robust candidates at z~7-14 drawn from the ASTRODEEP-JWST dataset over ~0.2 deg^2 and model their properties with non-parametric SFHs to derive their specific star formation rate (sSFR) and stellar population properties. We find that the median sSFR and M/L remain roughly constant across the probed redshift range. We show that this result is robust against potential systematics unless a hidden population of dust-enshrouded starbursts, undetectable in current data, exists at these redshifts. In any case, the absence of observed high-sSFR systems at the highest redshifts suggests that any dust-free starburst phase must be short-lived. The observed sSFR evolution is in tension with most (though not all) theoretical models, making it a key quantity for discriminating among competing scenarios. The sample shows a wide range of physical conditions and galaxy classes, including systems with low sSFR and high mass-to-light ratios (M/L) up to z~10, indicative of already evolved galaxies only a few hundred Myr after the Big Bang, and different degrees of dust attenuation. We finally attempt to reconstruct the assembly histories of two sub-samples: a) the highest-M/L galaxies at z~7-8, which appear to have formed the bulk of their stars at least 500 Myr before observation, implying progenitors observable as UV-bright sources at z&gt;20, and b) z&gt;11 galaxies, which formed through stochastic SFH, remaining UV-faint for most of their early evolution, before undergoing recent (~50 Myr old) episodes of major growth.</div>
                <div class="mt-3">
                    <div class="arxiv-links mt-2">
                        <a class="btn btn-sm btn-outline-primary" href="https://arxiv.org/abs/2512.09139" target="_blank">arXiv</a>
                        <a class="btn btn-sm btn-outline-success" href="https://arxiv.org/pdf/2512.09139" target="_blank">PDF</a>
                        <a class="btn btn-sm btn-outline-secondary" href="https://ui.adsabs.harvard.edu/#abs/arXiv:2512.09139" target="_blank">ADS</a>
                    </div>
                </div>
                <div class="mt-2">
                    <div class="arxiv-scores">
                        <span class="badge bg-success">Total Score: 9.4</span>
                        <span class="badge bg-info text-dark">Author Score: 0.02</span>
                        <span class="badge bg-primary">Semantic Score: 0.93</span>
                        
                            <span class="badge bg-secondary">astro-ph.GA</span>
                        
                        
                            <span class="badge" style="background-color: #6f42c1; color: white;">Interest: Weak Lensing, Cosmic Shear, Galaxy Surveys / Galaxy-Halo Connection, Lensing, Clustering</span>
                        
                    </div>
                </div>
            </div>
        </div>
        
    </div>

    <footer class="footer">
        &copy; 2025 arXiv Daily · Powered by <a href="https://arxiv.org/" target="_blank">arXiv</a>
    </footer>
</body>
</html>